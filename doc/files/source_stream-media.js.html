<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>SkylinkJS 0.6.3</title>
    <!-- font and icon -->
    <link rel="shortcut icon" type="image/ico" href="../assets/favicon.ico">
    <link rel="stylesheet" href="../assets/vendor/prettify/prettify-min.css">
    <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600,700|Source+Sans+Pro" type="text/css">
    <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600,700|Source+Code+Pro" type="text/css">
    <!-- styling -->
    <link rel="stylesheet" href="../assets/vendor/css/bootstrap.min.css">
    <link rel="stylesheet" href="../assets/vendor/css/bootstrap-theme.min.css">
    <link href="../assets/vendor/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="../assets/css/style.css">
    <!-- scripts -->
    <script src="../assets/vendor/js/jquery.min.js"></script>
    <script src="../assets/vendor/js/bootstrap.min.js"></script>
    <script src="../assets/js/script.js"></script>
    <script src="http://yui.yahooapis.com/combo?3.9.1/build/yui/yui-min.js"></script>
</head>
<body>

<div id="doc">
  <nav id="hd" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a href="" class="navbar-brand">
          <img src="../assets/img/logo.svg" />JS<small>Version: 0.6.3</small>
        </a>
      </div>
      <div id="navbar" class="navbar-collapse collapse">
        <ul id="api-list" class="nav navbar-nav navbar-right">
  <li><a href="https://temasys.github.io">Getting Started</a></li>
  
    <li><a href="../classes/Skylink.html">Documentation</a></li>
  
  <!--<li class="dropdown">
    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Classes <span class="caret"></span></a>
    <ul class="dropdown-menu" role="menu">
      
        <li><a href="../classes/Skylink.html">Skylink</a></li>
      
    </ul>
  </li>-->
  <li><a class="btn btn-info btn-navbar" href="http://developer.temasys.com.sg/">Developer Console</a></li>
  <li><a class="btn btn-info btn-navbar" href="http://support.temasys.com.sg/">Support</a></li>
  <!--<li class="dropdown">
    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Modules <span class="caret"></span></a>
    <ul class="dropdown-menu" role="menu">
      <li><a href="#api-modules">View all Modules</a></li>
      
    </ul>
  </li>-->
</ul>
<!--<form id="api-tabview" class="navbar-form navbar-right" role="form">
  <div id="api-tabview-filter" class="form-group">
    <input type="search" id="api-filter" placeholder="Type to filter APIs">
  </div>
</form>-->
      </div><!--/.navbar-collapse -->
    </div>
  </nav>
  <div id="bd" class="yui3-g">

      <div class="yui3-u-1-4">

      </div>
      <div class="yui3-u-3-4">
          
          <div class="apidocs">
              <div id="docs-main">
                  <div class="content content-main">
                      <h1 class="file-heading">File: source/stream-media.js</h1>

<div class="file">
    <pre class="code prettyprint linenums">
/**
 * These are the list of available video codecs settings that Skylink would use
 *   when streaming video stream with Peers.
 * - The video codec would be used if the self and Peer&#x27;s browser supports the selected codec.
 * - This would default to the browser selected codec. In most cases, option &lt;code&gt;VP8&lt;/code&gt; is
 *   used by default.
 * @attribute VIDEO_CODEC
 * @param {String} AUTO &lt;small&gt;&lt;b&gt;DEFAULT&lt;/b&gt; | Value &lt;code&gt;&quot;auto&quot;&lt;/code&gt;&lt;/small&gt;
 *   The option to let Skylink use any video codec selected by the browser generated session description.
 * @param {String} VP8 &lt;small&gt;Value &lt;code&gt;&quot;VP8&quot;&lt;/code&gt;&lt;/small&gt;
 *   The option to let Skylink use the [VP8](https://en.wikipedia.org/wiki/VP8) codec.&lt;br&gt;
 *   This is the common and mandantory video codec used by most browsers.
 * @param {String} H264 &lt;small&gt;Value &lt;code&gt;&quot;H264&quot;&lt;/code&gt;&lt;/small&gt;
 *   The option to let Skylink use the [H264](https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC) codec.&lt;br&gt;
 *   This only works if the browser supports the H264 video codec.
 * @type JSON
 * @readOnly
 * @component Stream
 * @for Skylink
 * @since 0.5.10
 */
Skylink.prototype.VIDEO_CODEC = {
  AUTO: &#x27;auto&#x27;,
  VP8: &#x27;VP8&#x27;,
  H264: &#x27;H264&#x27;
};

/**
 * These are the list of available audio codecs settings that Skylink would use
 *   when streaming audio stream with Peers.
 * - The audio codec would be used if the self and Peer&#x27;s browser supports the selected codec.
 * - This would default to the browser selected codec. In most cases, option &lt;code&gt;OPUS&lt;/code&gt; is
 *   used by default.
 * @attribute AUDIO_CODEC
 * @param {String} AUTO &lt;small&gt;&lt;b&gt;DEFAULT&lt;/b&gt; | Value &lt;code&gt;&quot;auto&quot;&lt;/code&gt;&lt;/small&gt;
 *   The option to let Skylink use any audio codec selected by the browser generated session description.
 * @param {String} OPUS &lt;small&gt;Value &lt;code&gt;&quot;opus&quot;&lt;/code&gt;&lt;/small&gt;
 *   The option to let Skylink use the [OPUS](https://en.wikipedia.org/wiki/Opus_(audio_format)) codec.&lt;br&gt;
 *   This is the common and mandantory audio codec used.
 * @param {String} ISAC &lt;small&gt;Value &lt;code&gt;&quot;ISAC&quot;&lt;/code&gt;&lt;/small&gt;
 *   The option to let Skylink use the [iSAC](https://en.wikipedia.org/wiki/Internet_Speech_Audio_Codec).&lt;br&gt;
 *   This only works if the browser supports the iSAC video codec.
 * @type JSON
 * @readOnly
 * @component Stream
 * @for Skylink
 * @since 0.5.10
 */
Skylink.prototype.AUDIO_CODEC = {
  AUTO: &#x27;auto&#x27;,
  ISAC: &#x27;ISAC&#x27;,
  OPUS: &#x27;opus&#x27;
};

/**
 * Stores the preferred Peer connection streaming audio codec.
 * @attribute _selectedAudioCodec
 * @type String
 * @default Skylink.AUDIO_CODEC.AUTO
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.10
 */
Skylink.prototype._selectedAudioCodec = &#x27;auto&#x27;;

/**
 * Stores the preferred Peer connection streaming video codec.
 * @attribute _selectedVideoCodec
 * @type String
 * @default Skylink.VIDEO_CODEC.AUTO
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.10
 */
Skylink.prototype._selectedVideoCodec = &#x27;auto&#x27;;


/**
 * These are the list of suggested video resolutions that Skylink should configure
 *   when retrieving self user media video stream.
 * - Setting the resolution may not force set the resolution provided as it
 *   depends on the how the browser handles the resolution.
 * - It&#x27;s recommended to use video resolution option to maximum &lt;code&gt;FHD&lt;/code&gt;, as the other
 *   resolution options may be unrealistic and create performance issues. However, we provide them
 *   to allow developers to test with the browser capability, but do use it at your own risk.
 * - The higher the resolution, the more CPU usage might be used, hence it&#x27;s recommended to
 *   use the default option &lt;code&gt;VGA&lt;/code&gt;.
 * - This follows the
 *   [Wikipedia Graphics display resolution page](https://en.wikipedia.org/wiki/Graphics_display_resolution#Video_Graphics_Array)
 * @param {JSON} QQVGA &lt;small&gt;Value &lt;code&gt;{ width: 160, height: 120 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 *   The option to use QQVGA resolution.
 * @param {JSON} HQVGA &lt;small&gt;Value &lt;code&gt;{ width: 240, height: 160 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;3:2&lt;/code&gt;&lt;/small&gt;
 *   The option to use HQVGA resolution.
 * @param {JSON} QVGA &lt;small&gt;Value &lt;code&gt;{ width: 320, height: 240 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 *   The option to use QVGA resolution.
 * @param {JSON} WQVGA &lt;small&gt;Value &lt;code&gt;{ width: 384, height: 240 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;16:10&lt;/code&gt;&lt;/small&gt;
 *   The option to use WQVGA resolution.
 * @param {JSON} HVGA &lt;small&gt;Value &lt;code&gt;{ width: 480, height: 320 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;3:2&lt;/code&gt;&lt;/small&gt;
 *   The option to use HVGA resolution.
 * @param {JSON} VGA &lt;small&gt;&lt;b&gt;DEFAULT&lt;/b&gt; | Value &lt;code&gt;{ width: 640, height: 480 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 *   The option to use VGA resolution.
 * @param {JSON} WVGA &lt;small&gt;Value &lt;code&gt;{ width: 768, height: 480 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;16:10&lt;/code&gt;&lt;/small&gt;
 *   The option to use WVGA resolution.
 * @param {JSON} FWVGA &lt;small&gt;Value &lt;code&gt;{ width: 854, height: 480 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   The option to use FWVGA resolution.
 * @param {JSON} SVGA &lt;small&gt;Value &lt;code&gt;{ width: 800, height: 600 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 *   The option to use SVGA resolution.
 * @param {JSON} DVGA &lt;small&gt;Value &lt;code&gt;{ width: 960, height: 640 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;3:2&lt;/code&gt;&lt;/small&gt;
 *   The option to use DVGA resolution.
 * @param {JSON} WSVGA &lt;small&gt;Value &lt;code&gt;{ width: 1024, height: 576 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   The option to use WSVGA resolution.
 * @param {JSON} HD &lt;small&gt;Value &lt;code&gt;{ width: 1280, height: 720 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   The option to use HD resolution.
 * @param {JSON} HDPLUS &lt;small&gt;Value &lt;code&gt;{ width: 1600, height: 900 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   The option to use HDPLUS resolution.
 * @param {JSON} FHD &lt;small&gt;Value &lt;code&gt;{ width: 1920, height: 1080 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   The option to use FHD resolution.
 * @param {JSON} QHD &lt;small&gt;Value &lt;code&gt;{ width: 2560, height: 1440 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   The option to use QHD resolution.
 * @param {JSON} WQXGAPLUS &lt;small&gt;Value &lt;code&gt;{ width: 3200, height: 1800 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   The option to use WQXGAPLUS resolution.
 * @param {JSON} UHD &lt;small&gt;Value &lt;code&gt;{ width: 3840, height: 2160 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   The option to use UHD resolution.
 * @param {JSON} UHDPLUS &lt;small&gt;Value &lt;code&gt;{ width: 5120, height: 2880 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   The option to use UHDPLUS resolution.
 * @param {JSON} FUHD &lt;small&gt;Value &lt;code&gt;{ width: 7680, height: 4320 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   The option to use FUHD resolution.
 * @param {JSON} QUHD &lt;small&gt;Value &lt;code&gt;{ width: 15360, height: 8640 }&lt;/code&gt; | Aspect Ratio &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   The option to use QUHD resolution.
 * @attribute VIDEO_RESOLUTION
 * @type JSON
 * @readOnly
 * @component Stream
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype.VIDEO_RESOLUTION = {
  QQVGA: { width: 160, height: 120, aspectRatio: &#x27;4:3&#x27; },
  HQVGA: { width: 240, height: 160, aspectRatio: &#x27;3:2&#x27; },
  QVGA: { width: 320, height: 240, aspectRatio: &#x27;4:3&#x27; },
  WQVGA: { width: 384, height: 240, aspectRatio: &#x27;16:10&#x27; },
  HVGA: { width: 480, height: 320, aspectRatio: &#x27;3:2&#x27; },
  VGA: { width: 640, height: 480, aspectRatio: &#x27;4:3&#x27; },
  WVGA: { width: 768, height: 480, aspectRatio: &#x27;16:10&#x27; },
  FWVGA: { width: 854, height: 480, aspectRatio: &#x27;16:9&#x27; },
  SVGA: { width: 800, height: 600, aspectRatio: &#x27;4:3&#x27; },
  DVGA: { width: 960, height: 640, aspectRatio: &#x27;3:2&#x27; },
  WSVGA: { width: 1024, height: 576, aspectRatio: &#x27;16:9&#x27; },
  HD: { width: 1280, height: 720, aspectRatio: &#x27;16:9&#x27; },
  HDPLUS: { width: 1600, height: 900, aspectRatio: &#x27;16:9&#x27; },
  FHD: { width: 1920, height: 1080, aspectRatio: &#x27;16:9&#x27; },
  QHD: { width: 2560, height: 1440, aspectRatio: &#x27;16:9&#x27; },
  WQXGAPLUS: { width: 3200, height: 1800, aspectRatio: &#x27;16:9&#x27; },
  UHD: { width: 3840, height: 2160, aspectRatio: &#x27;16:9&#x27; },
  UHDPLUS: { width: 5120, height: 2880, aspectRatio: &#x27;16:9&#x27; },
  FUHD: { width: 7680, height: 4320, aspectRatio: &#x27;16:9&#x27; },
  QUHD: { width: 15360, height: 8640, aspectRatio: &#x27;16:9&#x27; }
};

/**
 * Stores the self user media MediaStream object.
 * @attribute _mediaStream
 * @type Object
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._mediaStream = null;

/**
 * Stores the self screensharing MediaStream.
 * @attribute _mediaScreen
 * @type Object
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.6.0
 */
Skylink.prototype._mediaScreen = null;

/**
 * Stores the self screensharing audio MediaStream
 *   for browsers that do not support bundling of
 *   screensharing MediaStream with &lt;code&gt;audio: true&lt;/code&gt;.
 * The current {{#crossLink &quot;Skylink/_mediaScreen:attribute&quot;}}_mediaScreen{{/crossLink}}
 *   clones this MediaStream object and &lt;code&gt;.addTrack()&lt;/code&gt; with the
 *   screensharing MediaStream object video MediaStreamTrack object.
 * @attribute _mediaScreenClone
 * @type Object
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.6.0
 */
Skylink.prototype._mediaScreenClone = null;

/**
 * Stores the Skylink default streaming settings.
 * @attribute _defaultStreamSettings
 * @type JSON
 * @param {Boolean|JSON} [audio=false] The
 *   default streaming audio settings. If
 *   &lt;code&gt;false&lt;/code&gt;, it means that audio streaming is disabled in
 *   self connection Stream.
 * @param {Boolean} [audio.stereo=false] The default flag that indicates if
 *   stereo should be enabled in self connection Stream
 *    audio streaming.
 * @param {Boolean|JSON} [video=false] The default
 *   streaming video settings. If &lt;code&gt;false&lt;/code&gt;, it means that
 *   video streaming is disabled in the remote Stream of the Peer.
 * @param {JSON} [video.resolution] The default
 *   streaming video resolution settings. Setting the resolution may
 *   not force set the resolution provided as it depends on the how the
 *   browser handles the resolution. [Rel: Skylink.VIDEO_RESOLUTION]
 * @param {Number} [video.resolution.width] The default
 *   streaming video resolution width.
 * @param {Number} [video.resolution.height] The default
 *   streaming video resolution height.
 * @param {Number} [video.frameRate] The default
 *   streaming video maximum frameRate.
 * @param {String} [bandwidth] The default
 *   streaming bandwidth settings. Setting the bandwidth flags may not
 *   force set the bandwidth for each connection stream channels as it depends
 *   on how the browser handles the bandwidth bitrate. Values are configured
 *   in &lt;var&gt;kb/s&lt;/var&gt;.
 * @param {String} [bandwidth.audio] The default
 *   audio stream channel for self Stream object bandwidth
 *   that audio streaming should use in &lt;var&gt;kb/s&lt;/var&gt;.
 * @param {String} [bandwidth.video] The default
 *   video stream channel for self Stream object bandwidth
 *   that video streaming should use in &lt;var&gt;kb/s&lt;/var&gt;.
 * @param {String} [bandwidth.data] The default
 *   datachannel channel for self DataChannel connection bandwidth
 *   that datachannel connection per packet should be able use in &lt;var&gt;kb/s&lt;/var&gt;.
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.7
 */
Skylink.prototype._defaultStreamSettings = {
  audio: {
    stereo: false
  },
  video: {
    resolution: {
      width: 640,
      height: 480
    },
    frameRate: 50
  },
  bandwidth: {
    audio: 50,
    video: 256,
    data: 1638400
  }
};

/**
 * Stores self user media Stream streaming settings. If both audio and video
 *   option is &lt;code&gt;false&lt;/code&gt;, there should be no
 *   receiving remote Stream object from self connection.
 * @attribute _streamSettings
 * @type JSON
 * @param {Boolean|JSON} [audio=false] The
 *   self Stream streaming audio settings. If
 *   &lt;code&gt;false&lt;/code&gt;, it means that audio streaming is disabled in
 *   the remote Stream of self connection.
 * @param {Boolean} [audio.stereo=false] The flag that indicates if
 *   stereo should be enabled in self connection Stream
 *   audio streaming.
 * @param {Array} [audio.optional] The optional constraints for audio streaming
 *   in self user media Stream object. Some of the values are
 *   set by the &lt;code&gt;audio.optional&lt;/code&gt; setting in
 *   {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}.
 * @param {Boolean|JSON} [video=false] The self
 *   Stream streaming video settings. If &lt;code&gt;false&lt;/code&gt;, it means that
 *   video streaming is disabled in the remote Stream of self connection.
 * @param {JSON} [video.resolution] The self
 *   Stream streaming video resolution settings. Setting the resolution may
 *   not force set the resolution provided as it depends on the how the
 *   browser handles the resolution. [Rel: Skylink.VIDEO_RESOLUTION]
 * @param {Number} [video.resolution.width] The self
 *   Stream streaming video resolution width.
 * @param {Number} [video.resolution.height] The self
 *   Stream streaming video resolution height.
 * @param {Number} [video.frameRate] The self
 *   Stream streaming video maximum frameRate.
 * @param {Boolean} [video.screenshare=false] The flag
 *   that indicates if the self connection Stream object sent
 *   is a screensharing stream or not. In this case, the
 *   value is &lt;code&gt;false&lt;/code&gt; for user media Stream object.
 * @param {Array} [video.optional] The optional constraints for video streaming
 *   in self user media Stream object. Some of the values are
 *   set by the &lt;code&gt;video.optional&lt;/code&gt; setting in
 *   {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}.
 * @param {String} [bandwidth] The self
 *   streaming bandwidth settings. Setting the bandwidth flags may not
 *   force set the bandwidth for each connection stream channels as it depends
 *   on how the browser handles the bandwidth bitrate. Values are configured
 *   in &lt;var&gt;kb/s&lt;/var&gt;.
 * @param {String} [bandwidth.audio] The configured
 *   audio stream channel for self connection Stream object bandwidth
 *   that audio streaming should use in &lt;var&gt;kb/s&lt;/var&gt;.
 * @param {String} [bandwidth.video] The configured
 *   video stream channel for the self connection Stream object bandwidth
 *   that video streaming should use in &lt;var&gt;kb/s&lt;/var&gt;.
 * @param {String} [bandwidth.data] The configured
 *   datachannel channel for self DataChannel connection bandwidth
 *   that datachannel connection per packet should be able use in &lt;var&gt;kb/s&lt;/var&gt;.
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._streamSettings = {};

/**
 * Stores self screensharing Stream streaming settings.
 * @attribute _screenSharingStreamSettings
 * @type JSON
 * @param {Boolean|JSON} [audio=false] The
 *   self Stream streaming audio settings. If
 *   &lt;code&gt;false&lt;/code&gt;, it means that audio streaming is disabled in
 *   the remote Stream of self connection.
 * @param {Boolean} [audio.stereo=false] The flag that indicates if
 *   stereo should be enabled in self connection Stream
 *   audio streaming.
 * @param {Boolean|JSON} video The self
 *   Stream streaming video settings.
 * @param {Boolean} [video.screenshare=false] The flag
 *   that indicates if the self connection Stream object sent
 *   is a screensharing stream or not. In this case, the
 *   value is &lt;code&gt;true&lt;/code&gt; for screensharing Stream object.
 * @param {String} [bandwidth] The self
 *   streaming bandwidth settings. Setting the bandwidth flags may not
 *   force set the bandwidth for each connection stream channels as it depends
 *   on how the browser handles the bandwidth bitrate. Values are configured
 *   in &lt;var&gt;kb/s&lt;/var&gt;.
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.6.1
 */
Skylink.prototype._screenSharingStreamSettings = {
  video: {
    screenshare: true
  }
};

/**
 * The flag that indicates if self browser supports the screensharing feature.
 * Currently, Opera does not support screensharing and only premium
 *   Temasys plugins support this screensharing feature.
 * @attribute _screenSharingAvailable
 * @type Boolean
 * @default false
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._screenSharingAvailable = false;

/**
 * Stores the
 *   [getUserMedia MediaStreamConstraints](https://w3c.github.io/mediacapture-main/getusermedia.html#idl-def-MediaStreamConstraints)
 *   parsed from {{#crossLink &quot;Skylink/_streamSettings:attribute&quot;}}_streamSettings{{/crossLink}}
 *   for user media Stream object.
 * @attribute _getUserMediaSettings
 * @type JSON
 * @param {Boolean|JSON} [audio=false] The flag that indicates if self user media
 *   MediaStream would have audio streaming.
 * @param {Array} [audio.optional] The optional constraints for audio streaming
 *   in self user media MediaStream object. Some of the values are
 *   set by the &lt;code&gt;audio.optional&lt;/code&gt; setting in
 *   {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}.
 * @param {Boolean|JSON} [video=false] The flag that indicates if self user media
 *   MediaStream would have video streaming.
 * @param {Number} [video.mandatory.maxHeight] The self user media
 *   MediaStream video streaming resolution maximum height.
 * @param {Number} [video.mandatory.maxWidth] The self user media
 *   MediaStream video streaming resolution maximum width.
 * @param {Number} [video.mandatory.maxFrameRate] The self user media
 *   MediaStream video streaming maxinmum framerate.
 * @param {Array} [video.optional] The optional constraints for video streaming
 *   in self user media MediaStream object. Some of the values are
 *   set by the &lt;code&gt;video.optional&lt;/code&gt; setting in
 *   {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}.
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._getUserMediaSettings = {};

/**
 * Stores self Stream mute settings for both audio and video streamings.
 * @attribute _mediaStreamsStatus
 * @type JSON
 * @param {Boolean} [audioMuted=true] The flag that
 *   indicates if self connection Stream object audio streaming is muted. If
 *   there is no audio streaming enabled for self connection, by default,
 *   it is set to &lt;code&gt;true&lt;/code&gt;.
 * @param {Boolean} [videoMuted=true] The flag that
 *   indicates if self connection Stream object video streaming is muted. If
 *   there is no video streaming enabled for self connection, by default,
 *   it is set to &lt;code&gt;true&lt;/code&gt;.
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._mediaStreamsStatus = {};

/**
 * The flag indicates that when Skylink tries to get both audio and video stream
 *   but Skylink fails to retrieve the user media stream, it should fallback
 *   to retrieve audio streaming for the user media stream only.
 * @attribute _audioFallback
 * @type Boolean
 * @default false
 * @private
 * @required
 * @component Stream
 * @for Skylink
 * @since 0.5.4
 */
Skylink.prototype._audioFallback = false;

/**
 * Handles the event when access to self user media MediaStream is successful.
 * @method _onUserMediaSuccess
 * @param {MediaStream} stream The self user MediaStream object.
 * @param {Boolean} [isScreenSharing=false] The flag that indicates if self
 *    Stream object is a screensharing stream or not.
 * @trigger mediaAccessSuccess
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.3.0
 */
Skylink.prototype._onUserMediaSuccess = function(stream, isScreenSharing) {
  var self = this;
  log.log([null, &#x27;MediaStream&#x27;, stream.id,
    &#x27;User has granted access to local media&#x27;], stream);

  var streamEnded = function () {
    log.log([null, &#x27;MediaStream&#x27;, stream.id, &#x27;Local mediastream has ended&#x27;], {
      inRoom: self._inRoom,
      currentTime: stream.currentTime,
      ended: typeof stream.active === &#x27;boolean&#x27; ?
        stream.active : stream.ended
    });

    if (self._inRoom) {
      log.debug([null, &#x27;MediaStream&#x27;, stream.id, &#x27;Sending mediastream ended status&#x27;]);
      self._sendChannelMessage({
        type: self._SIG_MESSAGE_TYPE.STREAM,
        mid: self._user.sid,
        rid: self._room.id,
        cid: self._key,
        sessionType: !!isScreenSharing ? &#x27;screensharing&#x27; : &#x27;stream&#x27;,
        status: &#x27;ended&#x27;
      });
    }
    self._trigger(&#x27;streamEnded&#x27;, self._user.sid || null, self.getPeerInfo(), true, !!isScreenSharing);
  };
  stream.onended = streamEnded;

  // Workaround for local stream.onended because firefox has not yet implemented it
  if (window.webrtcDetectedBrowser === &#x27;firefox&#x27;) {
    stream.onended = setInterval(function () {
      if (typeof stream.recordedTime === &#x27;undefined&#x27;) {
        stream.recordedTime = 0;
      }

      if (stream.recordedTime === stream.currentTime) {
        clearInterval(stream.onended);
        // trigger that it has ended
        streamEnded();

      } else {
        stream.recordedTime = stream.currentTime;
      }

    }, 1000);
  }

  // check if readyStateChange is done
  if (!isScreenSharing) {
    self._mediaStream = stream;
  } else {
    self._mediaScreen = stream;
  }

  self._muteLocalMediaStreams();

  self._wait(function () {
    self._trigger(&#x27;mediaAccessSuccess&#x27;, stream, !!isScreenSharing);
  }, function () {
    if (!isScreenSharing) {
      return self._mediaStream &amp;&amp; self._mediaStream !== null;
    } else {
      return self._mediaScreen &amp;&amp; self._mediaScreen !== null;
    }
  });

  /*self._condition(&#x27;readyStateChange&#x27;, function () {
    // check if users is in the room already
    self._condition(&#x27;peerJoined&#x27;, function () {
      self._trigger(&#x27;incomingStream&#x27;, self._user.sid, stream, true,
        self.getPeerInfo(), !!isScreenSharing);
    }, function () {
      return self._inRoom;
    }, function (peerId, peerInfo, isSelf) {
      return isSelf;
    });
  }, function () {
    return self._readyState === self.READY_STATE_CHANGE.COMPLETED;
  }, function (state) {
    return state === self.READY_STATE_CHANGE.COMPLETED;
  });*/
};

/**
 * Handles the event when access to self user media MediaStream has failed.
 * @method _onUserMediaError
 * @param {Object} error The error object thrown that caused the failure.
 * @param {Boolean} [isScreenSharing=false] The flag that indicates if self
 *    Stream object is a screensharing stream or not.
 * @param {Boolean} [audioFallback=false] The flag that indicates if stage
 *    of stream media error should do an audio fallback.
 * @trigger mediaAccessError
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.4
 */
Skylink.prototype._onUserMediaError = function(error, isScreenSharing, audioFallback) {
  var self = this;
  var hasAudioVideoRequest = !!self._streamSettings.video &amp;&amp; !!self._streamSettings.audio;

  if (self._audioFallback &amp;&amp; hasAudioVideoRequest &amp;&amp; audioFallback) {
    // redefined the settings for video as false
    self._streamSettings.video = false;
    self._getUserMediaSettings.video = false;

    log.debug([null, &#x27;MediaStream&#x27;, null, &#x27;Falling back to audio stream call&#x27;]);

    self._trigger(&#x27;mediaAccessFallback&#x27;, error);

    window.getUserMedia({
      audio: true
    }, function(stream) {
      self._onUserMediaSuccess(stream);
    }, function(error) {
      log.error([null, &#x27;MediaStream&#x27;, null,
        &#x27;Failed retrieving audio in audio fallback:&#x27;], error);
      self._trigger(&#x27;mediaAccessError&#x27;, error, !!isScreenSharing, true);
    });
  } else {
    log.error([null, &#x27;MediaStream&#x27;, null, &#x27;Failed retrieving stream:&#x27;], error);
   self._trigger(&#x27;mediaAccessError&#x27;, error, !!isScreenSharing, false);
  }
};

/**
 * Handles the event when remote MediaStream is received from Peer connection.
 * @method _onRemoteStreamAdded
 * @param {String} targetMid The Peer ID associated with the remote Stream object received.
 * @param {Event}  event The event object received in the &lt;code&gt;RTCPeerConnection.
 *   onaddstream&lt;/code&gt;.
 * @param {Boolean} [isScreenSharing=false] The flag that indicates if Peer connection
 *    Stream object is a screensharing stream or not.
 * @trigger incomingStream
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.2
 */
Skylink.prototype._onRemoteStreamAdded = function(targetMid, event, isScreenSharing) {
  var self = this;

  if(targetMid !== &#x27;MCU&#x27;) {
    if (!self._peerInformations[targetMid]) {
      log.error([targetMid, &#x27;MediaStream&#x27;, event.stream.id,
          &#x27;Received remote stream when peer is not connected. &#x27; +
          &#x27;Ignoring stream -&gt;&#x27;], event.stream);
      return;
    }

    if (!self._peerInformations[targetMid].settings.audio &amp;&amp;
      !self._peerInformations[targetMid].settings.video &amp;&amp; !isScreenSharing) {
      log.log([targetMid, &#x27;MediaStream&#x27;, event.stream.id,
        &#x27;Receive remote stream but ignoring stream as it is empty -&gt;&#x27;
        ], event.stream);
      return;
    }
    log.log([targetMid, &#x27;MediaStream&#x27;, event.stream.id,
      &#x27;Received remote stream -&gt;&#x27;], event.stream);

    if (isScreenSharing) {
      log.log([targetMid, &#x27;MediaStream&#x27;, event.stream.id,
        &#x27;Peer is having a screensharing session with user&#x27;]);
    }

    self._trigger(&#x27;incomingStream&#x27;, targetMid, event.stream,
      false, self.getPeerInfo(targetMid), !!isScreenSharing);
  } else {
    log.log([targetMid, null, null, &#x27;MCU is listening&#x27;]);
  }
};

/**
 * Parses the audio stream settings for self provided.
 * @method _parseAudioStreamSettings
 * @param {Boolean|JSON} [options=false] The flag that indicates if self user media
 *   MediaStream would have audio streaming.
 * @param {Boolean} [options.mute=false] The flag that
 *   indicates if the self Stream object audio streaming is muted.
 * @param {Array} [options.optional] The optional constraints for audio streaming
 *   in self user media Stream object. Some of the values are
 *   set by the &lt;code&gt;audio.optional&lt;/code&gt; setting in
 *   {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}.
 * @return {JSON} The parsed audio stream settings for self.
 *   &lt;ul&gt;
 *     &lt;li&gt;&lt;code&gt;return.settings&lt;/code&gt;: The output audio stream settings
 *        information for self&lt;/li&gt;
 *     &lt;li&gt;&lt;code&gt;return.userMedia&lt;/code&gt;: The output audio
 *        MediaStreamConstraints to be passed into getUserMedia()&lt;/li&gt;
 *  &lt;/ul&gt;
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype._parseAudioStreamSettings = function (audioOptions) {
  audioOptions = (typeof audioOptions === &#x27;object&#x27;) ?
    audioOptions : !!audioOptions;

  var hasOptional = false;

  // Cleaning of unwanted keys
  if (audioOptions !== false) {
    audioOptions = (typeof audioOptions === &#x27;boolean&#x27;) ? {} : audioOptions;
    var tempAudioOptions = {};
    tempAudioOptions.stereo = !!audioOptions.stereo;
    tempAudioOptions.optional = [];

    if (Array.isArray(audioOptions.optional)) {
      tempAudioOptions.optional = audioOptions.optional;
      hasOptional = true;
    }

    audioOptions = tempAudioOptions;
  }

  var userMedia = (typeof audioOptions === &#x27;object&#x27;) ?
    true : audioOptions;

  if (hasOptional) {
    userMedia = {
      optional: audioOptions.optional
    };
  }

  return {
    settings: audioOptions,
    userMedia: userMedia
  };
};

/**
 * Parses the video stream settings for self provided.
 * @method _parseVideoStreamSettings
 * @param {Boolean|JSON} [options=false] The self
 *   Stream streaming video settings. If &lt;code&gt;false&lt;/code&gt;, it means that
 *   video streaming is disabled in the remote Stream of self connection.
 * @param {JSON} [options.resolution] The self
 *   Stream streaming video resolution settings. Setting the resolution may
 *   not force set the resolution provided as it depends on the how the
 *   browser handles the resolution. [Rel: Skylink.VIDEO_RESOLUTION]
 * @param {Number} [options.resolution.width] The self
 *   Stream streaming video resolution width.
 * @param {Number} [options.resolution.height] The self
 *   Stream streaming video resolution height.
 * @param {Number} [options.frameRate] The self
 *   Stream streaming video maximum frameRate.
 * @param {Boolean} [options.mute=false] The flag that
 *   indicates if the self Stream object video streaming is muted.
 * @param {Array} [options.optional] The optional constraints for video streaming
 *   in self user media Stream object. Some of the values are
 *   set by the &lt;code&gt;video.optional&lt;/code&gt; setting in
 *   {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}.
 * @return {JSON} The parsed video stream settings for self.
 *   &lt;ul&gt;
 *     &lt;li&gt;&lt;code&gt;return.settings&lt;/code&gt;: The output video stream settings
 *        information for self&lt;/li&gt;
 *     &lt;li&gt;&lt;code&gt;return.userMedia&lt;/code&gt;: The output video
 *        MediaStreamConstraints to be passed into getUserMedia()&lt;/li&gt;
 *  &lt;/ul&gt;
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.8
 */
Skylink.prototype._parseVideoStreamSettings = function (videoOptions) {
  videoOptions = (typeof videoOptions === &#x27;object&#x27;) ?
    videoOptions : !!videoOptions;

  var userMedia = false;

  // Cleaning of unwanted keys
  if (videoOptions !== false) {
    videoOptions = (typeof videoOptions === &#x27;boolean&#x27;) ?
      { resolution: {} } : videoOptions;
    var tempVideoOptions = {};
    // set the resolution parsing
    videoOptions.resolution = videoOptions.resolution || {};
    tempVideoOptions.resolution = tempVideoOptions.resolution || {};
    // set resolution
    tempVideoOptions.resolution.width = videoOptions.resolution.width ||
      this._defaultStreamSettings.video.resolution.width;
    tempVideoOptions.resolution.height = videoOptions.resolution.height ||
      this._defaultStreamSettings.video.resolution.height;
    // set the framerate
    tempVideoOptions.frameRate = videoOptions.frameRate ||
      this._defaultStreamSettings.video.frameRate;
    // set the screenshare option
    tempVideoOptions.screenshare = false;

    tempVideoOptions.optional = [];

    if (Array.isArray(videoOptions.optional)) {
      tempVideoOptions.optional = videoOptions.optional;
    }

    videoOptions = tempVideoOptions;

    userMedia = {
      mandatory: {
        //minWidth: videoOptions.resolution.width,
        //minHeight: videoOptions.resolution.height,
        maxWidth: videoOptions.resolution.width,
        maxHeight: videoOptions.resolution.height,
        //minFrameRate: videoOptions.frameRate,
        maxFrameRate: videoOptions.frameRate
      },
      optional: tempVideoOptions.optional
    };

    //Remove maxFrameRate for AdapterJS to work with Safari
    if (window.webrtcDetectedType === &#x27;plugin&#x27;) {
      delete userMedia.mandatory.maxFrameRate;
    }

    // Check if screensharing is available and enabled
    /*if (this._screenSharingAvailable &amp;&amp; videoOptions.screenshare) {
      userMedia.optional.push({ sourceId: AdapterJS.WebRTCPlugin.plugin.screensharingKey });
    }*/

    //For Edge
    if (window.webrtcDetectedBrowser === &#x27;edge&#x27;) {
      userMedia = true;
    }
  }

  return {
    settings: videoOptions,
    userMedia: userMedia
  };
};

/**
 * Parses the streaming bandwidth settings for self provided.
 * @method _parseBandwidthSettings
 * @param {String} [options] The self
 *   streaming bandwidth settings. Setting the bandwidth flags may not
 *   force set the bandwidth for each connection stream channels as it depends
 *   on how the browser handles the bandwidth bitrate. Values are configured
 *   in &lt;var&gt;kb/s&lt;/var&gt;.
 * @param {String} [options.audio] The configured
 *   audio stream channel for self connection Stream object bandwidth
 *   that audio streaming should use in &lt;var&gt;kb/s&lt;/var&gt;.
 * @param {String} [options.video] The configured
 *   video stream channel for the self connection Stream object bandwidth
 *   that video streaming should use in &lt;var&gt;kb/s&lt;/var&gt;.
 * @param {String} [options.data] The configured
 *   datachannel channel for self DataChannel connection bandwidth
 *   that datachannel connection per packet should be able use in &lt;var&gt;kb/s&lt;/var&gt;.
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype._parseBandwidthSettings = function (bwOptions) {
  bwOptions = (typeof bwOptions === &#x27;object&#x27;) ?
    bwOptions : {};

  // set audio bandwidth
  bwOptions.audio = (typeof bwOptions.audio === &#x27;number&#x27;) ?
    bwOptions.audio : 50;
  // set video bandwidth
  bwOptions.video = (typeof bwOptions.video === &#x27;number&#x27;) ?
    bwOptions.video : 256;
  // set data bandwidth
  bwOptions.data = (typeof bwOptions.data === &#x27;number&#x27;) ?
    bwOptions.data : 1638400;

  // set the settings
  this._streamSettings.bandwidth = bwOptions;
};

/**
 * Parses the &lt;code&gt;mediaStatus&lt;/code&gt; settings for self provided.
 * @method _parseMutedSettings
 * @param {JSON} [options] The self Stream streaming settings.
 * @param {String|JSON} [options.userData] The custom user data
 *   information set by developer. This custom user data can also
 *   be set in {{#crossLink &quot;Skylink/setUserData:method&quot;}}setUserData(){{/crossLink}}.
 * @param {Boolean|JSON} [options.audio=false] The self Stream streaming audio settings.
 *   If &lt;code&gt;false&lt;/code&gt;, it means that audio streaming is disabled in
 *   the self Stream. If this option is set to &lt;code&gt;true&lt;/code&gt; or is defined with
 *   settings, {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}
 *   will be invoked. Self will not connect to the room unless the Stream audio
 *   user media access is given.
 * @param {Boolean} [audio.stereo=false] The default flag that indicates if
 *   stereo should be enabled in self connection Stream
 *   audio streaming.
 * @param {Boolean} [options.audio.mute=false] The flag that
 *   indicates if the self Stream object audio streaming is muted.
 * @param {Boolean|JSON} [options.video=false] The self Stream streaming video settings.
 *   If &lt;code&gt;false&lt;/code&gt;, it means that video streaming is disabled in
 *   the self Stream. If this option is set to &lt;code&gt;true&lt;/code&gt; or is defined with
 *   settings, {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}
 *   will be invoked. Self will not connect to the room unless the Stream video
 *   user media access is given.
 * @param {Boolean} [options.video.mute=false] The flag that
 *   indicates if the self Stream object video streaming is muted.
 * @param {JSON} [options.video.resolution] The self Stream streaming video
 *   resolution settings. Setting the resolution may
 *   not force set the resolution provided as it depends on the how the
 *   browser handles the resolution. [Rel: Skylink.VIDEO_RESOLUTION]
 * @param {Number} [options.video.resolution.width] The self
 *   Stream streaming video resolution width.
 * @param {Number} [options.video.resolution.height] The self
 *   Stream streaming video resolution height.
 * @param {Number} [options.video.frameRate=50] The self
 *   Stream streaming video maximum frameRate.
 * @return {JSON} The parsed &lt;code&gt;mediaStatus&lt;/code&gt; settings for self.
 *   &lt;ul&gt;
 *     &lt;li&gt;&lt;code&gt;return.audioMuted&lt;/code&gt;:  The flag that
 *       indicates if self connection Stream object audio streaming is muted. If
 *       there is no audio streaming enabled for self connection, by default,
 *       it is set to &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *     &lt;li&gt;&lt;code&gt;return.videoMuted&lt;/code&gt;: The flag that
 *       indicates if self connection Stream object video streaming is muted. If
 *       there is no video streaming enabled for self connection, by default,
 *       it is set to &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *  &lt;/ul&gt;
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype._parseMutedSettings = function (options) {
  // the stream options
  options = (typeof options === &#x27;object&#x27;) ?
    options : { audio: false, video: false };

  var updateAudioMuted = (typeof options.audio === &#x27;object&#x27;) ?
    !!options.audio.mute : !options.audio;
  var updateVideoMuted = (typeof options.video === &#x27;object&#x27;) ?
    !!options.video.mute : !options.video;

  return {
    audioMuted: updateAudioMuted,
    videoMuted: updateVideoMuted
  };
};

/**
 * Parses the default stream settings received from
 *   the platform signaling.
 * @method _parseDefaultMediaStreamSettings
 * @param {JSON} defaults The default user media settings.
 * @param {Number} [defaults.maxHeight] The default user media
 *   MediaStream video streaming resolution maximum height.
 * @param {Number} [defaults.maxWidth] The default user media
 *   MediaStream video streaming resolution maximum width.
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.7
 */
Skylink.prototype._parseDefaultMediaStreamSettings = function(options) {
  var hasMediaChanged = false;

  // prevent undefined error
  options = options || {};

  log.debug(&#x27;Parsing stream settings. Default stream options:&#x27;, options);

  options.maxWidth = (typeof options.maxWidth === &#x27;number&#x27;) ? options.maxWidth :
    640;
  options.maxHeight = (typeof options.maxHeight === &#x27;number&#x27;) ? options.maxHeight :
    480;

  // parse video resolution. that&#x27;s for now
  this._defaultStreamSettings.video.resolution.width = options.maxWidth;
  this._defaultStreamSettings.video.resolution.height = options.maxHeight;

  log.debug(&#x27;Parsed default media stream settings&#x27;, this._defaultStreamSettings);
};

/**
 * Parses the provided stream settings for self provided.
 * @method _parseMediaStreamSettings
 * @param {JSON} [options] The self Stream streaming settings. If both audio and video
 *   option is &lt;code&gt;false&lt;/code&gt;, there should be no audio and video stream
 *   sending from self connection.
 * @param {Boolean|JSON} [options.audio=false] The self Stream streaming audio settings.
 *   If &lt;code&gt;false&lt;/code&gt;, it means that audio streaming is disabled in
 *   the self Stream. If this option is set to &lt;code&gt;true&lt;/code&gt; or is defined with
 *   settings, {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}
 *   will be invoked. Self will not connect to the room unless the Stream audio
 *   user media access is given.
 * @param {Boolean} [options.audio.stereo=false] The flag that indicates if
 *   stereo should be enabled in self connection Stream
 *   audio streaming.
 * @param {Boolean} [options.audio.mute=false] The flag that
 *   indicates if the self Stream object audio streaming is muted.
 * @param {Boolean|JSON} [options.video=false] The self Stream streaming video settings.
 *   If &lt;code&gt;false&lt;/code&gt;, it means that video streaming is disabled in
 *   the self Stream. If this option is set to &lt;code&gt;true&lt;/code&gt; or is defined with
 *   settings, {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}
 *   will be invoked. Self will not connect to the room unless the Stream video
 *   user media access is given.
 * @param {Boolean} [options.video.mute=false] The flag that
 *   indicates if the self Stream object video streaming is muted.
 * @param {JSON} [options.video.resolution] The self Stream streaming video
 *   resolution settings. Setting the resolution may
 *   not force set the resolution provided as it depends on the how the
 *   browser handles the resolution. [Rel: Skylink.VIDEO_RESOLUTION]
 * @param {Number} [options.video.resolution.width] The self
 *   Stream streaming video resolution width.
 * @param {Number} [options.video.resolution.height] The self
 *   Stream streaming video resolution height.
 * @param {Number} [options.video.frameRate=50] The self
 *   Stream streaming video maximum frameRate.
 * @param {JSON} [options.bandwidth] The self
 *   streaming bandwidth settings. Setting the bandwidth flags may not
 *   force set the bandwidth for each connection stream channels as it depends
 *   on how the browser handles the bandwidth bitrate. Values are configured
 *   in &lt;var&gt;kb/s&lt;/var&gt;.
 * @param {Number} [options.bandwidth.audio] The configured
 *   audio stream channel for the self Stream object bandwidth
 *   that audio streaming should use in &lt;var&gt;kb/s&lt;/var&gt;.
 * @param {Number} [options.bandwidth.video] The configured
 *   video stream channel for the self Stream object bandwidth
 *   that video streaming should use in &lt;var&gt;kb/s&lt;/var&gt;.
 * @param {Number} [options.bandwidth.data] The configured
 *   datachannel channel for the DataChannel connection bandwidth
 *   that datachannel connection per packet should be able use in &lt;var&gt;kb/s&lt;/var&gt;.
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._parseMediaStreamSettings = function(options) {
  var hasMediaChanged = false;

  options = options || {};

  log.debug(&#x27;Parsing stream settings. Stream options:&#x27;, options);

  // Set audio settings
  var audioSettings = this._parseAudioStreamSettings(options.audio);
  // check for change
  this._streamSettings.audio = audioSettings.settings;
  this._getUserMediaSettings.audio = audioSettings.userMedia;

  // Set video settings
  var videoSettings = this._parseVideoStreamSettings(options.video);
  // check for change
  this._streamSettings.video = videoSettings.settings;
  this._getUserMediaSettings.video = videoSettings.userMedia;

  // Set user media status options
  var mutedSettings = this._parseMutedSettings(options);

  this._mediaStreamsStatus = mutedSettings;

  log.debug(&#x27;Parsed user media stream settings&#x27;, this._streamSettings);

  log.debug(&#x27;User media status:&#x27;, this._mediaStreamsStatus);
};

/**
 * Sends self selected Stream object to current Peer connections.
 * If {{#crossLink &quot;Skylink/_mediaScreen:attribute&quot;}}_mediaScreen{{/crossLink}}
 *   is not empty, it will send the screensharing stream, else it will
 *   send the {{#crossLink &quot;Skylink/_mediaStream:attribute&quot;}}_mediaStream{{/crossLink}}
 *   if is not empty.
 * If self does not have any Stream object to send, it will a connection without
 *   any remote Stream sent to the Peer connection.
 * @method _addLocalMediaStreams
 * @param {String} peerId The Peer ID of the connection to send
 *   Stream object to.
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.2
 */
Skylink.prototype._addLocalMediaStreams = function(peerId) {
  // NOTE ALEX: here we could do something smarter
  // a mediastream is mainly a container, most of the info
  // are attached to the tracks. We should iterates over track and print
  try {
    log.log([peerId, null, null, &#x27;Adding local stream&#x27;]);

    var pc = this._peerConnections[peerId];

    if (pc) {
      if (pc.signalingState !== this.PEER_CONNECTION_STATE.CLOSED) {
        if (this._mediaScreen &amp;&amp; this._mediaScreen !== null) {
          pc.addStream(this._mediaScreen);
          log.debug([peerId, &#x27;MediaStream&#x27;, this._mediaStream, &#x27;Sending screen&#x27;]);

        } else if (this._mediaStream &amp;&amp; this._mediaStream !== null) {
          pc.addStream(this._mediaStream);
          log.debug([peerId, &#x27;MediaStream&#x27;, this._mediaStream, &#x27;Sending stream&#x27;]);

        } else {
          log.warn([peerId, null, null, &#x27;No media to send. Will be only receiving&#x27;]);
        }

      } else {
        log.warn([peerId, &#x27;MediaStream&#x27;, this._mediaStream,
          &#x27;Not adding stream as signalingState is closed&#x27;]);
      }
    } else {
      log.warn([peerId, &#x27;MediaStream&#x27;, this._mediaStream,
        &#x27;Not adding stream as peerconnection object does not exists&#x27;]);
    }
  } catch (error) {
    if ((error.message || &#x27;&#x27;).indexOf(&#x27;already added&#x27;) &gt; -1) {
      log.warn([peerId, null, null, &#x27;Not re-adding stream as LocalMediaStream is already added&#x27;], error);
    } else {
      // Fix errors thrown like NS_ERROR_UNEXPECTED
      log.error([peerId, null, null, &#x27;Failed adding local stream&#x27;], error);
    }
  }
};

/**
 * Stops self user media Stream object attached to Skylink.
 * @method stopStream
 * @trigger mediaAccessStopped, streamEnded
 * @example
 *   SkylinkDemo.stopStream();
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype.stopStream = function () {
  // if previous line break, recheck again to trigger event
  this._stopLocalMediaStreams({
    userMedia: true
  });
};

/**
 * Handles the muting of audio and video streams in
 *   {{#crossLink &quot;Skylink/_mediaStream:attribute&quot;}}_mediaStream{{/crossLink}},
 *   {{#crossLink &quot;Skylink/_mediaScreen:attribute&quot;}}_mediaScreen{{/crossLink}} and
 *   {{#crossLink &quot;Skylink/_mediaScreenClone:attribute&quot;}}_mediaScreenClone{{/crossLink}},
 * @method _muteLocalMediaStreams
 * @return {JSON} The information of the self MediaStream object attached to
 *   Skylink if they have the specified tracks for the stream settings.
 *   &lt;ul&gt;
 *     &lt;li&gt;&lt;code&gt;return.hasAudioTracks&lt;/code&gt;: The flag that indicates if
 *        self MediaStream has audio tracks&lt;/li&gt;
 *     &lt;li&gt;&lt;code&gt;return.hasVideoTracks&lt;/code&gt;: The flag that indicates if
 *        self MediaStream has video tracks&lt;/li&gt;
 *  &lt;/ul&gt;
 * @private
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._muteLocalMediaStreams = function () {
  var hasAudioTracks = false;
  var hasVideoTracks = false;

  var audioTracks;
  var videoTracks;
  var a, v;

  // Loop and enable tracks accordingly (mediaStream)
  if (this._mediaStream &amp;&amp; this._mediaStream !== null) {
    audioTracks = this._mediaStream.getAudioTracks();
    videoTracks = this._mediaStream.getVideoTracks();

    hasAudioTracks = audioTracks.length &gt; 0 || hasAudioTracks;
    hasVideoTracks = videoTracks.length &gt; 0 || hasVideoTracks;

    // loop audio tracks
    for (a = 0; a &lt; audioTracks.length; a++) {
      if (this._mediaStreamsStatus.audioMuted) {
        audioTracks[a].enabled = false;
      } else {
        audioTracks[a].enabled = true;
      }
    }
    // loop video tracks
    for (v = 0; v &lt; videoTracks.length; v++) {
      if (this._mediaStreamsStatus.videoMuted) {
        videoTracks[v].enabled = false;
      } else {
        videoTracks[v].enabled = true;
      }
    }
  }

  // Loop and enable tracks accordingly (mediaScreen)
  if (this._mediaScreen &amp;&amp; this._mediaScreen !== null) {
    audioTracks = this._mediaScreen.getAudioTracks();
    videoTracks = this._mediaScreen.getVideoTracks();

    hasAudioTracks = hasAudioTracks || audioTracks.length &gt; 0;
    hasVideoTracks = hasVideoTracks || videoTracks.length &gt; 0;

    // loop audio tracks
    for (a = 0; a &lt; audioTracks.length; a++) {
      if (this._mediaStreamsStatus.audioMuted) {
        audioTracks[a].enabled = false;
      } else {
        audioTracks[a].enabled = true;
      }
    }
    // loop video tracks
    for (v = 0; v &lt; videoTracks.length; v++) {
      if (this._mediaStreamsStatus.videoMuted) {
        videoTracks[v].enabled = false;
      } else {
        videoTracks[v].enabled = true;
      }
    }
  }

  // Loop and enable tracks accordingly (mediaScreenClone)
  if (this._mediaScreenClone &amp;&amp; this._mediaScreenClone !== null) {
    videoTracks = this._mediaScreen.getVideoTracks();

    hasVideoTracks = hasVideoTracks || videoTracks.length &gt; 0;

    // loop video tracks
    for (v = 0; v &lt; videoTracks.length; v++) {
      if (this._mediaStreamsStatus.videoMuted) {
        videoTracks[v].enabled = false;
      } else {
        videoTracks[v].enabled = true;
      }
    }
  }

  // update accordingly if failed
  if (!hasAudioTracks) {
    this._mediaStreamsStatus.audioMuted = true;
    this._streamSettings.audio = false;
  }
  if (!hasVideoTracks) {
    this._mediaStreamsStatus.videoMuted = true;
    this._streamSettings.video = false;
  }

  log.log(&#x27;Update to muted status -&gt;&#x27;, this._mediaStreamsStatus);

  return {
    hasAudioTracks: hasAudioTracks,
    hasVideoTracks: hasVideoTracks
  };
};

/**
 * Handles the stopping of audio and video streams.
 * @method _stopLocalMediaStreams
 * @param {Boolean|JSON} options The stop attached Stream options for
 *   Skylink when leaving the room.
 * @param {Boolean} [options.userMedia=false]  The flag that indicates if leaving the room
 *   should automatically stop and clear the existing user media stream attached to skylink.
 *   This would trigger &lt;code&gt;mediaAccessStopped&lt;/code&gt; for this Stream if available.
 * @param {Boolean} [options.screenshare=false] The flag that indicates if leaving the room
 *   should automatically stop and clear the existing screensharing stream attached to skylink.
 *   This would trigger &lt;code&gt;mediaAccessStopped&lt;/code&gt; for this Stream if available.
 * @private
 * @for Skylink
 * @since 0.6.3
 */
Skylink.prototype._stopLocalMediaStreams = function (options) {
  var stopUserMedia = false;
  var stopScreenshare = false;
  var triggerStopped = false;

  if (typeof options === &#x27;object&#x27;) {
    stopUserMedia = options.userMedia === true;
    stopScreenshare = options.screenshare === true;
  }

  var stopTracksFn = function (stream) {
    var audioTracks = stream.getAudioTracks();
    var videoTracks = stream.getVideoTracks();

    for (var i = 0; i &lt; audioTracks.length; i++) {
      audioTracks[i].stop();
    }

    for (var j = 0; j &lt; videoTracks.length; j++) {
      videoTracks[j].stop();
    }
  };

  var stopFn = function (stream, name) {
    if (window.webrtcDetectedBrowser === &#x27;chrome&#x27; &amp;&amp; window.webrtcDetectedVersion &gt; 44) {
      stopTracksFn(stream);
    } else {
      try {
        stream.stop();
      } catch (error) {
        log.warn(&#x27;Failed stopping MediaStreamTracks for &#x27; + name + &#x27;.&#x27; +
          &#x27; Stopping MediaStream instead&#x27;, error);
        stopTracksFn(stream);
      }
    }
  };

  if (stopScreenshare) {
    log.log([null, &#x27;MediaStream&#x27;, self._selectedRoom, &#x27;Stopping screensharing MediaStream&#x27;]);

    if (this._mediaScreen &amp;&amp; this._mediaScreen !== null) {
      stopFn(this._mediaScreen, &#x27;_mediaScreen&#x27;);
      this._mediaScreen = null;
      triggerStopped = true;
    }

    if (this._mediaScreenClone &amp;&amp; this._mediaScreenClone !== null) {
      stopFn(this._mediaScreenClone, &#x27;_mediaScreenClone&#x27;);
      this._mediaScreenClone = null;
    }

    if (triggerStopped) {
      this._trigger(&#x27;mediaAccessStopped&#x27;, true);
    }
  } else {
    log.log([null, &#x27;MediaStream&#x27;, self._selectedRoom, &#x27;Screensharing MediaStream will not be stopped&#x27;]);
  }

  if (stopUserMedia) {
    log.log([null, &#x27;MediaStream&#x27;, self._selectedRoom, &#x27;Stopping user\&#x27;s MediaStream&#x27;]);

    if (this._mediaStream &amp;&amp; this._mediaStream !== null) {
      stopFn(this._mediaStream, &#x27;_mediaStream&#x27;);
      this._mediaStream = null;
      triggerStopped = true;
    }

    if (triggerStopped) {
      this._trigger(&#x27;mediaAccessStopped&#x27;, false);
    }
  } else {
    log.log([null, &#x27;MediaStream&#x27;, self._selectedRoom, &#x27;User\&#x27;s MediaStream will not be stopped&#x27;]);
  }
};

/**
 * Waits for self MediaStream object to be attached to Skylink based
 *   on the options provided before firing the callback to indicate
 *   that self Stream object is received.
 * This will stop any currently attached Stream object to Skylink.
 * @method _waitForLocalMediaStream
 * @param {Function} callback The callback fired after self MediaStream object
 *   is attached to Skylink based on the options provided.
 * @param {Object} [callback.error=null] The callback error that is defined
 *   when there&#x27;s an error.
 * @param {Function} callback The callback fired after self MediaStream object
 *   is attached to Skylink based on the options provided successfully or met with
 *   an exception. The callback signature is &lt;code&gt;function (error)&lt;/code&gt;.
 * @param {Object} callback.error The error object received in the callback.
 *   If received as &lt;code&gt;undefined&lt;/code&gt;, it means that there is no errors.
 * @param {JSON} [options] The self Stream streaming settings. If both audio and video
 *   option is &lt;code&gt;false&lt;/code&gt;, there should be no audio and video stream
 *   sending from self connection.
 * @param {Boolean|JSON} [options.audio=false] The self Stream streaming audio settings.
 *   If &lt;code&gt;false&lt;/code&gt;, it means that audio streaming is disabled in
 *   the self Stream. If this option is set to &lt;code&gt;true&lt;/code&gt; or is defined with
 *   settings, {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}
 *   will be invoked. Self will not connect to the room unless the Stream audio
 *   user media access is given.
 * @param {Boolean} [options.audio.stereo=false] The flag that indicates if
 *   stereo should be enabled in self connection Stream
 *   audio streaming.
 * @param {Boolean} [options.audio.mute=false] The flag that
 *   indicates if the self Stream object audio streaming is muted.
 * @param {Boolean|JSON} [options.video=false] The self Stream streaming video settings.
 *   If &lt;code&gt;false&lt;/code&gt;, it means that video streaming is disabled in
 *   the self Stream. If this option is set to &lt;code&gt;true&lt;/code&gt; or is defined with
 *   settings, {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}
 *   will be invoked. Self will not connect to the room unless the Stream video
 *   user media access is given.
 * @param {Boolean} [options.video.mute=false] The flag that
 *   indicates if the self Stream object video streaming is muted.
 * @param {JSON} [options.video.resolution] The self Stream streaming video
 *   resolution settings. Setting the resolution may
 *   not force set the resolution provided as it depends on the how the
 *   browser handles the resolution. [Rel: Skylink.VIDEO_RESOLUTION]
 * @param {Number} [options.video.resolution.width] The self
 *   Stream streaming video resolution width.
 * @param {Number} [options.video.resolution.height] The self
 *   Stream streaming video resolution height.
 * @param {Number} [options.video.frameRate=50] The self
 *   Stream streaming video maximum frameRate.
 * @param {String} [options.bandwidth] The self
 *   streaming bandwidth settings. Setting the bandwidth flags may not
 *   force set the bandwidth for each connection stream channels as it depends
 *   on how the browser handles the bandwidth bitrate. Values are configured
 *   in &lt;var&gt;kb/s&lt;/var&gt;.
 * @param {String} [options.bandwidth.audio] The configured
 *   audio stream channel for the self Stream object bandwidth
 *   that audio streaming should use in &lt;var&gt;kb/s&lt;/var&gt;.
 * @param {String} [options.bandwidth.video] The configured
 *   video stream channel for the self Stream object bandwidth
 *   that video streaming should use in &lt;var&gt;kb/s&lt;/var&gt;.
 * @param {String} [options.bandwidth.data] The configured
 *   datachannel channel for the DataChannel connection bandwidth
 *   that datachannel connection per packet should be able use in &lt;var&gt;kb/s&lt;/var&gt;.
 * @trigger mediaAccessSuccess, mediaAccessError, mediaAccessRequired
 * @private
 * @component Stream
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._waitForLocalMediaStream = function(callback, options) {
  var self = this;
  options = options || {};

  // get the stream
  if (options.manualGetUserMedia === true) {
    self._trigger(&#x27;mediaAccessRequired&#x27;);
  }
  // If options video or audio false, do the opposite to throw a true.
  var requireAudio = !!options.audio;
  var requireVideo = !!options.video;

  log.log(&#x27;Requested audio:&#x27;, requireAudio);
  log.log(&#x27;Requested video:&#x27;, requireVideo);

  // check if it requires audio or video
  if (!requireAudio &amp;&amp; !requireVideo &amp;&amp; !options.manualGetUserMedia) {
    // set to default
    if (options.audio === false &amp;&amp; options.video === false) {
      self._parseMediaStreamSettings(options);
    }

    callback(null);
    return;
  }

  // get the user media
  if (!options.manualGetUserMedia &amp;&amp; (options.audio || options.video)) {
    self.getUserMedia({
      audio: options.audio,
      video: options.video

    }, function (error, success) {
      if (error) {
        callback(error);
      } else {
        callback(null, success);
      }
    });
  }

  // clear previous mediastreams
  self.stopStream();

  if (options.manualGetUserMedia === true) {
    var current50Block = 0;
    var mediaAccessRequiredFailure = false;
    // wait for available audio or video stream
    self._wait(function () {
      if (mediaAccessRequiredFailure === true) {
        self._onUserMediaError(new Error(&#x27;Waiting for stream timeout&#x27;), false, false);
      } else {
        callback(null, self._mediaStream);
      }
    }, function () {
      current50Block += 1;
      if (current50Block === 600) {
        mediaAccessRequiredFailure = true;
        return true;
      }

      if (self._mediaStream &amp;&amp; self._mediaStream !== null) {
        return true;
      }
    }, 50);
  }
};



/**
 * Gets self user media Stream object to attach to Skylink.
 * Do not invoke this function when user has already joined a room as
 *   this may affect any currently attached stream. You may use
 *  {{#crossLink &quot;Skylink/sendStream:method&quot;}}sendStream(){{/crossLink}}
 *  instead if self is already in the room, and allows application to
 *  attach application own MediaStream object to Skylink.
 * @method getUserMedia
 * @param {JSON} [options] The self Stream streaming settings for the new Stream
 *   object attached to Skylink. If this parameter is not provided, the
 *   options value would be &lt;code&gt;{ audio: true, video: true }&lt;/code&gt;.
 * @param {Boolean|JSON} [options.audio=false] The self Stream streaming audio settings.
 *   If &lt;code&gt;false&lt;/code&gt;, it means that audio streaming is disabled in
 *   the self Stream. If this option is set to &lt;code&gt;true&lt;/code&gt; or is defined with
 *   settings, {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}
 *   will be invoked. Self will not connect to the room unless the Stream audio
 *   user media access is given.
 * @param {Boolean} [options.audio.stereo=false] The flag that indicates if
 *   stereo should be enabled in self connection Stream
 *   audio streaming.
 * @param {Boolean} [options.audio.mute=false] The flag that
 *   indicates if the self Stream object audio streaming is muted.
 * @param {Array} [options.audio.optional] The optional constraints for audio streaming
 *   in self user media Stream object. This follows the &lt;code&gt;optional&lt;/code&gt;
 *   setting in the &lt;code&gt;MediaStreamConstraints&lt;/code&gt; when &lt;code&gt;getUserMedia()&lt;/code&gt; is invoked.
 *   Tampering this may cause errors in retrieval of self user media Stream object.
 *   Refer to this [site for more reference](http://www.sitepoint.com/introduction-getusermedia-api/).
 * @param {Boolean|JSON} [options.video=false] The self Stream streaming video settings.
 *   If &lt;code&gt;false&lt;/code&gt;, it means that video streaming is disabled in
 *   the self Stream. If this option is set to &lt;code&gt;true&lt;/code&gt; or is defined with
 *   settings, {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}
 *   will be invoked. Self will not connect to the room unless the Stream video
 *   user media access is given.
 * @param {Boolean} [options.video.mute=false] The flag that
 *   indicates if the self Stream object video streaming is muted.
 * @param {JSON} [options.video.resolution] The self Stream streaming video
 *   resolution settings. Setting the resolution may
 *   not force set the resolution provided as it depends on the how the
 *   browser handles the resolution. [Rel: Skylink.VIDEO_RESOLUTION]
 * @param {Number} [options.video.resolution.width] The self
 *   Stream streaming video resolution width.
 *   &lt;i&gt;This sets the &lt;code&gt;maxWidth&lt;/code&gt; of the &lt;code&gt;video&lt;/code&gt;
 *   constraints passed in &lt;code&gt;getUserMedia()&lt;/code&gt;&lt;/i&gt;.
 * @param {Number} [options.video.resolution.height] The self
 *   Stream streaming video resolution height.
 *   &lt;i&gt;This sets the &lt;code&gt;maxHeight&lt;/code&gt; of the &lt;code&gt;video&lt;/code&gt;
 *   constraints passed in &lt;code&gt;getUserMedia()&lt;/code&gt;&lt;/i&gt;.
 * @param {Number} [options.video.frameRate=50] The self
 *   Stream streaming video maximum frameRate.
 *   &lt;i&gt;This sets the &lt;code&gt;maxFramerate&lt;/code&gt; of the &lt;code&gt;video&lt;/code&gt;
 *   constraints passed in &lt;code&gt;getUserMedia()&lt;/code&gt;&lt;/i&gt;.
 * @param {Array} [options.video.optional] The optional constraints for video streaming
 *   in self user media Stream object. This follows the &lt;code&gt;optional&lt;/code&gt;
 *   setting in the &lt;code&gt;MediaStreamConstraints&lt;/code&gt; when &lt;code&gt;getUserMedia()&lt;/code&gt; is invoked.
 *   Tampering this may cause errors in retrieval of self user media Stream object.
 *   Refer to this [site for more reference](http://www.sitepoint.com/introduction-getusermedia-api/).
 * @param {Function} [callback] The callback fired after Skylink has gained
 *   access to self media stream and attached it successfully with the provided
 *   media settings or have met with an exception.
 *   The callback signature is &lt;code&gt;function (error, success)&lt;/code&gt;.
 * @param {Object} callback.error The error object received in the callback.
 *   This is the exception thrown that caused the failure for getting self user media.
 *   If received as &lt;code&gt;null&lt;/code&gt;, it means that there is no errors.
 * @param {Object} callback.success The success object received in the callback.
 *   The self user media [MediaStream](https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_API)
 *   object. To display the MediaStream object to a &lt;code&gt;video&lt;/code&gt; or &lt;code&gt;audio&lt;/code&gt;, simply invoke:&lt;br&gt;
 *   &lt;code&gt;attachMediaStream(domElement, stream);&lt;/code&gt;.
 *   If received as &lt;code&gt;null&lt;/code&gt;, it means that there are errors.
 * @example
 *   // Default is to get both audio and video
 *   // Example 1: Get both audio and video by default.
 *   SkylinkDemo.getUserMedia();
 *
 *   // Example 2: Get the audio stream only
 *   SkylinkDemo.getUserMedia({
 *     video: false,
 *     audio: true
 *   });
 *
 *   // Example 3: Set the stream settings for the audio and video
 *   SkylinkDemo.getUserMedia({
 *     video: {
 *        resolution: SkylinkDemo.VIDEO_RESOLUTION.HD,
 *        frameRate: 50
 *      },
 *     audio: {
 *       stereo: true
 *     }
 *   });
 *
 *   // Example 4: Get user media with callback
 *   SkylinkDemo.getUserMedia({
 *     video: false,
 *     audio: true
 *   },function(error,success){
 *      if (error){
 *        console.log(error);
 *      }
 *      else{
 *        console.log(success);
 *     }
 *   });
 * @trigger mediaAccessSuccess, mediaAccessError
 * @component Stream
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype.getUserMedia = function(options,callback) {
  var self = this;

  var errorMsg; // j-shint rocks

  if (typeof options === &#x27;function&#x27;){
    callback = options;
    options = {
      audio: true,
      video: true
    };
  }
  else if (typeof options !== &#x27;object&#x27; || options === null) {
    if (typeof options === &#x27;undefined&#x27;) {
      options = {
        audio: true,
        video: true
      };
    } else {
      errorMsg = &#x27;Please provide a valid options&#x27;;
      log.error(errorMsg, options);
      if (typeof callback === &#x27;function&#x27;) {
        callback(new Error(errorMsg), null);
      }
      return;
    }
  }
  else if (!options.audio &amp;&amp; !options.video) {
    errorMsg = &#x27;Please select audio or video&#x27;;
    log.error(errorMsg, options);
    if (typeof callback === &#x27;function&#x27;) {
      callback(new Error(errorMsg), null);
    }
    return;
  }

  if (window.location.protocol !== &#x27;https:&#x27; &amp;&amp; window.webrtcDetectedBrowser === &#x27;chrome&#x27; &amp;&amp;
    window.webrtcDetectedVersion &gt; 46) {
    errorMsg = &#x27;getUserMedia() has to be called in https:// application&#x27;;
    log.error(errorMsg, options);
    if (typeof callback === &#x27;function&#x27;) {
      callback(new Error(errorMsg), null);
    }
    return;
  }

  // parse stream settings
  self._parseMediaStreamSettings(options);

  // if audio and video is false, do not call getUserMedia
  if (!(options.audio === false &amp;&amp; options.video === false)) {
    // clear previous mediastreams
    self.stopStream();

    setTimeout(function () {
      try {
        if (typeof callback === &#x27;function&#x27;){
          var mediaAccessErrorFn = function (error) {
            callback(error, null);
            self.off(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn);
          };

          var mediaAccessSuccessFn = function (stream) {
            callback(null, stream);
            self.off(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn);
          };

          self.once(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn);
          self.once(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn);
        }

        window.getUserMedia(self._getUserMediaSettings, function (stream) {
          var isSuccess = false;
          var requireAudio = !!options.audio;
          var requireVideo = !!options.video;
          var hasAudio = !requireAudio;
          var hasVideo = !requireVideo;

          // for now we require one MediaStream with both audio and video
          // due to firefox non-supported audio or video
          if (stream &amp;&amp; stream !== null) {
            var notSameTracksError = new Error(
              &#x27;Expected audio tracks length with &#x27; +
              (requireAudio ? &#x27;1&#x27; : &#x27;0&#x27;) + &#x27; and video tracks length with &#x27; +
              (requireVideo ? &#x27;1&#x27; : &#x27;0&#x27;) + &#x27; but received audio tracks length &#x27; +
              &#x27;with &#x27; + stream.getAudioTracks().length + &#x27; and video &#x27; +
              &#x27;tracks length with &#x27; + stream.getVideoTracks().length);

            // do the check
            if (requireAudio) {
              hasAudio = stream.getAudioTracks().length &gt; 0;
            }
            if (requireVideo) {
              hasVideo =  stream.getVideoTracks().length &gt; 0;

              if (self._audioFallback &amp;&amp; !hasVideo) {
                hasVideo = true; // to trick isSuccess to be true
                self._trigger(&#x27;mediaAccessFallback&#x27;, notSameTracksError);
              }
            }
            if (hasAudio &amp;&amp; hasVideo) {
              isSuccess = true;
            }

            if (isSuccess) {
              self._onUserMediaSuccess(stream);
            } else {
              self._onUserMediaError(notSameTracksError, false, false);
            }
          }
        }, function (error) {
          self._onUserMediaError(error, false, true);
        });
      } catch (error) {
        self._onUserMediaError(error, false, true);
      }
    }, window.webrtcDetectedBrowser === &#x27;firefox&#x27; ? 500 : 1);
  } else {
    log.warn([null, &#x27;MediaStream&#x27;, null, &#x27;Not retrieving stream&#x27;]);
  }
};

/**
 * Replaces the currently attached Stream object in Skylink and refreshes all
 *   connection with Peer connections to send the updated Stream object.
 * The application may provide their own MediaStream object to send to
 *   all PeerConnections connection.
 * Reference {{#crossLink &quot;Skylink/refreshConnection:method&quot;}}refreshConnection(){{/crossLink}}
 *    on the events triggered and restart mechanism.
 * @method sendStream
 * @param {Object|JSON} options The self Stream streaming settings for the new Stream
 *   object to replace the current Stream object attached to Skylink.
 *   If this parameter is provided as a MediaStream object, the
 *   MediaStream object settings for &lt;code&gt;mediaStatus&lt;/code&gt; would be
 *   detected as unmuted by default.
 * @param {Boolean|JSON} [options.audio=false] The self Stream streaming audio settings.
 *   If &lt;code&gt;false&lt;/code&gt;, it means that audio streaming is disabled in
 *   the self Stream. If this option is set to &lt;code&gt;true&lt;/code&gt; or is defined with
 *   settings, {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}
 *   will be invoked. Self will not connect to the room unless the Stream audio
 *   user media access is given.
 * @param {Boolean} [options.audio.stereo=false] The flag that indicates if
 *   stereo should be enabled in self connection Stream
 *   audio streaming.
 * @param {Boolean} [options.audio.mute=false] The flag that
 *   indicates if the self Stream object audio streaming is muted.
 * @param {Boolean|JSON} [options.video=false] The self Stream streaming video settings.
 *   If &lt;code&gt;false&lt;/code&gt;, it means that video streaming is disabled in
 *   the self Stream. If this option is set to &lt;code&gt;true&lt;/code&gt; or is defined with
 *   settings, {{#crossLink &quot;Skylink/getUserMedia:method&quot;}}getUserMedia(){{/crossLink}}
 *   will be invoked. Self will not connect to the room unless the Stream video
 *   user media access is given.
 * @param {Array} [options.audio.optional] The optional constraints for audio streaming
 *   in self user media Stream object. This follows the &lt;code&gt;optional&lt;/code&gt;
 *   setting in the &lt;code&gt;MediaStreamConstraints&lt;/code&gt; when &lt;code&gt;getUserMedia()&lt;/code&gt; is invoked.
 *   Tampering this may cause errors in retrieval of self user media Stream object.
 *   Refer to this [site for more reference](http://www.sitepoint.com/introduction-getusermedia-api/).
 * @param {Boolean} [options.video.mute=false] The flag that
 *   indicates if the self Stream object video streaming is muted.
 * @param {JSON} [options.video.resolution] The self Stream streaming video
 *   resolution settings. Setting the resolution may
 *   not force set the resolution provided as it depends on the how the
 *   browser handles the resolution. [Rel: Skylink.VIDEO_RESOLUTION]
 * @param {Number} [options.video.resolution.width] The self
 *   Stream streaming video resolution width.
 * @param {Number} [options.video.resolution.height] The self
 *   Stream streaming video resolution height.
 * @param {Number} [options.video.frameRate=50] The self
 *   Stream streaming video maximum frameRate.
 * @param {Array} [options.video.optional] The optional constraints for video streaming
 *   in self user media Stream object. This follows the &lt;code&gt;optional&lt;/code&gt;
 *   setting in the &lt;code&gt;MediaStreamConstraints&lt;/code&gt; when &lt;code&gt;getUserMedia()&lt;/code&gt; is invoked.
 *   Tampering this may cause errors in retrieval of self user media Stream object.
 *   Refer to this [site for more reference](http://www.sitepoint.com/introduction-getusermedia-api/).
 * @param {Function} [callback] The callback fired after Skylink has replaced
 *   the current Stream object successfully with the provided
 *   media settings / MediaStream object or have met with an exception.
 *   The callback signature is &lt;code&gt;function (error, success)&lt;/code&gt;.
 * @param {Object} callback.error The error object received in the callback.
 *   This is the exception thrown that caused the failure for replacing the current
 *   Stream object. If received as &lt;code&gt;null&lt;/code&gt;, it means that there is no errors.
 * @param {Object} callback.success The success object received in the callback.
 *   The self user media [MediaStream](https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_API)
 *   object. To display the MediaStream object to a &lt;code&gt;video&lt;/code&gt; or &lt;code&gt;audio&lt;/code&gt;, simply invoke:&lt;br&gt;
 *   &lt;code&gt;attachMediaStream(domElement, stream);&lt;/code&gt;.
 *   If received as &lt;code&gt;null&lt;/code&gt;, it means that there are errors.
 * @example
 *   // Example 1: Send a stream object instead
 *   SkylinkDemo.on(&#x27;mediaAccessSuccess&#x27;, function (stream) {
 *     SkylinkDemo.sendStream(stream);
 *   });
 *
 *   // Example 2: Send stream with getUserMedia automatically called for you
 *   SkylinkDemo.sendStream({
 *     audio: true,
 *     video: false
 *   });
 *
 *   // Example 3: Send stream with getUserMedia automatically called for you
 *   // and audio is muted
 *   SkylinkDemo.sendStream({
 *     audio: { mute: true },
 *     video: false
 *   });
 *
 *   // Example 4: Send stream with callback
 *   SkylinkDemo.sendStream({
 *    audio: true,
 *    video: true
 *   },function(error,success){
 *    if (error){
 *      console.log(&#x27;Error occurred. Stream was not sent: &#x27;+error)
 *    }
 *    else{
 *      console.log(&#x27;Stream successfully sent: &#x27;+success);
 *    }
 *   });
 *
 * @trigger peerRestart, serverPeerRestart, incomingStream
 * @component Stream
 * @for Skylink
 * @since 0.5.6
 */

Skylink.prototype.sendStream = function(stream, callback) {
  var self = this;
  var restartCount = 0;
  var peerCount = Object.keys(self._peerConnections).length;

  if (typeof stream !== &#x27;object&#x27; || stream === null) {
    var error = &#x27;Provided stream settings is invalid&#x27;;
    log.error(error, stream);
    if (typeof callback === &#x27;function&#x27;){
      callback(new Error(error),null);
    }
    return;
  }

  var hasNoPeers = Object.keys(self._peerConnections).length === 0;

  // Stream object
  // getAudioTracks or getVideoTracks first because adapterjs
  // has not implemeneted MediaStream as an interface
  // interopability with firefox and chrome
  //MediaStream = MediaStream || webkitMediaStream;
  // NOTE: eventually we should do instanceof
  if (typeof stream.getAudioTracks === &#x27;function&#x27; ||
    typeof stream.getVideoTracks === &#x27;function&#x27;) {
    // stop playback
    self.stopStream();

    self._streamSettings.audio = stream.getAudioTracks().length &gt; 0;
    self._streamSettings.video = stream.getVideoTracks().length &gt; 0;

    self._mediaStreamsStatus.audioMuted = self._streamSettings.audio === false;
    self._mediaStreamsStatus.videoMuted = self._streamSettings.video === false;

    if (self._inRoom) {
      self.once(&#x27;mediaAccessSuccess&#x27;, function (stream) {
        if (self._hasMCU) {
          self._restartMCUConnection();
        } else {
          self._trigger(&#x27;incomingStream&#x27;, self._user.sid, self._mediaStream,
            true, self.getPeerInfo(), false);
          for (var peer in self._peerConnections) {
            if (self._peerConnections.hasOwnProperty(peer)) {
              self._restartPeerConnection(peer, true, false, null, true);
            }
          }
        }

        self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
      });
    }

    // send the stream
    if (self._mediaStream !== stream) {
      self._onUserMediaSuccess(stream);
    }

    // The callback is provided and has peers, so require to wait for restart
    if (typeof callback === &#x27;function&#x27; &amp;&amp; !hasNoPeers) {
      self.once(&#x27;peerRestart&#x27;,function(peerId, peerInfo, isSelfInitiatedRestart){
        log.log([null, &#x27;MediaStream&#x27;, stream.id,
          &#x27;Stream was sent. Firing callback&#x27;], stream);
        callback(null,stream);
        restartCount = 0; //reset counter
      },function(peerId, peerInfo, isSelfInitiatedRestart){
        if (isSelfInitiatedRestart){
          restartCount++;
          if (restartCount === peerCount){
            return true;
          }
        }
        return false;
      },false);
    }

    // The callback is provided but there is no peers, so automatically invoke the callback
    if (typeof callback === &#x27;function&#x27; &amp;&amp; hasNoPeers) {
      callback(null, self._mediaStream);
    }

  // Options object
  } else {
    // The callback is provided but there is peers, so require to wait for restart
    if (typeof callback === &#x27;function&#x27; &amp;&amp; !hasNoPeers) {
      self.once(&#x27;peerRestart&#x27;,function(peerId, peerInfo, isSelfInitiatedRestart){
        log.log([null, &#x27;MediaStream&#x27;, stream.id,
          &#x27;Stream was sent. Firing callback&#x27;], stream);
        callback(null,stream);
        restartCount = 0; //reset counter
      },function(peerId, peerInfo, isSelfInitiatedRestart){
        if (isSelfInitiatedRestart){
          restartCount++;
          if (restartCount === peerCount){
            return true;
          }
        }
        return false;
      },false);
    }

    if (self._inRoom) {
      self.once(&#x27;mediaAccessSuccess&#x27;, function (stream) {
        if (self._hasMCU) {
          self._restartMCUConnection();
        } else {
          self._trigger(&#x27;incomingStream&#x27;, self._user.sid, self._mediaStream,
            true, self.getPeerInfo(), false);
          for (var peer in self._peerConnections) {
            if (self._peerConnections.hasOwnProperty(peer)) {
              self._restartPeerConnection(peer, true, false, null, true);
            }
          }
        }

        self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
      });
    }

    // get the mediastream and then wait for it to be retrieved before sending
    self._waitForLocalMediaStream(function (error) {
      if (!error) {
        // The callback is provided but there is not peers, so automatically invoke the callback
        if (typeof callback === &#x27;function&#x27; &amp;&amp; hasNoPeers) {
          callback(null, self._mediaStream);
        }
      } else {
        callback(error, null);
      }
    }, stream);
  }
};

/**
 * Mutes the currently attached Stream object in Skylink.
 * @method muteStream
 * @param {JSON} options The self Stream streaming muted settings.
 * @param {Boolean} [options.audioMuted=true]  The flag that
 *   indicates if self connection Stream object audio streaming is muted. If
 *   there is no audio streaming enabled for self connection, by default,
 *   it is set to &lt;code&gt;true&lt;/code&gt;.
 * @param {Boolean} [options.videoMuted=true] The flag that
 *   indicates if self connection Stream object video streaming is muted. If
 *   there is no video streaming enabled for self connection, by default,
 *   it is set to &lt;code&gt;true&lt;/code&gt;.
 * @example
 *   SkylinkDemo.muteStream({
 *     audioMuted: true,
 *     videoMuted: false
 *   });
 * @trigger streamMuted, peerUpdated
 * @component Stream
 * @for Skylink
 * @since 0.5.7
 */
Skylink.prototype.muteStream = function(options) {
  var self = this;
  var hasAudioError = false;
  var hasVideoError = false;

  if (typeof options !== &#x27;object&#x27;) {
    log.error(&#x27;Provided settings is not an object&#x27;);
    return;
  }

  if ((!self._mediaStream || self._mediaStream === null) &amp;&amp;
    (!self._mediaScreen || self._mediaScreen === null)) {
    log.warn(&#x27;No streams are available to mute / unmute!&#x27;);
    return;
  }

  // set the muted status
  if (typeof options.audioMuted === &#x27;boolean&#x27;) {
    if (self._streamSettings.audio === false) {
      log.error(&#x27;No audio available to mute / unmute&#x27;);
      hasAudioError = true;
    } else {
      if (options.audioMuted) {
        self._mediaStreamsStatus.audioMuted = true;
      } else {
        self._mediaStreamsStatus.audioMuted = false;
      }
    }
  }
  if (typeof options.videoMuted === &#x27;boolean&#x27;) {
    if (self._streamSettings.video === false) {
      log.error(&#x27;No video available to mute / unmute&#x27;);
      hasVideoError = true;
    } else {
      if (options.videoMuted) {
        self._mediaStreamsStatus.videoMuted = true;
      } else {
        self._mediaStreamsStatus.videoMuted = false;
      }
    }
  }

  var hasTracksOption = self._muteLocalMediaStreams();

  if (self._inRoom) {
    // update to mute status of video tracks
    if (hasTracksOption.hasVideoTracks) {
      // send message
      self._sendChannelMessage({
        type: self._SIG_MESSAGE_TYPE.MUTE_VIDEO,
        mid: self._user.sid,
        rid: self._room.id,
        muted: self._mediaStreamsStatus.videoMuted
      });
    }
    // update to mute status of audio tracks
    if (hasTracksOption.hasAudioTracks) {
      // send message
      // set timeout to do a wait interval of 1s
      setTimeout(function () {
        self._sendChannelMessage({
          type: self._SIG_MESSAGE_TYPE.MUTE_AUDIO,
          mid: self._user.sid,
          rid: self._room.id,
          muted: self._mediaStreamsStatus.audioMuted
        });
      }, 1050);
    }

    if (!hasAudioError || !hasVideoError) {
      self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
    }
  }

  if (!hasAudioError || !hasVideoError) {
    self._trigger(&#x27;streamMuted&#x27;, self._user.sid || null, self.getPeerInfo(), true,
      !!self._mediaScreen &amp;&amp; self._mediaScreen !== null);
  }
};

/**
 * Unmutes the currently attached Stream object audio stream.
 * @method enableAudio
 * @trigger peerUpdated
 * @deprecated Use .muteStream()
 * @example
 *   SkylinkDemo.enableAudio();
 * @trigger streamMuted, peerUpdated
 * @component Stream
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.enableAudio = function() {
  this.muteStream({
    audioMuted: false
  });
};

/**
 * Mutes the currently attached Stream object audio stream.
 * @method disableAudio
 * @deprecated Use .muteStream()
 * @example
 *   SkylinkDemo.disableAudio();
 * @trigger peerUpdated
 * @trigger streamMuted, peerUpdated
 * @component Stream
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.disableAudio = function() {
  this.muteStream({
    audioMuted: true
  });
};

/**
 * Unmutes the currently attached Stream object video stream.
 * @method enableVideo
 * @deprecated Use .muteStream()
 * @example
 *   SkylinkDemo.enableVideo();
 * @trigger peerUpdated
 * @trigger streamMuted, peerUpdated
 * @component Stream
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.enableVideo = function() {
  this.muteStream({
    videoMuted: false
  });
};

/**
 * Mutes the currently attached Stream object video stream.
 * @method disableVideo
 * @depcreated Use .muteStream()
 * @example
 *   SkylinkDemo.disableVideo();
 * @trigger streamMuted, peerUpdated
 * @component Stream
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.disableVideo = function() {
  this.muteStream({
    videoMuted: true
  });
};

/**
 * Shares the current screen with Peer connections and will refresh all
 *    Peer connections to send the screensharing Stream object with
 *    &lt;code&gt;HTTPS&lt;/code&gt; protocol accessing application.
 * Reference {{#crossLink &quot;Skylink/refreshConnection:method&quot;}}refreshConnection(){{/crossLink}}
 *    on the events triggered and restart mechanism.
 * This will require our own Temasys Skylink extension to do screensharing.
 * For screensharing feature in IE / Safari with our Temasys Plugin, please
 *   [contact us](https://www.temasys.com.sg/contact-us).
 * Currently, Opera does not support screensharing feature.
 * This does not replace the currently attached user media Stream object in Skylink.
 * @method shareScreen
 * @param {JSON} [enableAudio=false] The flag that indicates if self screensharing
 *   Stream streaming should have audio. If
 *   &lt;code&gt;false&lt;/code&gt;, it means that audio streaming is disabled in
 *   the remote Stream of self connection.
 * @param {Function} [callback] The callback fired after Skylink has shared
 *   the screen successfully or have met with an exception.
 *   The callback signature is &lt;code&gt;function (error, success)&lt;/code&gt;.
 * @param {Object} callback.error The error object received in the callback.
 *   This is the exception thrown that caused the failure for sharing the screen.
 *   If received as &lt;code&gt;null&lt;/code&gt;, it means that there is no errors.
 * @param {Object} callback.success The success object received in the callback.
 *   The self screensharing [MediaStream](https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_API)
 *   object. To display the MediaStream object to a &lt;code&gt;video&lt;/code&gt; or &lt;code&gt;audio&lt;/code&gt;, simply invoke:&lt;br&gt;
 *   &lt;code&gt;attachMediaStream(domElement, stream);&lt;/code&gt;.
 *   If received as &lt;code&gt;null&lt;/code&gt;, it means that there are errors.
 * @example
 *   // Example 1: Share the screen
 *   SkylinkDemo.shareScreen();
 *
 *   // Example 2: Share screen with callback when screen is ready and shared
 *   SkylinkDemo.shareScreen(function(error,success){
 *      if (error){
 *        console.log(error);
 *      }
 *      else{
 *        console.log(success);
 *     }
 *   });
 * @trigger mediaAccessSuccess, mediaAccessError, incomingStream, peerRestart, serverPeerRestart, peerUpdated
 * @component Stream
 * @for Skylink
 * @since 0.6.0
 */
Skylink.prototype.shareScreen = function (enableAudio, callback) {
  var self = this;
  var hasAudio = false;

  var settings = {
    video: {
      mediaSource: &#x27;window&#x27;
    }
  };

  if (typeof enableAudio === &#x27;function&#x27;) {
    callback = enableAudio;
    enableAudio = true;
  }

  if (typeof enableAudio !== &#x27;boolean&#x27;) {
    enableAudio = true;
  }

  var triggerSuccessFn = function (sStream) {
    if (hasAudio) {
      if (typeof self._streamSettings.audio === &#x27;object&#x27;) {
        self._screenSharingStreamSettings.audio = {
          stereo: !!self._streamSettings.audio.stereo
        };
      } else {
        self._screenSharingStreamSettings.audio = true;
      }
    } else {
      log.warn(&#x27;This screensharing session will not support audio streaming&#x27;);
      self._screenSharingStreamSettings.audio = false;
    }
    self._onUserMediaSuccess(sStream, true);
  };

  if (window.webrtcDetectedBrowser === &#x27;firefox&#x27;) {
    settings.audio = !!enableAudio;
  }

  try {
    window.getUserMedia(settings, function (stream) {
      self.once(&#x27;mediaAccessSuccess&#x27;, function (stream) {
        if (self._inRoom) {
          if (self._hasMCU) {
            self._restartMCUConnection();
          } else {
            self._trigger(&#x27;incomingStream&#x27;, self._user.sid, self._mediaStream,
              true, self.getPeerInfo(), false);
            for (var peer in self._peerConnections) {
              if (self._peerConnections.hasOwnProperty(peer)) {
                self._restartPeerConnection(peer, true, false, null, true);
              }
            }
          }
        } else if (typeof callback === &#x27;function&#x27;) {
          callback(null, stream);
        }
      });

      if (window.webrtcDetectedBrowser !== &#x27;firefox&#x27; &amp;&amp; enableAudio) {
        window.getUserMedia({
          audio: true
        }, function (audioStream) {
          try {
            audioStream.addTrack(stream.getVideoTracks()[0]);
            self._mediaScreenClone = stream;
            hasAudio = true;
            triggerSuccessFn(audioStream, true);

          } catch (error) {
            log.error(&#x27;Failed retrieving audio stream for screensharing stream&#x27;, error);
            triggerSuccessFn(stream, true);
          }

        }, function (error) {
          log.error(&#x27;Failed retrieving audio stream for screensharing stream&#x27;, error);
          triggerSuccessFn(stream, true);
        });
      } else {
        hasAudio = window.webrtcDetectedBrowser === &#x27;firefox&#x27; ? enableAudio : false;
        triggerSuccessFn(stream, true);
      }

    }, function (error) {
      self._onUserMediaError(error, true, false);

      if (typeof callback === &#x27;function&#x27;) {
        callback(error, null);
      }
    });

  } catch (error) {
    self._onUserMediaError(error, true, false);

    if (typeof callback === &#x27;function&#x27;) {
      callback(error, null);
    }
  }
};

/**
 * Stops self screensharing Stream object attached to Skylink.
 * If user media Stream object is available, Skylink will refresh all
 *    Peer connections to send the user media Stream object.
 * Reference {{#crossLink &quot;Skylink/refreshConnection:method&quot;}}refreshConnection(){{/crossLink}}
 *    on the events triggered and restart mechanism.
 * @method stopScreen
 * @example
 *   SkylinkDemo.stopScreen();
 * @trigger mediaAccessStopped, streamEnded, incomingStream, peerRestart, serverPeerRestart
 * @for Skylink
 * @since 0.6.0
 */
Skylink.prototype.stopScreen = function () {
  var endSession = false;

  if (this._mediaScreen &amp;&amp; this._mediaScreen !== null) {
    endSession = !!this._mediaScreen.endSession;

    this._stopLocalMediaStreams({
      screenshare: true
    });

    if (!endSession) {
      if (this._hasMCU) {
        this._restartMCUConnection();
      } else {
        if (!!this._mediaStream &amp;&amp; this._mediaStream !== null) {
          this._trigger(&#x27;incomingStream&#x27;, this._user.sid, this._mediaStream, true,
            this.getPeerInfo(), false);
        }
        for (var peer in this._peerConnections) {
          if (this._peerConnections.hasOwnProperty(peer)) {
            this._restartPeerConnection(peer, true, false, null, true);
          }
        }
      }
    }
  }
};
    </pre>
</div>

                  </div>
              </div>
          </div>
      </div>
  </div>
</div>
<script src="../assets/vendor/prettify/prettify-min.js"></script>
<script>prettyPrint();</script>
<script src="../assets/js/yui-prettify.js"></script>
<script src="../assets/../api.js"></script>
<script src="../assets/js/api-filter.js"></script>
<script src="../assets/js/api-list.js"></script>
<script src="../assets/js/api-search.js"></script>
<script src="../assets/js/apidocs.js"></script>
</body>
</html>
