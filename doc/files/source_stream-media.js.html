<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Temasys Documentation - SkylinkJS 0.9.2 - Web SDK</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- font and icon -->
    <link rel="shortcut icon" type="image/ico" href="../assets/favicon.ico">
    <link rel="stylesheet" href="../assets/vendor/prettify/prettify-min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600,700|Source+Sans+Pro" type="text/css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600,700|Source+Code+Pro" type="text/css">
    <!-- styling -->
    <link rel="stylesheet" href="../assets/vendor/css/bootstrap.min.css">
    <link rel="stylesheet" href="../assets/vendor/css/bootstrap-theme.min.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="../assets/css/style.css">
    <!-- scripts -->
    <script src="../assets/vendor/js/jquery.min.js"></script>
    <script src="../assets/vendor/js/bootstrap.min.js"></script>
    <script src="../assets/js/script.js"></script>
    <script src="http://yui.yahooapis.com/combo?3.9.1/build/yui/yui-min.js"></script>
</head>
<body>

<div id="doc">
  <nav id="hd" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a href="" class="navbar-brand">
          <img src="../assets/img/logo.svg" /><small>Version: 0.9.2</small>
        </a>
      </div>
      <div id="navbar" class="navbar-collapse collapse">
        <ul id="api-list" class="nav navbar-nav navbar-right">
  <li class="dropdown">
    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Getting Started Examples <span class="caret"></span></a>
    <ul class="dropdown-menu" role="menu">
      <li><a href="https://temasys.io/getting-started-with-webrtc-and-skylinkjs/">Setting up a Video Call</a></li>
      <li><a href="https://temasys.io/screensharing-with-skylinkjs/">Setting up Screensharing</a></li>
      <li><a href="https://temasys.io/building-a-simple-peer-to-peer-webrtc-chat/">Setting up a Chatroom</a></li>
    </ul>
  </li>
  
    <li><a href="../classes/Skylink.html">Documentation</a></li>
  
  <!--<li class="dropdown">
    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Classes <span class="caret"></span></a>
    <ul class="dropdown-menu" role="menu">
      
        <li><a href="../classes/Skylink.html">Skylink</a></li>
      
    </ul>
  </li>-->
  <li><a class="btn btn-info btn-navbar" href="https://console.temasys.io/">Developer Console</a></li>
  <li><a class="btn btn-info btn-navbar" href="http://support.temasys.io/">Support</a></li>
  <!--<li class="dropdown">
    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Modules <span class="caret"></span></a>
    <ul class="dropdown-menu" role="menu">
      <li><a href="#api-modules">View all Modules</a></li>
      
    </ul>
  </li>-->
</ul>
<!--<form id="api-tabview" class="navbar-form navbar-right" role="form">
  <div id="api-tabview-filter" class="form-group">
    <input type="search" id="api-filter" placeholder="Type to filter APIs">
  </div>
</form>-->
      </div><!--/.navbar-collapse -->
    </div>
  </nav>
  <div id="bd" class="yui3-g">

      <div class="yui3-u-1-4">

      </div>
      <div class="yui3-u-3-4">
          
          <div class="apidocs">
              <div id="docs-main">
                  <div class="content content-main">
                      <h1 class="file-heading">File: source/stream-media.js</h1>

<div class="file">
    <pre class="code prettyprint linenums">
/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   For a better user experience, the functionality is throttled when invoked many times in less
 *   than the milliseconds interval configured in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.
 * &lt;/blockquote&gt;
 * Function that retrieves camera Stream.
 * @method getUserMedia
 * @param {JSON} [options] The camera Stream configuration options.
 * - When not provided, the value is set to &lt;code&gt;{ audio: true, video: true }&lt;/code&gt;.
 *   &lt;small&gt;To fallback to retrieve audio track only when retrieving of audio and video tracks failed,
 *   enable the &lt;code&gt;audioFallback&lt;/code&gt; flag in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;
 * @param {Boolean} [options.useExactConstraints=false] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that by enabling this flag, exact values will be requested when retrieving camera Stream,
 *   but it does not prevent constraints related errors. By default when not enabled,
 *   expected mandatory maximum values (or optional values for source ID) will requested to prevent constraints related
 *   errors, with an exception for &lt;code&gt;options.video.frameRate&lt;/code&gt; option in Safari and IE (any plugin-enabled) browsers,
 *   where the expected maximum value will not be requested due to the lack of support.&lt;/blockquote&gt;
 *   The flag if &lt;code&gt;getUserMedia()&lt;/code&gt; should request for camera Stream to match exact requested values of
 *   &lt;code&gt;options.audio.deviceId&lt;/code&gt; and &lt;code&gt;options.video.deviceId&lt;/code&gt;, &lt;code&gt;options.video.resolution&lt;/code&gt;
 *   and &lt;code&gt;options.video.frameRate&lt;/code&gt; when provided.
 * @param {Boolean|JSON} [options.audio=false] &lt;blockquote class=&quot;info&quot;&gt;
 *    Note that the current Edge browser implementation does not support the &lt;code&gt;options.audio.optional&lt;/code&gt;,
 *    &lt;code&gt;options.audio.deviceId&lt;/code&gt;, &lt;code&gt;options.audio.echoCancellation&lt;/code&gt;.&lt;/blockquote&gt;
 *    The audio configuration options.
 * @param {Boolean} [options.audio.stereo=false] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt; and
 *   the &lt;code&gt;options.codecParams.audio.opus[&quot;sprop-stereo&quot;]&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt; or &lt;code&gt;options.codecParams.audio.opus[&quot;sprop-stereo&quot;]&lt;/code&gt;
 *   is configured, this overrides the &lt;code&gt;options.audio.stereo&lt;/code&gt; setting.&lt;/blockquote&gt;
 *   The flag if OPUS audio codec stereo band should be configured for sending encoded audio data.
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Boolean} [options.audio.usedtx] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt; is configured, this overrides the
 *   &lt;code&gt;options.audio.stereo&lt;/code&gt; setting.  Note that this feature might
 *   not work depending on the browser support and implementation.&lt;/blockquote&gt;
 *   The flag if OPUS audio codec should enable DTX (Discontinuous Transmission) for sending encoded audio data.
 *   &lt;small&gt;This might help to reduce bandwidth as it reduces the bitrate during silence or background noise, and
 *   goes hand-in-hand with the &lt;code&gt;options.voiceActivityDetection&lt;/code&gt; flag in &lt;a href=&quot;#method_joinRoom&quot;&gt;
 *   &lt;code&gt;joinRoom()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Boolean} [options.audio.useinbandfec] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.useinbandfec&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.useinbandfec&lt;/code&gt; is configured, this overrides the
 *   &lt;code&gt;options.audio.useinbandfec&lt;/code&gt; setting. Note that this parameter should only be used
 *   for debugging purposes only.&lt;/blockquote&gt;
 *   The flag if OPUS audio codec has the capability to take advantage of the in-band FEC
 *   (Forward Error Correction) when sending encoded audio data.
 *   &lt;small&gt;This helps to reduce the harm of packet loss by encoding information about the previous packet loss.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Number} [options.audio.maxplaybackrate] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.maxplaybackrate&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.maxplaybackrate&lt;/code&gt; is configured, this overrides the
 *   &lt;code&gt;options.audio.maxplaybackrate&lt;/code&gt; setting.  Note that this feature might
 *   not work depending on the browser support and implementation.
 *   Note that this parameter should only be used for debugging purposes only.&lt;/blockquote&gt;
 *   The OPUS audio codec maximum output sampling rate in Hz (hertz) that is is capable of receiving
 *   decoded audio data, to adjust to the hardware limitations and ensure that any sending audio data
 *   would not encode at a higher sampling rate specified by this.
 *   &lt;small&gt;This value must be between &lt;code&gt;8000&lt;/code&gt; to &lt;code&gt;48000&lt;/code&gt;.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Boolean} [options.audio.mute=false] The flag if audio tracks should be muted upon receiving them.
 *   &lt;small&gt;Providing the value as &lt;code&gt;false&lt;/code&gt; does nothing to &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt;,
 *   but when provided as &lt;code&gt;true&lt;/code&gt;, this sets the &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt; value to
 *   &lt;code&gt;true&lt;/code&gt; and mutes any existing &lt;a href=&quot;#method_shareScreen&quot;&gt;
 *   &lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; audio tracks as well.&lt;/small&gt;
 * @param {Array} [options.audio.optional] &lt;blockquote class=&quot;info&quot;&gt;
 *   This property has been deprecated. &quot;optional&quot; constraints has been moved from specs.&lt;br&gt;
 *   Note that this may result in constraints related error when &lt;code&gt;options.useExactConstraints&lt;/code&gt; value is
 *   &lt;code&gt;true&lt;/code&gt;. If you are looking to set the requested source ID of the audio track,
 *   use &lt;code&gt;options.audio.deviceId&lt;/code&gt; instead.&lt;/blockquote&gt;
 *   The &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API &lt;code&gt;audio: { optional [..] }&lt;/code&gt; property.
 * @param {String} [options.audio.deviceId] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note this is currently not supported in Firefox browsers.
 *   &lt;/blockquote&gt; The audio track source ID of the device to use.
 *   &lt;small&gt;The list of available audio source ID can be retrieved by the &lt;a href=&quot;https://developer.
 * mozilla.org/en-US/docs/Web/API/MediaDevices/enumerateDevices&quot;&gt;&lt;code&gt;navigator.mediaDevices.enumerateDevices&lt;/code&gt;
 *   API&lt;/a&gt;.&lt;/small&gt;
 * @param {Boolean} [options.audio.echoCancellation=true] &lt;blockquote class=&quot;info&quot;&gt;
 *   For Chrome/Opera/IE/Safari/Bowser, the echo cancellation functionality may not work and may produce a terrible
 *   feedback. It is recommended to use headphones or other microphone devices rather than the device
 *   in-built microphones.&lt;/blockquote&gt; The flag to enable echo cancellation for audio track.
 * @param {Boolean|JSON} [options.video=false] &lt;blockquote class=&quot;info&quot;&gt;
 *    Note that the current Edge browser implementation does not support the &lt;code&gt;options.video.optional&lt;/code&gt;,
 *    &lt;code&gt;options.video.deviceId&lt;/code&gt;, &lt;code&gt;options.video.resolution&lt;/code&gt; and
 *    &lt;code&gt;options.video.frameRate&lt;/code&gt;, &lt;code&gt;options.video.facingMode&lt;/code&gt;.&lt;/blockquote&gt;
 *   The video configuration options.
 * @param {Boolean} [options.video.mute=false] The flag if video tracks should be muted upon receiving them.
 *   &lt;small&gt;Providing the value as &lt;code&gt;false&lt;/code&gt; does nothing to &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt;,
 *   but when provided as &lt;code&gt;true&lt;/code&gt;, this sets the &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt; value to
 *   &lt;code&gt;true&lt;/code&gt; and mutes any existing &lt;a href=&quot;#method_shareScreen&quot;&gt;
 *   &lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; video tracks as well.&lt;/small&gt;
 * @param {JSON} [options.video.resolution] The video resolution.
 *   &lt;small&gt;By default, &lt;a href=&quot;#attr_VIDEO_RESOLUTION&quot;&gt;&lt;code&gt;VGA&lt;/code&gt;&lt;/a&gt; resolution option
 *   is selected when not provided.&lt;/small&gt;
 *   [Rel: Skylink.VIDEO_RESOLUTION]
 * @param {Number|JSON} [options.video.resolution.width] The video resolution width.
 * - When provided as a number, it is the video resolution width.
 * - When provided as a JSON, it is the &lt;code&gt;navigator.mediaDevices.getUserMedia()&lt;/code&gt; &lt;code&gt;.width&lt;/code&gt; settings.
 *   Parameters are &lt;code&gt;&quot;ideal&quot;&lt;/code&gt; for ideal resolution width, &lt;code&gt;&quot;exact&quot;&lt;/code&gt; for exact video resolution width,
 *   &lt;code&gt;&quot;min&quot;&lt;/code&gt; for min video resolution width and &lt;code&gt;&quot;max&quot;&lt;/code&gt; for max video resolution width.
 *   Note that this may result in constraints related errors depending on the browser/hardware supports.
 * @param {Number|JSON} [options.video.resolution.height] The video resolution height.
 * - When provided as a number, it is the video resolution height.
 * - When provided as a JSON, it is the &lt;code&gt;navigator.mediaDevices.getUserMedia()&lt;/code&gt; &lt;code&gt;.height&lt;/code&gt; settings.
 *   Parameters are &lt;code&gt;&quot;ideal&quot;&lt;/code&gt; for ideal video resolution height, &lt;code&gt;&quot;exact&quot;&lt;/code&gt; for exact video resolution height,
 *   &lt;code&gt;&quot;min&quot;&lt;/code&gt; for min video resolution height and &lt;code&gt;&quot;max&quot;&lt;/code&gt; for max video resolution height.
 *   Note that this may result in constraints related errors depending on the browser/hardware supports.
 * @param {Number|JSON} [options.video.frameRate] The video &lt;a href=&quot;https://en.wikipedia.org/wiki/Frame_rate&quot;&gt;
 *   frameRate&lt;/a&gt; per second (fps).
 * - When provided as a number, it is the video framerate.
 * - When provided as a JSON, it is the &lt;code&gt;navigator.mediaDevices.getUserMedia()&lt;/code&gt; &lt;code&gt;.frameRate&lt;/code&gt; settings.
 *   Parameters are &lt;code&gt;&quot;ideal&quot;&lt;/code&gt; for ideal video framerate, &lt;code&gt;&quot;exact&quot;&lt;/code&gt; for exact video framerate,
 *   &lt;code&gt;&quot;min&quot;&lt;/code&gt; for min video framerate and &lt;code&gt;&quot;max&quot;&lt;/code&gt; for max video framerate.
 *   Note that this may result in constraints related errors depending on the browser/hardware supports.
 * @param {Array} [options.video.optional] &lt;blockquote class=&quot;info&quot;&gt;
 *   This property has been deprecated. &quot;optional&quot; constraints has been moved from specs.&lt;br&gt;
 *   Note that this may result in constraints related error when &lt;code&gt;options.useExactConstraints&lt;/code&gt; value is
 *   &lt;code&gt;true&lt;/code&gt;. If you are looking to set the requested source ID of the video track,
 *   use &lt;code&gt;options.video.deviceId&lt;/code&gt; instead.&lt;/blockquote&gt;
 *   The &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API &lt;code&gt;video: { optional [..] }&lt;/code&gt; property.
 * @param {String} [options.video.deviceId] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note this is currently not supported in Firefox browsers.
 *   &lt;/blockquote&gt; The video track source ID of the device to use.
 *   &lt;small&gt;The list of available video source ID can be retrieved by the &lt;a href=&quot;https://developer.
 * mozilla.org/en-US/docs/Web/API/MediaDevices/enumerateDevices&quot;&gt;&lt;code&gt;navigator.mediaDevices.enumerateDevices&lt;/code&gt;
 *   API&lt;/a&gt;.&lt;/small&gt;
 * @param {String|JSON} [options.video.facingMode] The video camera facing mode.
 *   &lt;small&gt;The list of available video source ID can be retrieved by the &lt;a href=&quot;https://developer.mozilla.org
 *   /en-US/docs/Web/API/MediaTrackConstraints/facingMode&quot;&gt;MediaTrackConstraints &lt;code&gt;facingMode&lt;/code&gt; API&lt;/a&gt;.&lt;/small&gt;
 * @param {Function} [callback] The callback function fired when request has completed.
 *   &lt;small&gt;Function parameters signature is &lt;code&gt;function (error, success)&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Function request completion is determined by the &lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggering &lt;code&gt;isScreensharing&lt;/code&gt; parameter
 *   payload value as &lt;code&gt;false&lt;/code&gt; for request success.&lt;/small&gt;
 * @param {Error|String} callback.error The error result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are no errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;code&gt;getUserMedia()&lt;/code&gt; error when retrieving camera Stream.&lt;/small&gt;
 * @param {MediaStream} callback.success The success result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the camera Stream object.&lt;/small&gt;
 * @example
 *   // Example 1: Get both audio and video.
 *   skylinkDemo.getUserMedia(function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *   });
 *
 *   // Example 2: Get only audio.
 *   skylinkDemo.getUserMedia({
 *     audio: true
 *   }, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-audio&quot;), success);
 *   });
 *
 *   // Example 3: Configure resolution for video
 *   skylinkDemo.getUserMedia({
 *     audio: true,
 *     video: {
 *       resolution: skylinkDemo.VIDEO_RESOLUTION.HD
 *     }
 *   }, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *   });
 *
 *   // Example 4: Configure stereo flag for OPUS codec audio (OPUS is always used by default)
 *   skylinkDemo.init({
 *     appKey: &quot;xxxxxx&quot;,
 *     audioCodec: skylinkDemo.AUDIO_CODEC.OPUS
 *   }, function (initErr, initSuccess) {
 *     skylinkDemo.getUserMedia({
 *       audio: {
 *         stereo: true
 *       },
 *       video: true
 *     }, function (error, success) {
 *       if (error) return;
 *       attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *     });
 *   });
 *
 *   // Example 5: Configure frameRate for video
 *   skylinkDemo.getUserMedia({
 *     audio: true,
 *     video: {
 *       frameRate: 50
 *     }
 *   }, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *   });
 *
 *   // Example 6: Configure video and audio based on selected sources. Does not work for Firefox currently.
 *   var sources = { audio: [], video: [] };
 *
 *   function selectStream (audioSourceId, videoSourceId) {
 *     if (AdapterJS.webrtcDetectedBrowser === &#x27;firefox&#x27;) {
 *       console.warn(&quot;Currently this feature is not supported by Firefox browsers!&quot;);
 *       return;
 *     }
 *     skylinkDemo.getUserMedia({
 *       audio: {
 *         optional: [{ sourceId: audioSourceId }]
 *       },
 *       video: {
 *         optional: [{ sourceId: videoSourceId }]
 *       }
 *     }, function (error, success) {
 *       if (error) return;
 *       attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *     });
 *   }
 *
 *   navigator.mediaDevices.enumerateDevices().then(function(devices) {
 *     var selectedAudioSourceId = &quot;&quot;;
 *     var selectedVideoSourceId = &quot;&quot;;
 *     devices.forEach(function(device) {
 *       console.log(device.kind + &quot;: &quot; + device.label + &quot; source ID = &quot; + device.deviceId);
 *       if (device.kind === &quot;audio&quot;) {
 *         selectedAudioSourceId = device.deviceId;
 *       } else {
 *         selectedVideoSourceId = device.deviceId;
 *       }
 *     });
 *     selectStream(selectedAudioSourceId, selectedVideoSourceId);
 *   }).catch(function (error) {
 *      console.error(&quot;Failed&quot;, error);
 *   });
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;If &lt;code&gt;options.audio&lt;/code&gt; value is &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;options.video&lt;/code&gt;
 *   value is &lt;code&gt;false&lt;/code&gt;: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Retrieve camera Stream. &lt;ol&gt;&lt;li&gt;If retrieval was succesful: &lt;ol&gt;
 *   &lt;li&gt;If there is any previous &lt;code&gt;getUserMedia()&lt;/code&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;If there are missing audio or video tracks requested: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Mutes / Unmutes audio and video tracks based on current muted settings in &lt;code&gt;peerInfo.mediaStatus&lt;/code&gt;.
 *   &lt;small&gt;This can be retrieved with &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;If &lt;code&gt;options.audioFallback&lt;/code&gt; is enabled in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;code&gt;options.audio&lt;/code&gt; value is &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;options.video&lt;/code&gt; value is &lt;code&gt;true&lt;/code&gt;: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; event triggers
 *   parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKING&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;Retrieve camera Stream with audio tracks only. &lt;ol&gt;&lt;li&gt;If retrieval was successful: &lt;ol&gt;
 *   &lt;li&gt;If there is any previous &lt;code&gt;getUserMedia()&lt;/code&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; event triggers
 *   parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;Mutes / Unmutes audio and video tracks based on current muted settings in &lt;code&gt;peerInfo.mediaStatus&lt;/code&gt;.
 *   &lt;small&gt;This can be retrieved with &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessError&quot;&gt;&lt;code&gt;mediaAccessError&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallbackError&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; event triggers
 *   parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;ERROR&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt; value as
 *   &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessError&quot;&gt;&lt;code&gt;mediaAccessError&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallbackError&lt;/code&gt; value as
 *   &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype.getUserMedia = function(options,callback) {
  var self = this;

  if (typeof options === &#x27;function&#x27;){
    callback = options;
    options = {
      audio: true,
      video: true
    };

  } else if (typeof options !== &#x27;object&#x27; || options === null) {
    if (typeof options === &#x27;undefined&#x27;) {
      options = {
        audio: true,
        video: true
      };

    } else {
      var invalidOptionsError = &#x27;Please provide a valid options&#x27;;
      log.error(invalidOptionsError, options);
      if (typeof callback === &#x27;function&#x27;) {
        callback(new Error(invalidOptionsError), null);
      }
      return;
    }

  } else if (!options.audio &amp;&amp; !options.video) {
    var noConstraintOptionsSelectedError = &#x27;Please select audio or video&#x27;;
    log.error(noConstraintOptionsSelectedError, options);
    if (typeof callback === &#x27;function&#x27;) {
      callback(new Error(noConstraintOptionsSelectedError), null);
    }
    return;
  }

  /*if (window.location.protocol !== &#x27;https:&#x27; &amp;&amp; AdapterJS.webrtcDetectedBrowser === &#x27;chrome&#x27; &amp;&amp;
    AdapterJS.webrtcDetectedVersion &gt; 46) {
    errorMsg = &#x27;getUserMedia() has to be called in https:// application&#x27;;
    log.error(errorMsg, options);
    if (typeof callback === &#x27;function&#x27;) {
      callback(new Error(errorMsg), null);
    }
    return;
  }*/

  self._throttle(function (runFn) {
    if (!runFn) {
      if (self._initOptions.throttlingShouldThrowError) {
        var throttleLimitError = &#x27;Unable to run as throttle interval has not reached (&#x27; + self._initOptions.throttleIntervals.getUserMedia + &#x27;ms).&#x27;;
        log.error(throttleLimitError);

        if (typeof callback === &#x27;function&#x27;) {
          callback(new Error(throttleLimitError), null);
        }
      }
      return;
    }

    if (typeof callback === &#x27;function&#x27;) {
      var mediaAccessSuccessFn = function (stream) {
        self.off(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn);
        callback(null, stream);
      };
      var mediaAccessErrorFn = function (error) {
        self.off(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn);
        callback(error, null);
      };

      self.once(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn, function (stream, isScreensharing) {
        return !isScreensharing;
      });

      self.once(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn, function (error, isScreensharing) {
        return !isScreensharing;
      });
    }

    // Parse stream settings
    var settings = self._parseStreamSettings(options);

    var onSuccessCbFn = function (stream) {
      if (settings.mutedSettings.shouldAudioMuted) {
        self._streamsMutedSettings.audioMuted = true;
      }

      if (settings.mutedSettings.shouldVideoMuted) {
        self._streamsMutedSettings.videoMuted = true;
      }

      self._onStreamAccessSuccess(stream, settings, false, false);
    };

    var onErrorCbFn = function (error) {
      self._onStreamAccessError(error, settings, false, false);
    };

    try {
      if (typeof (AdapterJS || {}).webRTCReady !== &#x27;function&#x27;) {
        return onErrorCbFn(new Error(&#x27;Failed to call getUserMedia() as AdapterJS is not yet loaded!&#x27;));
      }

      AdapterJS.webRTCReady(function () {
        navigator.getUserMedia(settings.getUserMediaSettings, onSuccessCbFn, onErrorCbFn);
      });
    } catch (error) {
      onErrorCbFn(error);
    }

  }, &#x27;getUserMedia&#x27;, self._initOptions.throttleIntervals.getUserMedia);
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that if &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; is available despite having
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; available, the
 *   &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; is sent instead of the
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; to Peers.
 * &lt;/blockquote&gt;
 * Function that sends a new &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;
 * to all connected Peers in the Room.
 * @method sendStream
 * @param {JSON|MediaStream} options The &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt;
 *   method&lt;/a&gt; &lt;code&gt;options&lt;/code&gt; parameter settings.
 * - When provided as a &lt;code&gt;MediaStream&lt;/code&gt; object, this configures the &lt;code&gt;options.audio&lt;/code&gt; and
 *   &lt;code&gt;options.video&lt;/code&gt; based on the tracks available in the &lt;code&gt;MediaStream&lt;/code&gt; object,
 *   and configures the &lt;code&gt;options.audio.mute&lt;/code&gt; and &lt;code&gt;options.video.mute&lt;/code&gt; based on the tracks
 *   &lt;code&gt;.enabled&lt;/code&gt; flags in the tracks provided in the &lt;code&gt;MediaStream&lt;/code&gt; object without
 *   invoking &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;.
 *   &lt;small&gt;Object signature matches the &lt;code&gt;options&lt;/code&gt; parameter in the
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;
 * @param {Function} [callback] The callback function fired when request has completed.
 *   &lt;small&gt;Function parameters signature is &lt;code&gt;function (error, success)&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Function request completion is determined by the &lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggering &lt;code&gt;isScreensharing&lt;/code&gt; parameter payload value
 *   as &lt;code&gt;false&lt;/code&gt; for request success when User is in Room without Peers,
 *   or by the &lt;a href=&quot;#event_peerRestart&quot;&gt;&lt;code&gt;peerRestart&lt;/code&gt; event&lt;/a&gt; triggering
 *   &lt;code&gt;isSelfInitiateRestart&lt;/code&gt; parameter payload value as &lt;code&gt;true&lt;/code&gt; for all connected Peers
 *   for request success when User is in Room with Peers.&lt;/small&gt;
 * @param {Error|String} callback.error The error result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are no errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt; error or
 *   when invalid &lt;code&gt;options&lt;/code&gt; is provided.&lt;/small&gt;
 * @param {MediaStream} callback.success The success result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;
 *   Stream object.&lt;/small&gt;
 * @example
 *   // Example 1: Send MediaStream object before being connected to Room
 *   function retrieveStreamBySourceForFirefox (sourceId) {
 *     navigator.mediaDevices.getUserMedia({
 *       audio: true,
 *       video: {
 *         sourceId: { exact: sourceId }
 *       }
 *     }).then(function (stream) {
 *       skylinkDemo.sendStream(stream, function (error, success) {
 *         if (err) return;
 *         if (stream === success) {
 *           console.info(&quot;Same MediaStream has been sent&quot;);
 *         }
 *         console.log(&quot;Stream is now being sent to Peers&quot;);
 *         attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *       });
 *     });
 *   }
 *
 *   // Example 2: Send video after being connected to Room
 *   function sendVideo () {
 *     skylinkDemo.joinRoom(function (jRError, jRSuccess) {
 *       if (jRError) return;
 *       skylinkDemo.sendStream({
 *         audio: true,
 *         video: true
 *       }, function (error, success) {
 *         if (error) return;
 *         console.log(&quot;getUserMedia() Stream with video is now being sent to Peers&quot;);
 *         attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *       });
 *     });
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Checks &lt;code&gt;options&lt;/code&gt; provided. &lt;ol&gt;&lt;li&gt;If provided parameter &lt;code&gt;options&lt;/code&gt; is not valid: &lt;ol&gt;
 *   &lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Else if provided parameter &lt;code&gt;options&lt;/code&gt; is a Stream object: &lt;ol&gt;
 *   &lt;li&gt;Checks if there is any audio or video tracks. &lt;ol&gt;&lt;li&gt;If there is no tracks: &lt;ol&gt;
 *   &lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;Set &lt;code&gt;options.audio&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; if Stream has audio tracks.&lt;/li&gt;
 *   &lt;li&gt;Set &lt;code&gt;options.video&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; if Stream has video tracks.&lt;/li&gt;
 *   &lt;li&gt;Mutes / Unmutes audio and video tracks based on current muted settings in
 *   &lt;code&gt;peerInfo.mediaStatus&lt;/code&gt;. &lt;small&gt;This can be retrieved with
 *   &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;&lt;/li&gt;
 *   &lt;li&gt;If there is any previous &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;:
 *   &lt;ol&gt;&lt;li&gt;Invokes &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt; to stop previous Stream.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;Invoke &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options&lt;/code&gt; provided in &lt;code&gt;sendStream()&lt;/code&gt;. &lt;ol&gt;&lt;li&gt;If request has errors: &lt;ol&gt;
 *   &lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;If there is currently no &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; and User is in Room: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_incomingStream&quot;&gt;&lt;code&gt;incomingStream&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;stream&lt;/code&gt; as
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;Checks if MCU is enabled for App Key provided in &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;. &lt;ol&gt;
 *   &lt;li&gt;If MCU is enabled: &lt;ol&gt;&lt;li&gt;Invoke &lt;a href=&quot;#method_refreshConnection&quot;&gt;&lt;code&gt;refreshConnection()&lt;/code&gt;
 *   method&lt;/a&gt;. &lt;ol&gt;&lt;li&gt;If request has errors: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Else: &lt;ol&gt;&lt;li&gt;If there are connected Peers in the Room: &lt;ol&gt;
 *   &lt;li&gt;Invoke &lt;a href=&quot;#method_refreshConnection&quot;&gt;&lt;code&gt;refreshConnection()&lt;/code&gt; method&lt;/a&gt;. &lt;ol&gt;
 *   &lt;li&gt;If request has errors: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.
 *   &lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.6
 */

Skylink.prototype.sendStream = function(options, callback) {
  var self = this;

  var renegotiate = function(newStream, cb) {
    if (Object.keys(self._peerConnections).length &gt; 0 || self._hasMCU) {
      self._refreshPeerConnection(Object.keys(self._peerConnections), false, {}, function (err, success) {
        if (err) {
          log.error(&#x27;Failed refreshing connections for sendStream() -&gt;&#x27;, err);
          if (typeof cb === &#x27;function&#x27;) {
            cb(new Error(&#x27;Failed refreshing connections.&#x27;), null);
          }
          return;
        }
        if (typeof cb === &#x27;function&#x27;) {
          cb(null, newStream);
        }
      });
    } else if (typeof cb === &#x27;function&#x27;) {
      cb(null, newStream);
    }
  }

  var performReplaceTracks = function (originalStream, newStream, cb) {
    if (!originalStream) {
      renegotiate(newStream, cb);
      return;
    }
    var newStreamHasVideoTrack = Array.isArray(newStream.getVideoTracks()) &amp;&amp; newStream.getVideoTracks().length;
    var newStreamHasAudioTrack = Array.isArray(newStream.getAudioTracks()) &amp;&amp; newStream.getAudioTracks().length;
    var originalStreamHasVideoTrack = Array.isArray(originalStream.getVideoTracks()) &amp;&amp; originalStream.getVideoTracks().length;
    var originalStreamHasAudioTrack = Array.isArray(originalStream.getAudioTracks()) &amp;&amp; originalStream.getAudioTracks().length;

    if ((newStreamHasVideoTrack &amp;&amp; !originalStreamHasVideoTrack) || (newStreamHasAudioTrack &amp;&amp; !originalStreamHasAudioTrack)) {
      renegotiate(newStream, cb);
      return;
    }

    if (newStreamHasVideoTrack &amp;&amp; originalStreamHasVideoTrack) {
      self._replaceTrack(originalStream.getVideoTracks()[0].id, newStream.getVideoTracks()[0]);
    }

    if (newStreamHasAudioTrack &amp;&amp; originalStreamHasAudioTrack) {
      self._replaceTrack(originalStream.getAudioTracks()[0].id, newStream.getAudioTracks()[0]);
    }
  };

  var restartFn = function (originalStream, stream) {
    if (self._inRoom) {

      if (!self._streams.screenshare) {
        self._trigger(&#x27;incomingStream&#x27;, self._user.sid, stream, true, self.getPeerInfo(), false, stream.id || stream.label);
        self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
      } else {
        performReplaceTracks(originalStream, stream, callback);
      }

      if (self._streams.userMedia) {
        performReplaceTracks(originalStream, stream, callback);
      }

    } else if (typeof callback === &#x27;function&#x27;) {
      callback(null, stream);
    }
  };

  // Note: Sometimes it may be &quot;function&quot; or &quot;object&quot; but then &quot;function&quot; might be mistaken for callback function, so for now fixing it that way
  if ((typeof options !== &#x27;object&#x27; || options === null) &amp;&amp; !(AdapterJS &amp;&amp; AdapterJS.WebRTCPlugin &amp;&amp;
    AdapterJS.WebRTCPlugin.plugin &amp;&amp; [&#x27;function&#x27;, &#x27;object&#x27;].indexOf(typeof options) &gt; -1)) {
    var invalidOptionsError = &#x27;Provided stream settings is invalid&#x27;;
    log.error(invalidOptionsError, options);
    if (typeof callback === &#x27;function&#x27;){
      callback(new Error(invalidOptionsError),null);
    }
    return;
  }

  if (!self._inRoom) {
    log.warn(&#x27;There are no peers to send stream to as not in room!&#x27;);
  }

  if (AdapterJS.webrtcDetectedBrowser === &#x27;edge&#x27;) {
    var edgeNotSupportError = &#x27;Edge browser currently does not support renegotiation.&#x27;;
    log.error(edgeNotSupportError, options);
    if (typeof callback === &#x27;function&#x27;){
      callback(new Error(edgeNotSupportError),null);
    }
    return;
  }

  var origStream = null;

  if (self._streams.userMedia) {
    origStream = self._streams.userMedia.stream;
  }

  if (self._streams.screenshare) {
    origStream = self._streams.screenshare.stream;
  }

  if (typeof options.getAudioTracks === &#x27;function&#x27; || typeof options.getVideoTracks === &#x27;function&#x27;) {
    var checkActiveTracksFn = function (tracks) {
      for (var t = 0; t &lt; tracks.length; t++) {
        if (!(tracks[t].ended || (typeof tracks[t].readyState === &#x27;string&#x27; ?
          tracks[t].readyState !== &#x27;live&#x27; : false))) {
          return true;
        }
      }
      return false;
    };

    if (!checkActiveTracksFn( options.getAudioTracks() ) &amp;&amp; !checkActiveTracksFn( options.getVideoTracks() )) {
      var invalidStreamError = &#x27;Provided stream object does not have audio or video tracks.&#x27;;
      log.error(invalidStreamError, options);
      if (typeof callback === &#x27;function&#x27;){
        callback(new Error(invalidStreamError),null);
      }
      return;
    }

    self._onStreamAccessSuccess(options, {
      settings: {
        audio: true,
        video: true
      },
      getUserMediaSettings: {
        audio: true,
        video: true
      }
    }, false, false);

    restartFn(origStream, options);

  } else {
    self.getUserMedia(options, function (err, stream) {
      if (err) {
        if (typeof callback === &#x27;function&#x27;) {
          callback(err, null);
        }
        return;
      }
      restartFn(origStream, stream);
    });
  }
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that broadcasted events from &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_sendMessage&quot;&gt;&lt;code&gt;sendMessage()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_unlockRoom&quot;&gt;&lt;code&gt;unlockRoom()&lt;/code&gt; method&lt;/a&gt; and
 *   &lt;a href=&quot;#method_lockRoom&quot;&gt;&lt;code&gt;lockRoom()&lt;/code&gt; method&lt;/a&gt; may be queued when
 *   sent within less than an interval.
 * &lt;/blockquote&gt;
 * Function that stops &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;.
 * @method stopStream
 * @example
 *   function stopStream () {
 *     skylinkDemo.stopStream();
 *   }
 *
 *   skylinkDemo.getUserMedia();
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Checks if there is &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;. &lt;ol&gt;
 *   &lt;li&gt;If there is &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;: &lt;ol&gt;
 *   &lt;li&gt;Stop &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; Stream. &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessStopped&quot;&gt;&lt;code&gt;mediaAccessStopped&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;If User is in Room: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_streamEnded&quot;&gt;&lt;code&gt;streamEnded&lt;/code&gt; event&lt;/a&gt; triggers parameter
 *   payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isScreensharing&lt;/code&gt; value as&lt;code&gt;false&lt;/code&gt;
 *   .&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype.stopStream = function () {
  if (this._streams.userMedia) {
    this._stopStreams({
      userMedia: true
    });
  }
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that broadcasted events from &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_sendMessage&quot;&gt;&lt;code&gt;sendMessage()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_unlockRoom&quot;&gt;&lt;code&gt;unlockRoom()&lt;/code&gt; method&lt;/a&gt; and
 *   &lt;a href=&quot;#method_lockRoom&quot;&gt;&lt;code&gt;lockRoom()&lt;/code&gt; method&lt;/a&gt; may be queued when
 *   sent within less than an interval.
 * &lt;/blockquote&gt;
 * Function that mutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; audio or video tracks.
 * @method muteStream
 * @param {JSON} options The Streams muting options.
 * @param {Boolean} [options.audioMuted=true] The flag if all Streams audio
 *   tracks should be muted or not.
 * @param {Boolean} [options.videoMuted=true] The flag if all Strea.ms video
 *   tracks should be muted or not.
 * @example
 *   // Example 1: Mute both audio and video tracks in all Streams
 *   skylinkDemo.muteStream({
 *     audioMuted: true,
 *     videoMuted: true
 *   });
 *
 *   // Example 2: Mute only audio tracks in all Streams
 *   skylinkDemo.muteStream({
 *     audioMuted: true,
 *     videoMuted: false
 *   });
 *
 *   // Example 3: Mute only video tracks in all Streams
 *   skylinkDemo.muteStream({
 *     audioMuted: false,
 *     videoMuted: true
 *   });
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;If provided parameter &lt;code&gt;options&lt;/code&gt; is invalid: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Checks if there is any available Streams: &lt;ol&gt;&lt;li&gt;If there is no available Streams: &lt;ol&gt;
 *   &lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;If User is in Room: &lt;ol&gt;
 *   &lt;li&gt;Checks if there is audio tracks to mute / unmute: &lt;ol&gt;&lt;li&gt;If there is audio tracks to mute / unmute: &lt;ol&gt;
 *   &lt;li&gt;If &lt;code&gt;options.audioMuted&lt;/code&gt; value is not the same as the current
 *   &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt;: &lt;small&gt;This can be retrieved with
 *   &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt; &lt;ol&gt;
 *   &lt;li&gt;&lt;em&gt;For Peer only&lt;/em&gt; &lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt;
 *   triggers with parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;em&gt;For Peer only&lt;/em&gt; &lt;a href=&quot;#event_streamMuted&quot;&gt;&lt;code&gt;streamMuted&lt;/code&gt; event&lt;/a&gt;
 *   triggers with parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Checks if there is video tracks to mute / unmute: &lt;ol&gt;&lt;li&gt;If there is video tracks to mute / unmute: &lt;ol&gt;
 *   &lt;li&gt;If &lt;code&gt;options.videoMuted&lt;/code&gt; value is not the same as the current
 *   &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt;: &lt;small&gt;This can be retrieved with
 *   &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt; &lt;ol&gt;
 *   &lt;li&gt;&lt;em&gt;For Peer only&lt;/em&gt; &lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt;
 *   triggers with parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;em&gt;For Peer only&lt;/em&gt; &lt;a href=&quot;#event_streamMuted&quot;&gt;&lt;code&gt;streamMuted&lt;/code&gt; event&lt;/a&gt; triggers with
 *   parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;If &lt;code&gt;options.audioMuted&lt;/code&gt; value is not the same as the current
 *   &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt; or &lt;code&gt;options.videoMuted&lt;/code&gt; value is not
 *   the same as the current &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt;: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_localMediaMuted&quot;&gt;&lt;code&gt;localMediaMuted&lt;/code&gt; event&lt;/a&gt; triggers.&lt;/li&gt;
 *   &lt;li&gt;If User is in Room: &lt;ol&gt;&lt;li&gt;&lt;a href=&quot;#event_streamMuted&quot;&gt;&lt;code&gt;streamMuted&lt;/code&gt; event&lt;/a&gt;
 *   triggers with parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers with
 *   parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.7
 */
Skylink.prototype.muteStream = function(options) {
  var self = this;

  if (typeof options !== &#x27;object&#x27;) {
    log.error(&#x27;Provided settings is not an object&#x27;);
    return;
  }

  if (!(self._streams.userMedia &amp;&amp; self._streams.userMedia.stream) &amp;&amp;
    !(self._streams.screenshare &amp;&amp; self._streams.screenshare.stream)) {
    log.warn(&#x27;No streams are available to mute / unmute!&#x27;);
    return;
  }

  var audioMuted = typeof options.audioMuted === &#x27;boolean&#x27; ? options.audioMuted : true;
  var videoMuted = typeof options.videoMuted === &#x27;boolean&#x27; ? options.videoMuted : true;
  var hasToggledAudio = false;
  var hasToggledVideo = false;

  if (self._streamsMutedSettings.audioMuted !== audioMuted) {
    self._streamsMutedSettings.audioMuted = audioMuted;
    hasToggledAudio = true;
  }

  if (self._streamsMutedSettings.videoMuted !== videoMuted) {
    self._streamsMutedSettings.videoMuted = videoMuted;
    hasToggledVideo = true;
  }

  if (hasToggledVideo || hasToggledAudio) {
    var streamTracksAvailability = self._muteStreams();

    if (hasToggledVideo &amp;&amp; self._inRoom) {
      self._sendChannelMessage({
        type: self._SIG_MESSAGE_TYPE.MUTE_VIDEO,
        mid: self._user.sid,
        rid: self._room.id,
        muted: self._streamsMutedSettings.videoMuted,
        stamp: (new Date()).getTime()
      });
    }

    if (hasToggledAudio &amp;&amp; self._inRoom) {
      setTimeout(function () {
        self._sendChannelMessage({
          type: self._SIG_MESSAGE_TYPE.MUTE_AUDIO,
          mid: self._user.sid,
          rid: self._room.id,
          muted: self._streamsMutedSettings.audioMuted,
          stamp: (new Date()).getTime()
        });
      }, hasToggledVideo ? 1050 : 0);
    }

    if ((streamTracksAvailability.hasVideo &amp;&amp; hasToggledVideo) ||
      (streamTracksAvailability.hasAudio &amp;&amp; hasToggledAudio)) {

      self._trigger(&#x27;localMediaMuted&#x27;, {
        audioMuted: streamTracksAvailability.hasAudio ? self._streamsMutedSettings.audioMuted : true,
        videoMuted: streamTracksAvailability.hasVideo ? self._streamsMutedSettings.videoMuted : true
      });

      if (self._inRoom) {
        self._trigger(&#x27;streamMuted&#x27;, self._user.sid, self.getPeerInfo(), true,
          self._streams.screenshare &amp;&amp; self._streams.screenshare.stream);
        self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
      }
    }
  }
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that unmutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; audio tracks.
 * @method enableAudio
 * @deprecated true
 * @example
 *   function unmuteAudio () {
 *     skylinkDemo.enableAudio();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.audioMuted&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;options.videoMuted&lt;/code&gt; value with current &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt; value.
 *   &lt;small&gt;See &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt; for more information.&lt;/small&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.enableAudio = function() {
  this.muteStream({
    audioMuted: false,
    videoMuted: this._streamsMutedSettings.videoMuted
  });
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that mutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; audio tracks.
 * @method disableAudio
 * @deprecated true
 * @example
 *   function muteAudio () {
 *     skylinkDemo.disableAudio();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.audioMuted&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and
 *   &lt;code&gt;options.videoMuted&lt;/code&gt; value with current &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt; value.
 *   &lt;small&gt;See &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt; for more information.&lt;/small&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.disableAudio = function() {
  this.muteStream({
    audioMuted: true,
    videoMuted: this._streamsMutedSettings.videoMuted
  });
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that unmutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; video tracks.
 * @method enableVideo
 * @deprecated true
 * @example
 *   function unmuteVideo () {
 *     skylinkDemo.enableVideo();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.videoMuted&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;options.audioMuted&lt;/code&gt; value with current &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt; value.
 *   &lt;small&gt;See &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt; for more information.&lt;/small&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.enableVideo = function() {
  this.muteStream({
    videoMuted: false,
    audioMuted: this._streamsMutedSettings.audioMuted
  });
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that mutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; video tracks.
 * @method disableVideo
 * @deprecated true
 * @example
 *   function muteVideo () {
 *     skylinkDemo.disableVideo();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.videoMuted&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and
 *   &lt;code&gt;options.audioMuted&lt;/code&gt; value with current &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt; value.
 *   &lt;small&gt;See &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt; for more information.&lt;/small&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.disableVideo = function() {
  this.muteStream({
    videoMuted: true,
    audioMuted: this._streamsMutedSettings.audioMuted
  });
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   For a better user experience, the functionality is throttled when invoked many times in less
 *   than the milliseconds interval configured in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.
 *   Note that the Opera and Edge browser does not support screensharing, and as for IE / Safari browsers using
 *   the Temasys Plugin screensharing support, check out the &lt;a href=&quot;https://temasys.com.sg/plugin/#commercial-licensing&quot;&gt;
 *   commercial licensing&lt;/a&gt; for more options.
 * &lt;/blockquote&gt;
 * Function that retrieves screensharing Stream.
 * @method shareScreen
 * @param {JSON|Boolean} [enableAudio=false] The flag if audio tracks should be retrieved.
 * @param {Boolean} [enableAudio.stereo=false] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt; and
 *   the &lt;code&gt;options.codecParams.audio.opus[&quot;sprop-stereo&quot;]&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt; or &lt;code&gt;options.codecParams.audio.opus[&quot;sprop-stereo&quot;]&lt;/code&gt;
 *   is configured, this overrides the &lt;code&gt;options.audio.stereo&lt;/code&gt; setting.&lt;/blockquote&gt;
 *   The flag if OPUS audio codec stereo band should be configured for sending encoded audio data.
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Boolean} [enableAudio.usedtx] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt; is configured, this overrides the
 *   &lt;code&gt;options.audio.stereo&lt;/code&gt; setting.  Note that this feature might
 *   not work depending on the browser support and implementation.&lt;/blockquote&gt;
 *   The flag if OPUS audio codec should enable DTX (Discontinuous Transmission) for sending encoded audio data.
 *   &lt;small&gt;This might help to reduce bandwidth as it reduces the bitrate during silence or background noise, and
 *   goes hand-in-hand with the &lt;code&gt;options.voiceActivityDetection&lt;/code&gt; flag in &lt;a href=&quot;#method_joinRoom&quot;&gt;
 *   &lt;code&gt;joinRoom()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Boolean} [enableAudio.useinbandfec] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.useinbandfec&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.useinbandfec&lt;/code&gt; is configured, this overrides the
 *   &lt;code&gt;options.audio.useinbandfec&lt;/code&gt; setting. Note that this parameter should only be used
 *   for debugging purposes only.&lt;/blockquote&gt;
 *   The flag if OPUS audio codec has the capability to take advantage of the in-band FEC
 *   (Forward Error Correction) when sending encoded audio data.
 *   &lt;small&gt;This helps to reduce the harm of packet loss by encoding information about the previous packet loss.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Number} [enableAudio.maxplaybackrate] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.maxplaybackrate&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.maxplaybackrate&lt;/code&gt; is configured, this overrides the
 *   &lt;code&gt;options.audio.maxplaybackrate&lt;/code&gt; setting.  Note that this feature might
 *   not work depending on the browser support and implementation.
 *   Note that this parameter should only be used for debugging purposes only.&lt;/blockquote&gt;
 *   The OPUS audio codec maximum output sampling rate in Hz (hertz) that is is capable of receiving
 *   decoded audio data, to adjust to the hardware limitations and ensure that any sending audio data
 *   would not encode at a higher sampling rate specified by this.
 *   &lt;small&gt;This value must be between &lt;code&gt;8000&lt;/code&gt; to &lt;code&gt;48000&lt;/code&gt;.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Boolean} [enableAudio.echoCancellation=true] &lt;blockquote class=&quot;info&quot;&gt;
 *   For Chrome/Opera/IE/Safari/Bowser, the echo cancellation functionality may not work and may produce a terrible
 *   feedback. It is recommended to use headphones or other microphone devices rather than the device
 *   in-built microphones.&lt;/blockquote&gt; The flag to enable echo cancellation for audio track.
 *   &lt;small&gt;Note that this will not be toggled for Chrome/Opera case when &#x60;mediaSource&#x60; value is &#x60;[&quot;tab&quot;,&quot;audio&quot;]&#x60;.&lt;/small&gt;
 * @param {String|Array|JSON} [mediaSource=screen] The screensharing media source to select.
 *   &lt;small&gt;Note that multiple sources are not supported by Firefox as of the time of this release.
 *   Firefox will use the first item specified in the Array in the event that multiple sources are defined.&lt;/small&gt;
 *   &lt;small&gt;E.g. &lt;code&gt;[&quot;screen&quot;, &quot;window&quot;]&lt;/code&gt;, &lt;code&gt;[&quot;tab&quot;, &quot;audio&quot;]&lt;/code&gt;, &lt;code&gt;&quot;screen&quot;&lt;/code&gt; or &lt;code&gt;&quot;tab&quot;&lt;/code&gt;
 *   or &lt;code&gt;{ sourceId: &quot;xxxxx&quot;, mediaSource: &quot;screen&quot; }&lt;/code&gt;.&lt;/small&gt;
 *   [Rel: Skylink.MEDIA_SOURCE]
 * @param {Function} [callback] The callback function fired when request has completed.
 *   &lt;small&gt;Function parameters signature is &lt;code&gt;function (error, success)&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Function request completion is determined by the &lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggering &lt;code&gt;isScreensharing&lt;/code&gt; parameter payload value
 *   as &lt;code&gt;true&lt;/code&gt; for request success when User is not in the Room or is in Room without Peers,
 *   or by the &lt;a href=&quot;#event_peerRestart&quot;&gt;&lt;code&gt;peerRestart&lt;/code&gt; event&lt;/a&gt; triggering
 *   &lt;code&gt;isSelfInitiateRestart&lt;/code&gt; parameter payload value as &lt;code&gt;true&lt;/code&gt; for all connected Peers
 *   for request success when User is in Room with Peers.&lt;/small&gt;
 * @param {Error|String} callback.error The error result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are no errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;code&gt;shareScreen()&lt;/code&gt; error when retrieving screensharing Stream.&lt;/small&gt;
 * @param {MediaStream} callback.success The success result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the screensharing Stream object.&lt;/small&gt;
 * @example
 *   // Example 1: Share screen with audio
 *   skylinkDemo.shareScreen(true, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-screen&quot;), success);
 *   });
 *
 *   // Example 2: Share screen without audio
 *   skylinkDemo.shareScreen(false, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-screen&quot;), success);
 *   });
 *
 *   // Example 3: Share &quot;window&quot; media source
 *   skylinkDemo.shareScreen(&quot;window&quot;, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-screen&quot;), success);
 *   });
 *
 *   // Example 4: Share tab and its audio media source
 *   skylinkDemo.shareScreen(true, [&quot;tab&quot;, &quot;audio&quot;], function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-screen&quot;), success);
 *   });
 *
 *   // Example 5: Share &quot;window&quot; and &quot;screen&quot; media source
 *   skylinkDemo.shareScreen([&quot;window&quot;, &quot;screen&quot;], function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-screen&quot;), success);
 *   });
 *
 *   // Example 6: Share &quot;window&quot; with specific media source for specific plugin build users.
 *   skylinkDemo.shareScreen({ mediaSource: &quot;window&quot;, sourceId: &quot;xxxxx&quot; }, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-screen&quot;), success);
 *   });
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Retrieves screensharing Stream. &lt;ol&gt;&lt;li&gt;If retrieval was successful: &lt;ol&gt;&lt;li&gt;If browser is Firefox: &lt;ol&gt;
 *   &lt;li&gt;If there are missing audio or video tracks requested: &lt;ol&gt;
 *   &lt;li&gt;If there is any previous &lt;code&gt;shareScreen()&lt;/code&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt;
 *   triggers parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;If audio is requested: &lt;small&gt;Chrome, Safari and IE currently doesn&#x27;t support retrieval of
 *   audio track together with screensharing video track.&lt;/small&gt; &lt;ol&gt;&lt;li&gt;Retrieves audio Stream: &lt;ol&gt;
 *   &lt;li&gt;If retrieval was successful: &lt;ol&gt;&lt;li&gt;Attempts to attach screensharing Stream video track to audio Stream. &lt;ol&gt;
 *   &lt;li&gt;If attachment was successful: &lt;ol&gt;&lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers parameter payload &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;If there is any previous &lt;code&gt;shareScreen()&lt;/code&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;If there is any previous &lt;code&gt;shareScreen()&lt;/code&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt;
 *   triggers parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt;
 *   triggers parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;
 *   and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessError&quot;&gt;&lt;code&gt;mediaAccessError&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as
 *   &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;If User is in Room: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_incomingStream&quot;&gt;&lt;code&gt;incomingStream&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;stream&lt;/code&gt; as &lt;code&gt;shareScreen()&lt;/code&gt; Stream.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;Checks if MCU is enabled for App Key provided in &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;. &lt;ol&gt;
 *   &lt;li&gt;If MCU is enabled: &lt;ol&gt;&lt;li&gt;Invoke &lt;a href=&quot;#method_refreshConnection&quot;&gt;&lt;code&gt;refreshConnection()&lt;/code&gt; method&lt;/a&gt;.
 *   &lt;ol&gt;&lt;li&gt;If request has errors: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;If there are connected Peers in the Room: &lt;ol&gt;&lt;li&gt;Invoke &lt;a href=&quot;#method_refreshConnection&quot;&gt;
 *   &lt;code&gt;refreshConnection()&lt;/code&gt; method&lt;/a&gt;. &lt;ol&gt;&lt;li&gt;If request has errors: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;
 *   &lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.6.0
 */
Skylink.prototype.shareScreen = function (enableAudio, mediaSource, callback) {
  var self = this;
  var enableAudioSettings = false;
  var useMediaSource = [self.MEDIA_SOURCE.SCREEN];
  var useMediaSourceId = null;
  var checkIfSourceExistsFn = function (val) {
    for (var prop in self.MEDIA_SOURCE) {
      if (self.MEDIA_SOURCE.hasOwnProperty(prop) &amp;&amp; self.MEDIA_SOURCE[prop] === val) {
        return true;
      }
    }
    return false;
  };

  // shareScreen(&quot;screen&quot;) or shareScreen({ sourceId: &quot;xxxx&quot;, mediaSource: &quot;xxxxx&quot; })
  if (enableAudio &amp;&amp; typeof enableAudio === &#x27;string&#x27; ||
    (enableAudio &amp;&amp; typeof enableAudio === &#x27;object&#x27; &amp;&amp; enableAudio.sourceId &amp;&amp; enableAudio.mediaSource)) {
    if (checkIfSourceExistsFn(typeof enableAudio === &#x27;object&#x27; ? enableAudio.mediaSource : enableAudio)) {
      useMediaSource = [typeof enableAudio === &#x27;object&#x27; ? enableAudio.mediaSource : enableAudio];
    }
    useMediaSourceId = typeof enableAudio === &#x27;object&#x27; ? enableAudio.sourceId : null;
  // shareScreen([&quot;screen&quot;, &quot;window&quot;])
  } else if (Array.isArray(enableAudio)) {
    var enableAudioArr = [];

    for (var i = 0; i &lt; enableAudio.length; i++) {
      if (checkIfSourceExistsFn(enableAudio[i])) {
        enableAudioArr.push(enableAudio[i]);
      }
    }

    if (enableAudioArr.length &gt; 0) {
      useMediaSource = enableAudioArr;
    }
  // shareScreen({ stereo: true })
  } else if (enableAudio &amp;&amp; typeof enableAudio === &#x27;object&#x27;) {
    if (enableAudio.sourceId &amp;&amp; enableAudio.mediaSource) {

    } else {
      enableAudioSettings = {
        usedtx: typeof enableAudio.usedtx === &#x27;boolean&#x27; ? enableAudio.usedtx : null,
        useinbandfec: typeof enableAudio.useinbandfec === &#x27;boolean&#x27; ? enableAudio.useinbandfec : null,
        stereo: enableAudio.stereo === true,
        echoCancellation: enableAudio.echoCancellation !== false,
        deviceId: enableAudio.deviceId
      };
    }
  // shareScreen(true)
  } else if (enableAudio === true) {
    enableAudioSettings = enableAudio === true ? {
      usedtx: null,
      useinbandfec: null,
      stereo: false,
      echoCancellation: true,
      deviceId: null
    } : false;
  // shareScreen(function () {})
  } else if (typeof enableAudio === &#x27;function&#x27;) {
    callback = enableAudio;
    enableAudio = false;
  }

  // shareScreen(.., &quot;screen&quot;) or shareScreen({ sourceId: &quot;xxxx&quot;, mediaSource: &quot;xxxxx&quot; })
  if (mediaSource &amp;&amp; typeof mediaSource === &#x27;string&#x27; ||
    (mediaSource &amp;&amp; typeof mediaSource === &#x27;object&#x27; &amp;&amp; mediaSource.sourceId &amp;&amp; mediaSource.mediaSource)) {
    if (checkIfSourceExistsFn(typeof mediaSource === &#x27;object&#x27; ? mediaSource.mediaSource : mediaSource)) {
      useMediaSource = [typeof mediaSource === &#x27;object&#x27; ? mediaSource.mediaSource : mediaSource];
    }
    useMediaSourceId = typeof mediaSource === &#x27;object&#x27; ? mediaSource.sourceId : null;
  // shareScreen(.., [&quot;screen&quot;, &quot;window&quot;])
  } else if (Array.isArray(mediaSource)) {
    var mediaSourceArr = [];
    for (var i = 0; i &lt; mediaSource.length; i++) {
      if (checkIfSourceExistsFn(mediaSource[i])) {
        mediaSourceArr.push(mediaSource[i]);
      }
    }
    if (mediaSourceArr.length &gt; 0) {
      useMediaSource = mediaSourceArr;
    }
  // shareScreen(.., function () {})
  } else if (typeof mediaSource === &#x27;function&#x27;) {
    callback = mediaSource;
  }

  if (useMediaSource.indexOf(&#x27;audio&#x27;) &gt; -1 &amp;&amp; useMediaSource.indexOf(&#x27;tab&#x27;) === -1) {
    useMediaSource.splice(useMediaSource.indexOf(&#x27;audio&#x27;), 1);
    if (useMediaSource.length === 0) {
      useMediaSource = [self.MEDIA_SOURCE.SCREEN];
    }
  }

  self._throttle(function (runFn) {
    if (!runFn) {
      if (self._initOptions.throttlingShouldThrowError) {
        var throttleLimitError = &#x27;Unable to run as throttle interval has not reached (&#x27; + self._initOptions.throttleIntervals.shareScreen + &#x27;ms).&#x27;;
        log.error(throttleLimitError);

        if (typeof callback === &#x27;function&#x27;) {
          callback(new Error(throttleLimitError), null);
        }
      }
      return;
    }

    var settings = {
      settings: {
        audio: enableAudioSettings,
        video: {
          screenshare: true,
          exactConstraints: false
        }
      },
      getUserMediaSettings: {
        audio: false,
        video: {
          mediaSource: useMediaSource
        }
      }
    };

    if (AdapterJS.webrtcDetectedType === &#x27;plugin&#x27; &amp;&amp; useMediaSourceId) {
      settings.getUserMediaSettings.video.optional = [{
        screenId: useMediaSourceId
      }];
    }

    var mediaAccessSuccessFn = function (stream) {
      self.off(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn);

      if (self._inRoom) {
        self._trigger(&#x27;incomingStream&#x27;, self._user.sid, stream, true, self.getPeerInfo(), true, stream.id || stream.label);
        self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
        var shouldRenegotiate = true;

        if (self._streams.userMedia &amp;&amp; self._streams.userMedia.stream &amp;&amp; Array.isArray(self._streams.userMedia.stream.getVideoTracks()) &amp;&amp; self._streams.userMedia.stream.getVideoTracks().length) {
          shouldRenegotiate = false;
        }

        if (AdapterJS.webrtcDetectedBrowser === &#x27;edge&#x27;) {
          shouldRenegotiate = true;
        }

        if (shouldRenegotiate) {
          if (Object.keys(self._peerConnections).length &gt; 0 || self._hasMCU) {
            stream.wasNegotiated = true;
            self._refreshPeerConnection(Object.keys(self._peerConnections), false, {}, function (err, success) {
              if (err) {
                log.error(&#x27;Failed refreshing connections for shareScreen() -&gt;&#x27;, err);
                if (typeof callback === &#x27;function&#x27;) {
                  callback(new Error(&#x27;Failed refreshing connections.&#x27;), null);
                }
                return;
              }
              if (typeof callback === &#x27;function&#x27;) {
                callback(null, stream);
              }
            });
          } else if (typeof callback === &#x27;function&#x27;) {
            callback(null, stream);
          }
        } else {
          var gDMVideoTrack = stream.getVideoTracks()[0];
          var gUMVideoTrack = self._streams.userMedia.stream.getVideoTracks()[0];
          self._replaceTrack(gUMVideoTrack.id, gDMVideoTrack);
        }
      } else if (typeof callback === &#x27;function&#x27;) {
        callback(null, stream);
      }
    };

    var mediaAccessErrorFn = function (error) {
      self.off(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn);

      if (typeof callback === &#x27;function&#x27;) {
        callback(error, null);
      }
    };

    self.once(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn, function (stream, isScreensharing) {
      return isScreensharing;
    });

    self.once(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn, function (error, isScreensharing) {
      return isScreensharing;
    });

    var getUserMediaAudioSettings = enableAudioSettings ? {
      echoCancellation: enableAudioSettings.echoCancellation
    } : false;

    try {
      var hasDefaultAudioTrack = false;
      if (enableAudioSettings) {
        if (AdapterJS.webrtcDetectedBrowser === &#x27;firefox&#x27;) {
          hasDefaultAudioTrack = true;
          settings.getUserMediaSettings.audio = getUserMediaAudioSettings;
        } else if (useMediaSource.indexOf(&#x27;audio&#x27;) &gt; -1 &amp;&amp; useMediaSource.indexOf(&#x27;tab&#x27;) &gt; -1) {
          hasDefaultAudioTrack = true;
          settings.getUserMediaSettings.audio = {};
        }
      }

      var onSuccessCbFn = function (stream) {
        if (hasDefaultAudioTrack || !enableAudioSettings) {
          self._onStreamAccessSuccess(stream, settings, true, false);
          return;
        }

        settings.getUserMediaSettings.audio = getUserMediaAudioSettings;

        var onAudioSuccessCbFn = function (audioStream) {
          try {
            audioStream.addTrack(stream.getVideoTracks()[0]);

            self.once(&#x27;mediaAccessSuccess&#x27;, function () {
              self._streams.screenshare.streamClone = stream;
            }, function (stream, isScreensharing) {
              return isScreensharing;
            });

            self._onStreamAccessSuccess(audioStream, settings, true, false);

          } catch (error) {
            log.error(&#x27;Failed retrieving audio stream for screensharing stream&#x27;, error);
            self._onStreamAccessSuccess(stream, settings, true, false);
          }
        };

        var onAudioErrorCbFn = function (error) {
          log.error(&#x27;Failed retrieving audio stream for screensharing stream&#x27;, error);
          self._onStreamAccessSuccess(stream, settings, true, false);
        };

        navigator.getUserMedia({ audio: getUserMediaAudioSettings }, onAudioSuccessCbFn, onAudioErrorCbFn);
      };

      var onErrorCbFn = function (error) {
        self._onStreamAccessError(error, settings, true, false);
        if (typeof callback === &#x27;function&#x27;) {
          callback(error, null);
        }
      };

      if (typeof (AdapterJS || {}).webRTCReady !== &#x27;function&#x27;) {
        return onErrorCbFn(new Error(&#x27;Failed to call getUserMedia() as AdapterJS is not yet loaded!&#x27;));
      }

      AdapterJS.webRTCReady(function () {
        if (AdapterJS.webrtcDetectedBrowser === &#x27;edge&#x27; &amp;&amp; typeof navigator.getDisplayMedia === &#x27;function&#x27;) {
          navigator.getDisplayMedia(settings.getUserMediaSettings).then(function(stream) {
            onSuccessCbFn(stream);
          }).catch(function(err) {
            onErrorCbFn(err);
          });
        } else if (typeof navigator.mediaDevices.getDisplayMedia === &#x27;function&#x27;) {
          navigator.mediaDevices.getDisplayMedia(settings.getUserMediaSettings).then(function(stream) {
            onSuccessCbFn(stream);
          }).catch(function(err) {
            onErrorCbFn(err);
          });
        } else {
          navigator.getUserMedia(settings.getUserMediaSettings, onSuccessCbFn, onErrorCbFn);
        }
      });
    } catch (error) {
      self._onStreamAccessError(error, settings, true, false);
    }
  }, &#x27;shareScreen&#x27;, self._initOptions.throttleIntervals.shareScreen);
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that broadcasted events from &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_sendMessage&quot;&gt;&lt;code&gt;sendMessage()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_unlockRoom&quot;&gt;&lt;code&gt;unlockRoom()&lt;/code&gt; method&lt;/a&gt; and
 *   &lt;a href=&quot;#method_lockRoom&quot;&gt;&lt;code&gt;lockRoom()&lt;/code&gt; method&lt;/a&gt; may be queued when
 *   sent within less than an interval.
 * &lt;/blockquote&gt;
 * Function that stops &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt;.
 * @method stopScreen
 * @example
 *   function stopScreen () {
 *     skylinkDemo.stopScreen();
 *   }
 *
 *   skylinkDemo.shareScreen();
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Checks if there is &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt;. &lt;ol&gt;
 *   &lt;li&gt;If there is &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt;: &lt;ol&gt;
 *   &lt;li&gt;Stop &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; Stream. &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessStopped&quot;&gt;&lt;code&gt;mediaAccessStopped&lt;/code&gt; event&lt;/a&gt;
 *   triggers parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;If User is in Room: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_streamEnded&quot;&gt;&lt;code&gt;streamEnded&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;If User is in Room: &lt;small&gt;&lt;b&gt;SKIP&lt;/b&gt; this step if &lt;code&gt;stopScreen()&lt;/code&gt;
 *   was invoked from &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt; &lt;ol&gt;
 *   &lt;li&gt;If there is &lt;a href=&quot;#method_getUserMedia&quot;&gt; &lt;code&gt;getUserMedia()&lt;/code&gt;Stream&lt;/a&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_incomingStream&quot;&gt;&lt;code&gt;incomingStream&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;stream&lt;/code&gt; as
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Invoke &lt;a href=&quot;#method_refreshConnection&quot;&gt;&lt;code&gt;refreshConnection()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;
 *   &lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.6.0
 */
Skylink.prototype.stopScreen = function () {
  var self = this;
  if (self._streams.screenshare) {
    if (self._inRoom) {
      if (self._streams.userMedia &amp;&amp; self._streams.userMedia.stream) {
        self._trigger(&#x27;incomingStream&#x27;, self._user.sid, self._streams.userMedia.stream, true, self.getPeerInfo(),
          false, self._streams.userMedia.stream.id || self._streams.userMedia.stream.label);
        self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
      }

      if (self._streams.screenshare.stream.wasNegotiated === true) {
        this._refreshPeerConnection(Object.keys(this._peerConnections), {}, false);
      } else {
        var gDMVideoTrack = self._streams.screenshare.stream.getVideoTracks()[0];
        var gUMVideoTrack = self._streams.userMedia.stream.getVideoTracks()[0];

        self._replaceTrack(gDMVideoTrack.id, gUMVideoTrack);
      }
    }
    self._stopStreams({
      screenshare: true
    });
  }
};

/**
 * Function that returns the camera and microphone sources.
 * @method getStreamSources
 * @param {Function} callback The callback function fired when request has completed.
 *   &lt;small&gt;Function parameters signature is &lt;code&gt;function (success)&lt;/code&gt;&lt;/small&gt;
 * @param {JSON} callback.success The success result in request.
 *   &lt;small&gt;Object signature is the list of sources.&lt;/small&gt;
 * @param {JSON} callback.success.audio The list of audio input (microphone) and output (speakers) sources.
 * @param {Array} callback.success.audio.input The list of audio input (microphone) sources.
 * @param {JSON} callback.success.audio.input.#index The audio input source item.
 * @param {String} callback.success.audio.input.#index.deviceId The audio input source item device ID.
 * @param {String} callback.success.audio.input.#index.label The audio input source item device label name.
 * @param {String} [callback.success.audio.input.#index.groupId] The audio input source item device physical device ID.
 * &lt;small&gt;Note that there can be different &lt;code&gt;deviceId&lt;/code&gt; due to differing sources but can share a
 * &lt;code&gt;groupId&lt;/code&gt; because it&#x27;s the same device.&lt;/small&gt;
 * @param {Array} callback.success.audio.output The list of audio output (speakers) sources.
 * @param {JSON} callback.success.audio.output.#index The audio output source item.
 * &lt;small&gt;Object signature matches &lt;code&gt;callback.success.audio.input.#index&lt;/code&gt; format.&lt;/small&gt;
 * @param {JSON} callback.success.video The list of video input (camera) sources.
 * @param {Array} callback.success.video.input The list of video input (camera) sources.
 * @param {JSON} callback.success.video.input.#index The video input source item.
 * &lt;small&gt;Object signature matches &lt;code&gt;callback.success.audio.input.#index&lt;/code&gt; format.&lt;/small&gt;
 * @example
 *   // Example 1: Retrieve the getUserMedia() stream with selected source ID.
 *   skylinkDemo.getStreamSources(function (sources) {
 *     skylinkDemo.getUserMedia({
 *       audio: sources.audio.input[0].deviceId,
 *       video: sources.video.input[0].deviceId
 *     });
 *   });
 *
 *   // Example 2: Set the output audio speaker (Chrome 49+ supported only)
 *   skylinkDemo.getStreamSources(function (sources) {
 *     var videoElement = document.getElementById(&#x27;video&#x27;);
 *     if (videoElement &amp;&amp; typeof videoElement.setSinkId === &#x27;function&#x27;) {
 *       videoElement.setSinkId(sources.audio.output[0].deviceId)
 *     }
 *   });
 * @for Skylink
 * @since 0.6.27
 */
Skylink.prototype.getStreamSources = function(callback) {
  var outputSources = {
    audio: {
      input: [],
      output: []
    },
    video: {
      input: []
    }
  };

  if (typeof callback !== &#x27;function&#x27;) {
    return log.error(&#x27;Please provide the callback.&#x27;);
  }

  var sourcesListFn = function (sources) {
    sources.forEach(function (sourceItem) {
      var item = {
        deviceId: sourceItem.deviceId || sourceItem.sourceId || &#x27;default&#x27;,
        label: sourceItem.label,
        groupId: sourceItem.groupId || null
      };

      item.label = item.label || &#x27;Source for &#x27; + item.deviceId;

      if ([&#x27;audio&#x27;, &#x27;audioinput&#x27;].indexOf(sourceItem.kind) &gt; -1) {
        outputSources.audio.input.push(item);
      } else if ([&#x27;video&#x27;, &#x27;videoinput&#x27;].indexOf(sourceItem.kind) &gt; -1) {
        outputSources.video.input.push(item);
      } else if (sourceItem.kind === &#x27;audiooutput&#x27;) {
        outputSources.audio.output.push(item);
      }
    });

    callback(outputSources);
  };

  if (navigator.mediaDevices &amp;&amp; typeof navigator.mediaDevices.enumerateDevices === &#x27;function&#x27;) {
    navigator.mediaDevices.enumerateDevices().then(sourcesListFn);
  } else if (window.MediaStreamTrack &amp;&amp; typeof MediaStreamTrack.getSources === &#x27;function&#x27;) {
    MediaStreamTrack.getSources(sourcesListFn);
  } else if (typeof navigator.getUserMedia === &#x27;function&#x27;) {
    sourcesListFn([
      { deviceId: &#x27;default&#x27;, kind: &#x27;audioinput&#x27;, label: &#x27;Default Audio Track&#x27; },
      { deviceId: &#x27;default&#x27;, kind: &#x27;videoinput&#x27;, label: &#x27;Default Video Track&#x27; }
    ]);
  } else {
    sourcesListFn([]);
  }
};

/**
 * Function that returns the screensharing sources.
 * @method getScreenSources
 * @param {Function} callback The callback function fired when request has completed.
 *   &lt;small&gt;Function parameters signature is &lt;code&gt;function (success)&lt;/code&gt;&lt;/small&gt;
 * @param {JSON} callback.success The success result in request.
 *   &lt;small&gt;Object signature is the list of sources.&lt;/small&gt;
 * @param {JSON} callback.success The list of screensharing media sources and screen sources.
 * @param {Array} callback.success.mediaSource The array of screensharing media sources.
 * @param {String} callback.success.mediaSource.#index The screensharing media source item.
 * [Rel: Skylink.MEDIA_SOURCE]
 * @param {Array} callback.success.mediaSourceInput The list of specific media source screen inputs.
 * @param {JSON} callback.success.mediaSourceInput.#index The media source screen input item.
 * @param {String} callback.success.mediaSourceInput.#index.sourceId The screen input item ID.
 * @param {String} callback.success.mediaSourceInput.#index.label The screen input item label name.
 * @param {String} callback.success.mediaSourceInput.#index.mediaSource The screen input item media source it belongs to.
 * [Rel: Skylink.MEDIA_SOURCE]
 * @example
 *   // Example 1: Retrieve the list of available shareScreen() sources.
 *   skylinkDemo.getScreenSources(function (sources) {
 *     skylinkDemo.shareScreen(sources.mediaSource[0] || null);
 *   });
 *
 *   // Example 2: Retrieve the list of available shareScreen() sources with a specific item.
 *   skylinkDemo.getScreenSources(function (sources) {
 *     if (sources.mediaSourceInput[0]) {
 *       skylinkDemo.shareScreen({
 *         mediaSource: mediaSourceInput[0].mediaSource,
 *         sourceId: mediaSourceInput[0].sourceId
 *       });
 *     } else {
 *       skylinkDemo.shareScreen();
 *     }
 *   });
 * @for Skylink
 * @since 0.6.27
 */
Skylink.prototype.getScreenSources = function(callback) {
  var outputSources = {
    mediaSource: [],
    mediaSourceInput: []
  };

  if (typeof callback !== &#x27;function&#x27;) {
    return log.error(&#x27;Please provide the callback.&#x27;);
  }

  // For chrome android 59+ has screensharing support behind chrome://flags (needs to be enabled by user)
  // Reference: https://bugs.chromium.org/p/chromium/issues/detail?id=487935
  if (navigator.userAgent.toLowerCase().indexOf(&#x27;android&#x27;) &gt; -1) {
    if (AdapterJS.webrtcDetectedBrowser === &#x27;chrome&#x27; &amp;&amp; AdapterJS.webrtcDetectedVersion &gt;= 59) {
      outputSources.mediaSource = [&#x27;screen&#x27;];
    }
    callback(outputSources);
    return;
  }

  // IE / Safari (plugin) needs commerical screensharing enabled
  if (AdapterJS.webrtcDetectedType === &#x27;plugin&#x27;) {
    AdapterJS.webRTCReady(function () {
      // IE / Safari (plugin) is not available or do not support screensharing
      if (AdapterJS.WebRTCPlugin.plugin &amp;&amp; AdapterJS.WebRTCPlugin.plugin.isScreensharingAvailable &amp;&amp;
        AdapterJS.WebRTCPlugin.plugin.HasScreensharingFeature) {
        outputSources.mediaSource = [&#x27;window&#x27;, &#x27;screen&#x27;];

        // Do not provide the error callback as well or it will throw NPError.
        if (typeof AdapterJS.WebRTCPlugin.plugin.getScreensharingSources === &#x27;function&#x27;) {
          AdapterJS.WebRTCPlugin.plugin.getScreensharingSources(function (sources) {
            sources.forEach(sources, function (sourceItem) {
              var item = {
                sourceId: sourceItem.id || sourceItem.sourceId || &#x27;default&#x27;,
                label: sourceItem.label,
                mediaSource: sourceItem.kind || &#x27;screen&#x27;
              };

              item.label = item.label || &#x27;Source for &#x27; + item.sourceId;
              outputSources.mediaSourceInput.push(item);
            });

            callback(outputSources);
          });
          return;
        }
      }

      callback(outputSources);
    });
    return;

  // Chrome 34+ and Opera 21(?)+ supports screensharing
  // Firefox 38(?)+ supports screensharing
  } else if ((AdapterJS.webrtcDetectedBrowser === &#x27;chrome&#x27; &amp;&amp; AdapterJS.webrtcDetectedVersion &gt;= 34) ||
    (AdapterJS.webrtcDetectedBrowser === &#x27;firefox&#x27; &amp;&amp; AdapterJS.webrtcDetectedVersion &gt;= 38) ||
    (AdapterJS.webrtcDetectedBrowser === &#x27;opera&#x27; &amp;&amp; AdapterJS.webrtcDetectedVersion &gt;= 21)) {
    // Just warn users for those who did not configure the Opera screensharing extension settings, it will not work!
    if (AdapterJS.webrtcDetectedBrowser === &#x27;opera&#x27; &amp;&amp; !(AdapterJS.extensionInfo &amp;&amp;
      AdapterJS.extensionInfo.opera &amp;&amp; AdapterJS.extensionInfo.opera.extensionId)) {
      log.warn(&#x27;Please ensure that your application allows Opera screensharing!&#x27;);
    }

    outputSources.mediaSource = [&#x27;window&#x27;, &#x27;screen&#x27;];

    // Chrome 52+ and Opera 39+ supports tab and audio
    // Reference: https://developer.chrome.com/extensions/desktopCapture
    if ((AdapterJS.webrtcDetectedBrowser === &#x27;chrome&#x27; &amp;&amp; AdapterJS.webrtcDetectedVersion &gt;= 52) ||
      (AdapterJS.webrtcDetectedBrowser === &#x27;opera&#x27; &amp;&amp; AdapterJS.webrtcDetectedVersion &gt;= 39)) {
      outputSources.mediaSource.push(&#x27;tab&#x27;, &#x27;audio&#x27;);

    // Firefox supports some other sources
    // Reference: http://fluffy.github.io/w3c-screen-share/#screen-based-video-constraints
    //            https://bugzilla.mozilla.org/show_bug.cgi?id=1313758
    //            https://bugzilla.mozilla.org/show_bug.cgi?id=1037405
    //            https://bugzilla.mozilla.org/show_bug.cgi?id=1313758
    } else if (AdapterJS.webrtcDetectedBrowser === &#x27;firefox&#x27;) {
      outputSources.mediaSource.push(&#x27;browser&#x27;, &#x27;camera&#x27;, &#x27;application&#x27;);
    }
  }

  callback(outputSources);
};

/**
 * Function that handles the muting of Stream audio and video tracks.
 * @method _muteStreams
 * @private
 * @for Skylink
 * @since 0.6.15
 */
Skylink.prototype._muteStreams = function () {
  var self = this;
  var hasVideo = false;
  var hasAudio = false;

  var muteFn = function (stream) {
    var audioTracks = stream.getAudioTracks();
    var videoTracks = stream.getVideoTracks();

    for (var a = 0; a &lt; audioTracks.length; a++) {
      audioTracks[a].enabled = !self._streamsMutedSettings.audioMuted;
      hasAudio = true;
    }

    for (var v = 0; v &lt; videoTracks.length; v++) {
      videoTracks[v].enabled = !self._streamsMutedSettings.videoMuted;
      hasVideo = true;
    }
  };

  if (self._streams.userMedia &amp;&amp; self._streams.userMedia.stream) {
    muteFn(self._streams.userMedia.stream);
  }

  if (self._streams.screenshare &amp;&amp; self._streams.screenshare.stream) {
    muteFn(self._streams.screenshare.stream);
  }

  if (self._streams.screenshare &amp;&amp; self._streams.screenshare.streamClone) {
    muteFn(self._streams.screenshare.streamClone);
  }

  if (AdapterJS.webrtcDetectedBrowser === &#x27;edge&#x27;) {
    for (var peerId in self._peerConnections) {
      if (self._peerConnections.hasOwnProperty(peerId) &amp;&amp; self._peerConnections[peerId]) {
        var localStreams = self._peerConnections[peerId].getLocalStreams();
        for (var s = 0; s &lt; localStreams.length; s++) {
          muteFn(localStreams[s]);
        }
      }
    }
  }

  log.debug(&#x27;Updated Streams muted status -&gt;&#x27;, self._streamsMutedSettings);

  return {
    hasVideo: hasVideo,
    hasAudio: hasAudio
  };
};

/**
 * Function that handles stopping the Stream streaming.
 * @method _stopStreams
 * @private
 * @for Skylink
 * @since 0.6.15
 */
Skylink.prototype._stopStreams = function (options) {
  var self = this;
  var stopFn = function (stream) {
    var streamId = stream.id || stream.label;
    log.debug([null, &#x27;MediaStream&#x27;, streamId, &#x27;Stopping Stream -&gt;&#x27;], stream);

    try {
      var audioTracks = stream.getAudioTracks();
      var videoTracks = stream.getVideoTracks();

      for (var a = 0; a &lt; audioTracks.length; a++) {
        audioTracks[a].stop();
      }

      for (var v = 0; v &lt; videoTracks.length; v++) {
        videoTracks[v].stop();
      }

    } catch (error) {
      stream.stop();
    }

    if (self._streamsStoppedCbs[streamId]) {
      self._streamsStoppedCbs[streamId]();
      delete self._streamsStoppedCbs[streamId];
    }
  };

  var stopUserMedia = false;
  var stopScreenshare = false;
  var hasStoppedMedia = false;

  if (typeof options === &#x27;object&#x27;) {
    stopUserMedia = options.userMedia === true;
    stopScreenshare = options.screenshare === true;
  }

  if (stopUserMedia &amp;&amp; self._streams.userMedia) {
    if (self._streams.userMedia.stream) {
      stopFn(self._streams.userMedia.stream);
    }

    self._streams.userMedia = null;
    hasStoppedMedia = true;
  }

  if (stopScreenshare &amp;&amp; self._streams.screenshare) {
    if (self._streams.screenshare.streamClone) {
      stopFn(self._streams.screenshare.streamClone);
    }

    if (self._streams.screenshare.stream) {
      stopFn(self._streams.screenshare.stream);
    }

    self._streams.screenshare = null;
    hasStoppedMedia = true;
  }

  if (self._inRoom &amp;&amp; hasStoppedMedia) {
    self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
  }

  log.log(&#x27;Stopping Streams with settings -&gt;&#x27;, options);
};

/**
 * Function that parses the &lt;code&gt;getUserMedia()&lt;/code&gt; settings provided.
 * @method _parseStreamSettings
 * @private
 * @for Skylink
 * @since 0.6.15
 */
Skylink.prototype._parseStreamSettings = function(options) {
  var settings = {
    settings: { audio: false, video: false },
    mutedSettings: { shouldAudioMuted: false, shouldVideoMuted: false },
    getUserMediaSettings: { audio: false, video: false }
  };

  if (options.audio) {
    // For Edge to work since they do not support the advanced constraints yet
    settings.settings.audio = {
      stereo: false,
      exactConstraints: !!options.useExactConstraints,
      echoCancellation: true
    };
    settings.getUserMediaSettings.audio = {
      echoCancellation: true
    };

    if (typeof options.audio === &#x27;object&#x27;) {
      if (typeof options.audio.stereo === &#x27;boolean&#x27;) {
        settings.settings.audio.stereo = options.audio.stereo;
      }

      if (typeof options.audio.useinbandfec === &#x27;boolean&#x27;) {
        settings.settings.audio.useinbandfec = options.audio.useinbandfec;
      }

      if (typeof options.audio.usedtx === &#x27;boolean&#x27;) {
        settings.settings.audio.usedtx = options.audio.usedtx;
      }

      if (typeof options.audio.maxplaybackrate === &#x27;number&#x27; &amp;&amp;
        options.audio.maxplaybackrate &gt;= 8000 &amp;&amp; options.audio.maxplaybackrate &lt;= 48000) {
        settings.settings.audio.maxplaybackrate = options.audio.maxplaybackrate;
      }

      if (typeof options.audio.mute === &#x27;boolean&#x27;) {
        settings.mutedSettings.shouldAudioMuted = options.audio.mute;
      }

      // Not supported in Edge browser features
      if (AdapterJS.webrtcDetectedBrowser !== &#x27;edge&#x27;) {
        if (typeof options.audio.echoCancellation === &#x27;boolean&#x27;) {
          settings.settings.audio.echoCancellation = options.audio.echoCancellation;
          settings.getUserMediaSettings.audio.echoCancellation = options.audio.echoCancellation;
        }

        if (Array.isArray(options.audio.optional)) {
          settings.settings.audio.optional = clone(options.audio.optional);
          settings.getUserMediaSettings.audio.optional = clone(options.audio.optional);
        }

        if (options.audio.deviceId &amp;&amp; typeof options.audio.deviceId === &#x27;string&#x27; &amp;&amp;
          AdapterJS.webrtcDetectedBrowser !== &#x27;firefox&#x27;) {
          settings.settings.audio.deviceId = options.audio.deviceId;
          settings.getUserMediaSettings.audio.deviceId = options.useExactConstraints ?
            { exact: options.audio.deviceId } : { ideal: options.audio.deviceId };
        }
      }
    }

    if (AdapterJS.webrtcDetectedBrowser === &#x27;edge&#x27;) {
      settings.getUserMediaSettings.audio = true;
    }
  }

  if (options.video) {
    // For Edge to work since they do not support the advanced constraints yet
    settings.settings.video = {
      resolution: clone(this.VIDEO_RESOLUTION.VGA),
      screenshare: false,
      exactConstraints: !!options.useExactConstraints
    };
    settings.getUserMediaSettings.video = {};

    if (typeof options.video === &#x27;object&#x27;) {
      if (typeof options.video.mute === &#x27;boolean&#x27;) {
        settings.mutedSettings.shouldVideoMuted = options.video.mute;
      }

      if (Array.isArray(options.video.optional)) {
        settings.settings.video.optional = clone(options.video.optional);
        settings.getUserMediaSettings.video.optional = clone(options.video.optional);
      }

      if (options.video.deviceId &amp;&amp; typeof options.video.deviceId === &#x27;string&#x27;) {
        settings.settings.video.deviceId = options.video.deviceId;
        settings.getUserMediaSettings.video.deviceId = options.useExactConstraints ?
          { exact: options.video.deviceId } : { ideal: options.video.deviceId };
      }

      if (options.video.resolution &amp;&amp; typeof options.video.resolution === &#x27;object&#x27;) {
        if ((options.video.resolution.width &amp;&amp; typeof options.video.resolution.width === &#x27;object&#x27;) ||
          typeof options.video.resolution.width === &#x27;number&#x27;) {
          settings.settings.video.resolution.width = options.video.resolution.width;
        }
        if ((options.video.resolution.height &amp;&amp; typeof options.video.resolution.height === &#x27;object&#x27;) ||
          typeof options.video.resolution.height === &#x27;number&#x27;) {
          settings.settings.video.resolution.height = options.video.resolution.height;
        }
      }

      settings.getUserMediaSettings.video.width = typeof settings.settings.video.resolution.width === &#x27;object&#x27; ?
        settings.settings.video.resolution.width : (options.useExactConstraints ?
        { exact: settings.settings.video.resolution.width } : { max: settings.settings.video.resolution.width });

      settings.getUserMediaSettings.video.height = typeof settings.settings.video.resolution.height === &#x27;object&#x27; ?
        settings.settings.video.resolution.height : (options.useExactConstraints ?
        { exact: settings.settings.video.resolution.height } : { max: settings.settings.video.resolution.height });

      if ((options.video.frameRate &amp;&amp; typeof options.video.frameRate === &#x27;object&#x27;) ||
        typeof options.video.frameRate === &#x27;number&#x27; &amp;&amp; AdapterJS.webrtcDetectedType !== &#x27;plugin&#x27;) {
        settings.settings.video.frameRate = options.video.frameRate;
        settings.getUserMediaSettings.video.frameRate = typeof settings.settings.video.frameRate === &#x27;object&#x27; ?
          settings.settings.video.frameRate : (options.useExactConstraints ?
          { exact: settings.settings.video.frameRate } : { max: settings.settings.video.frameRate });
      }

      if (options.video.facingMode &amp;&amp; [&#x27;string&#x27;, &#x27;object&#x27;].indexOf(typeof options.video.facingMode) &gt; -1 &amp;&amp; AdapterJS.webrtcDetectedType === &#x27;plugin&#x27;) {
        settings.settings.video.facingMode = options.video.facingMode;
        settings.getUserMediaSettings.video.facingMode = typeof settings.settings.video.facingMode === &#x27;object&#x27; ?
          settings.settings.video.facingMode : (options.useExactConstraints ?
          { exact: settings.settings.video.facingMode } : { max: settings.settings.video.facingMode });
      }
    } else {
      settings.getUserMediaSettings.video = {
        width: options.useExactConstraints ? { exact: settings.settings.video.resolution.width } :
          { max: settings.settings.video.resolution.width },
        height: options.useExactConstraints ? { exact: settings.settings.video.resolution.height } :
          { max: settings.settings.video.resolution.height }
      };
    }

    if (AdapterJS.webrtcDetectedBrowser === &#x27;edge&#x27;) {
      settings.settings.video = {
        screenshare: false,
        exactConstraints: !!options.useExactConstraints
      };
      settings.getUserMediaSettings.video = true;
    }
  }

  return settings;
};

/**
 * Function that parses the mediastream tracks for details.
 * @method _parseStreamTracksInfo
 * @private
 * @for Skylink
 * @since 0.6.31
 */
Skylink.prototype._parseStreamTracksInfo = function (streamKey, callback) {
	var self = this;
	var stream = self._streams[streamKey].stream;

	if (!stream) {
		log.warn(&#x27;Unable to parse stream tracks information as the stream is not defined&#x27;);
		return callback();
	}

	self._streams[streamKey].tracks = {
 		audio: null,
 		video: null
 	};

	// Currently, we are sending 1 audio and video track.
  var audioTracks = stream.getAudioTracks();
  var videoTracks = stream.getVideoTracks();

  if (audioTracks.length &gt; 0) {
  	self._streams[streamKey].tracks.audio = {
  		id: audioTracks[0].id || &#x27;&#x27;,
  		label: audioTracks[0].label || &#x27;audio_track_0&#x27;
  	};
  }

  if (videoTracks.length === 0) {
  	return callback();
  }

  self._streams[streamKey].tracks.video = {
		id: videoTracks[0].id || &#x27;&#x27;,
		label: videoTracks[0].label || &#x27;video_track_0&#x27;,
		width: null,
		height: null
	};

  callback();
  /**
	// Append the stream to a dummy &lt;video&gt; element to retrieve the resolution width and height.
  var videoElement = document.createElement(&#x27;video&#x27;);
  videoElement.autoplay = true;
  // Mute the audio of the &lt;video&gt; element to prevent feedback.
  videoElement.muted = true;
  videoElement.volume = 0;

  var onVideoLoaded = function () {
  	if (!self._streams[streamKey]) {
  		return;
  	}
  	self._streams[streamKey].tracks.video.width = videoElement.videoWidth;
  	self._streams[streamKey].tracks.video.height = videoElement.videoHeight;

  	videoElement.srcObject = null;
  	callback();
  };

  // Because the plugin does not support the &quot;loadeddata&quot; event.
  if (AdapterJS.webrtcDetectedType === &#x27;plugin&#x27;) {
    setTimeout(onVideoLoaded, 1500);

  } else {
    videoElement.addEventListener(&#x27;loadeddata&#x27;, onVideoLoaded);
  }

  AdapterJS.attachMediaStream(videoElement, stream);
   */
}

/**
 * Function that handles the native &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API success callback result.
 * @method _onStreamAccessSuccess
 * @private
 * @for Skylink
 * @since 0.3.0
 */
Skylink.prototype._onStreamAccessSuccess = function(stream, settings, isScreenSharing, isAudioFallback) {
  var self = this;
  var streamId = stream.id || stream.label;
  var streamHasEnded = false;

  log.log([null, &#x27;MediaStream&#x27;, streamId, &#x27;Has access to stream -&gt;&#x27;], stream);

  // Stop previous stream
  if (!isScreenSharing &amp;&amp; self._streams.userMedia) {
    self._stopStreams({
      userMedia: true,
      screenshare: false
    });

  } else if (isScreenSharing &amp;&amp; self._streams.screenshare) {
    self._stopStreams({
      userMedia: false,
      screenshare: true
    });
  }

  self._streamsStoppedCbs[streamId] = function () {
    log.log([null, &#x27;MediaStream&#x27;, streamId, &#x27;Stream has ended&#x27;]);
    streamHasEnded = true;
    self._trigger(&#x27;mediaAccessStopped&#x27;, !!isScreenSharing, !!isAudioFallback, streamId);

    if (self._inRoom) {
      log.debug([null, &#x27;MediaStream&#x27;, streamId, &#x27;Sending Stream ended status to Peers&#x27;]);

      self._sendChannelMessage({
        type: self._SIG_MESSAGE_TYPE.STREAM,
        mid: self._user.sid,
        rid: self._room.id,
        cid: self._key,
        streamId: streamId,
        settings: settings.settings,
        status: &#x27;ended&#x27;
      });

      self._trigger(&#x27;streamEnded&#x27;, self._user.sid, self.getPeerInfo(), true, !!isScreenSharing, streamId);

      if (isScreenSharing &amp;&amp; self._streams.screenshare &amp;&amp; self._streams.screenshare.stream &amp;&amp;
        (self._streams.screenshare.stream.id || self._streams.screenshare.stream.label) === streamId) {
        self._streams.screenshare = null;

      } else if (!isScreenSharing &amp;&amp; self._streams.userMedia &amp;&amp; self._streams.userMedia.stream &amp;&amp;
        (self._streams.userMedia.stream.id || self._streams.userMedia.stream.label) === streamId) {
        self._streams.userMedia = null;
      }
    }
  };

  // Handle event for Chrome / Opera
  if ([&#x27;chrome&#x27;, &#x27;opera&#x27;].indexOf(AdapterJS.webrtcDetectedBrowser) &gt; -1) {
    stream.oninactive = function () {
      if (self._streamsStoppedCbs[streamId]) {
        self._streamsStoppedCbs[streamId]();
        delete self._streamsStoppedCbs[streamId];
      }
    };

    if (isScreenSharing &amp;&amp; stream.getVideoTracks().length &gt; 0) {
      stream.getVideoTracks()[0].onended = function () {
        setTimeout(function () {
          if (!streamHasEnded &amp;&amp; self._inRoom) {
            self.stopScreen();
          }
        }, 350);
      };
    }

  // Handle event for Firefox (use an interval)
  } else if (AdapterJS.webrtcDetectedBrowser === &#x27;firefox&#x27;) {
    stream.endedInterval = setInterval(function () {
      if (typeof stream.recordedTime === &#x27;undefined&#x27;) {
        stream.recordedTime = 0;
      }
      if (stream.recordedTime === stream.currentTime) {
        clearInterval(stream.endedInterval);

        if (self._streamsStoppedCbs[streamId]) {
          self._streamsStoppedCbs[streamId]();
          delete self._streamsStoppedCbs[streamId];
        }

      } else {
        stream.recordedTime = stream.currentTime;
      }
    }, 1000);

  } else {
    stream.onended = function () {
      if (self._streamsStoppedCbs[streamId]) {
        self._streamsStoppedCbs[streamId]();
        delete self._streamsStoppedCbs[streamId];
      }
    };
  }

  if ((settings.settings.audio &amp;&amp; stream.getAudioTracks().length === 0) ||
    (settings.settings.video &amp;&amp; stream.getVideoTracks().length === 0)) {

    var tracksNotSameError = &#x27;Expected audio tracks length with &#x27; +
      (settings.settings.audio ? &#x27;1&#x27; : &#x27;0&#x27;) + &#x27; and video tracks length with &#x27; +
      (settings.settings.video ? &#x27;1&#x27; : &#x27;0&#x27;) + &#x27; but received audio tracks length &#x27; +
      &#x27;with &#x27; + stream.getAudioTracks().length + &#x27; and video &#x27; +
      &#x27;tracks length with &#x27; + stream.getVideoTracks().length;

    log.warn([null, &#x27;MediaStream&#x27;, streamId, tracksNotSameError]);

    var requireAudio = !!settings.settings.audio;
    var requireVideo = !!settings.settings.video;

    if (settings.settings.audio &amp;&amp; stream.getAudioTracks().length === 0) {
      settings.settings.audio = false;
    }

    if (settings.settings.video &amp;&amp; stream.getVideoTracks().length === 0) {
      settings.settings.video = false;
    }

    self._trigger(&#x27;mediaAccessFallback&#x27;, {
      error: new Error(tracksNotSameError),
      diff: {
        video: { expected: requireVideo ? 1 : 0, received: stream.getVideoTracks().length },
        audio: { expected: requireAudio ? 1 : 0, received: stream.getAudioTracks().length }
      }
    }, self.MEDIA_ACCESS_FALLBACK_STATE.FALLBACKED, !!isScreenSharing, !!isAudioFallback, streamId);
  }

  self._streams[ isScreenSharing ? &#x27;screenshare&#x27; : &#x27;userMedia&#x27; ] = {
  	id: streamId,
    stream: stream,
    settings: settings.settings,
    constraints: settings.getUserMediaSettings
  };

  self._muteStreams();

  self._parseStreamTracksInfo(isScreenSharing ? &#x27;screenshare&#x27; : &#x27;userMedia&#x27;, function () {
  	self._trigger(&#x27;mediaAccessSuccess&#x27;, stream, !!isScreenSharing, !!isAudioFallback, streamId);
  });
};

/**
 * Function that handles the native &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API failure callback result.
 * @method _onStreamAccessError
 * @private
 * @for Skylink
 * @since 0.6.15
 */
Skylink.prototype._onStreamAccessError = function(error, settings, isScreenSharing) {
  var self = this;

  if (!isScreenSharing &amp;&amp; settings.settings.audio &amp;&amp; settings.settings.video &amp;&amp; self._initOptions.audioFallback) {
    log.debug(&#x27;Fallbacking to retrieve audio only Stream&#x27;);

    self._trigger(&#x27;mediaAccessFallback&#x27;, {
      error: error,
      diff: null
    }, self.MEDIA_ACCESS_FALLBACK_STATE.FALLBACKING, false, true);

    var onAudioSuccessCbFn = function (stream) {
      self._onStreamAccessSuccess(stream, settings, false, true);
    };

    var onAudioErrorCbFn = function (error) {
      log.error(&#x27;Failed fallbacking to retrieve audio only Stream -&gt;&#x27;, error);

      self._trigger(&#x27;mediaAccessError&#x27;, error, false, true);
      self._trigger(&#x27;mediaAccessFallback&#x27;, {
        error: error,
        diff: null
      }, self.MEDIA_ACCESS_FALLBACK_STATE.ERROR, false, true);
    };

    navigator.getUserMedia({ audio: true }, onAudioSuccessCbFn, onAudioErrorCbFn);
    return;
  }
  if (isScreenSharing) {
    log.error(&#x27;Failed retrieving screensharing Stream -&gt;&#x27;, error);
  } else {
    log.error(&#x27;Failed retrieving camera Stream -&gt;&#x27;, error);
  }


  self._trigger(&#x27;mediaAccessError&#x27;, error, !!isScreenSharing, false);
};

/**
 * Function that handles the &lt;code&gt;RTCPeerConnection.onaddstream&lt;/code&gt; remote MediaStream received.
 * @method _onRemoteStreamAdded
 * @private
 * @for Skylink
 * @since 0.5.2
 */
Skylink.prototype._onRemoteStreamAdded = function(targetMid, stream, isScreenSharing) {
  var self = this;
  var streamId = (self._peerConnections[targetMid] &amp;&amp; self._peerConnections[targetMid].remoteStreamId) || stream.id || stream.label;

  // if (!self._peerInformations[targetMid]) {
  //   log.warn([targetMid, &#x27;MediaStream&#x27;, streamId, &#x27;Received remote stream when peer is not connected. Ignoring stream -&gt;&#x27;], stream);
  //   return;
  // }

  /*if (!self._peerInformations[targetMid].settings.audio &amp;&amp;
    !self._peerInformations[targetMid].settings.video &amp;&amp; !isScreenSharing) {
    log.log([targetMid, &#x27;MediaStream&#x27;, stream.id,
      &#x27;Receive remote stream but ignoring stream as it is empty -&gt;&#x27;
      ], stream);
    return;
  }*/
  log.log([targetMid, &#x27;MediaStream&#x27;, streamId, &#x27;Received remote stream -&gt;&#x27;], stream);

  if (isScreenSharing) {
    log.log([targetMid, &#x27;MediaStream&#x27;, streamId, &#x27;Peer is having a screensharing session with user&#x27;]);
  }

  self._trigger(&#x27;incomingStream&#x27;, targetMid, stream, false, self.getPeerInfo(targetMid), isScreenSharing, streamId);
  self._trigger(&#x27;peerUpdated&#x27;, targetMid, self.getPeerInfo(targetMid), false);
};


/**
 * Function that sets User&#x27;s Stream to send to Peer connection.
 * Priority for &lt;code&gt;shareScreen()&lt;/code&gt; Stream over &lt;code&gt;getUserMedia()&lt;/code&gt; Stream.
 * @method _addLocalMediaStreams
 * @private
 * @for Skylink
 * @since 0.5.2
 */
Skylink.prototype._addLocalMediaStreams = function(peerId) {
  var self = this;

  // NOTE ALEX: here we could do something smarter
  // a mediastream is mainly a container, most of the info
  // are attached to the tracks. We should iterates over track and print
  try {
    log.log([peerId, null, null, &#x27;Adding local stream&#x27;]);

    var pc = self._peerConnections[peerId];

    if (pc) {
      var offerToReceiveAudio = !(!self._sdpSettings.connection.audio &amp;&amp; peerId !== &#x27;MCU&#x27;) &amp;&amp;
        self._getSDPCommonSupports(peerId, pc.remoteDescription).video;
      var offerToReceiveVideo = !(!self._sdpSettings.connection.video &amp;&amp; peerId !== &#x27;MCU&#x27;) &amp;&amp;
        self._getSDPCommonSupports(peerId, pc.remoteDescription).audio;

      if (pc.signalingState !== self.PEER_CONNECTION_STATE.CLOSED) {
        // Updates the streams accordingly
        var updateStreamFn = function (updatedStream) {
          if (updatedStream ? (pc.localStreamId ? updatedStream.id !== pc.localStreamId : true) : true) {

            pc.getSenders().forEach(function (sender) {
              pc.removeTrack(sender);
            });

            if (!offerToReceiveAudio &amp;&amp; !offerToReceiveVideo) {
              return;
            }

            if (updatedStream) {
              updatedStream.getTracks().forEach(function (track) {
                if ((track.kind === &#x27;audio&#x27; &amp;&amp; !offerToReceiveAudio) || (track.kind === &#x27;video&#x27; &amp;&amp; !offerToReceiveVideo)) {
                  return;
                }
                pc.addTrack(track, updatedStream);
              });

              pc.localStreamId = updatedStream.id || updatedStream.label;
              pc.localStream = updatedStream;
            }
          }
        };

        if (self._streams.screenshare &amp;&amp; self._streams.screenshare.stream) {
          log.debug([peerId, &#x27;MediaStream&#x27;, null, &#x27;Sending screen&#x27;], self._streams.screenshare.stream);

          updateStreamFn(self._streams.screenshare.stream);

        } else if (self._streams.userMedia &amp;&amp; self._streams.userMedia.stream) {
          log.debug([peerId, &#x27;MediaStream&#x27;, null, &#x27;Sending stream&#x27;], self._streams.userMedia.stream);

          updateStreamFn(self._streams.userMedia.stream);

        } else {
          log.warn([peerId, &#x27;MediaStream&#x27;, null, &#x27;No media to send. Will be only receiving&#x27;]);

          updateStreamFn(null);
        }

      } else {
        log.warn([peerId, &#x27;MediaStream&#x27;, null,
          &#x27;Not adding any stream as signalingState is closed&#x27;]);
      }
    } else {
      log.warn([peerId, &#x27;MediaStream&#x27;, self._mediaStream,
        &#x27;Not adding stream as peerconnection object does not exists&#x27;]);
    }
  } catch (error) {
    if ((error.message || &#x27;&#x27;).indexOf(&#x27;already added&#x27;) &gt; -1) {
      log.warn([peerId, null, null, &#x27;Not re-adding stream as LocalMediaStream is already added&#x27;], error);
    } else {
      // Fix errors thrown like NS_ERROR_UNEXPECTED
      log.error([peerId, null, null, &#x27;Failed adding local stream&#x27;], error);
    }
  }
};

/**
 * Function that handles ended streams.
 * @method _handleEndedStreams
 * @private
 * @for Skylink
 * @since 0.6.16
 */
Skylink.prototype._handleEndedStreams = function (peerId, checkStreamId) {
  var self = this;
  self._streamsSession[peerId] = self._streamsSession[peerId] || {};

  var renderEndedFn = function (streamId) {
    if (self._streamsSession[peerId][streamId]) {
      var peerInfo = clone(self.getPeerInfo(peerId));
      peerInfo.settings.audio = clone(self._streamsSession[peerId][streamId].audio);
      peerInfo.settings.video = clone(self._streamsSession[peerId][streamId].video);
      var hasScreenshare = peerInfo.settings.video &amp;&amp; typeof peerInfo.settings.video === &#x27;object&#x27; &amp;&amp;
        !!peerInfo.settings.video.screenshare;
      self._streamsSession[peerId][streamId] = false;
      self._trigger(&#x27;streamEnded&#x27;, peerId, peerInfo, false, hasScreenshare, streamId);
    }
  };

  if (checkStreamId) {
    renderEndedFn(checkStreamId);
  } else if (self._peerConnections[peerId]) {
    for (var streamId in self._streamsSession[peerId]) {
      if (self._streamsSession[peerId].hasOwnProperty(streamId) &amp;&amp; self._streamsSession[peerId][streamId]) {
        renderEndedFn(streamId);
      }
    }
  }
};

    </pre>
</div>

                  </div>
              </div>
          </div>
      </div>
  </div>
</div>
<script src="../assets/vendor/prettify/prettify-min.js"></script>
<script>prettyPrint();</script>
<script src="../assets/js/yui-prettify.js"></script>
<script src="../assets/../api.js"></script>
<script src="../assets/js/api-filter.js"></script>
<script src="../assets/js/api-list.js"></script>
<script src="../assets/js/api-search.js"></script>
<script src="../assets/js/apidocs.js"></script>
</body>
</html>
