<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>SkylinkJS 0.6.24</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- font and icon -->
    <link rel="shortcut icon" type="image/ico" href="../assets/favicon.ico">
    <link rel="stylesheet" href="../assets/vendor/prettify/prettify-min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600,700|Source+Sans+Pro" type="text/css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600,700|Source+Code+Pro" type="text/css">
    <!-- styling -->
    <link rel="stylesheet" href="../assets/vendor/css/bootstrap.min.css">
    <link rel="stylesheet" href="../assets/vendor/css/bootstrap-theme.min.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="../assets/css/style.css">
    <!-- scripts -->
    <script src="../assets/vendor/js/jquery.min.js"></script>
    <script src="../assets/vendor/js/bootstrap.min.js"></script>
    <script src="../assets/js/script.js"></script>
    <script src="http://yui.yahooapis.com/combo?3.9.1/build/yui/yui-min.js"></script>
</head>
<body>

<div id="doc">
  <nav id="hd" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a href="" class="navbar-brand">
          <img src="../assets/img/logo.svg" /><small>Version: 0.6.24</small>
        </a>
      </div>
      <div id="navbar" class="navbar-collapse collapse">
        <ul id="api-list" class="nav navbar-nav navbar-right">
  <li class="dropdown">
    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Getting Started Examples <span class="caret"></span></a>
    <ul class="dropdown-menu" role="menu">
      <li><a href="https://temasys.io/getting-started-with-webrtc-and-skylinkjs/">Setting up a Video Call</a></li>
      <li><a href="https://temasys.io/screensharing-with-skylinkjs/">Setting up Screensharing</a></li>
      <li><a href="https://temasys.io/building-a-simple-peer-to-peer-webrtc-chat/">Setting up a Chatroom</a></li>
    </ul>
  </li>
  
    <li><a href="../classes/Skylink.html">Documentation</a></li>
  
  <!--<li class="dropdown">
    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Classes <span class="caret"></span></a>
    <ul class="dropdown-menu" role="menu">
      
        <li><a href="../classes/Skylink.html">Skylink</a></li>
      
    </ul>
  </li>-->
  <li><a class="btn btn-info btn-navbar" href="https://console.temasys.io/">Developer Console</a></li>
  <li><a class="btn btn-info btn-navbar" href="http://support.temasys.io/">Support</a></li>
  <!--<li class="dropdown">
    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Modules <span class="caret"></span></a>
    <ul class="dropdown-menu" role="menu">
      <li><a href="#api-modules">View all Modules</a></li>
      
    </ul>
  </li>-->
</ul>
<!--<form id="api-tabview" class="navbar-form navbar-right" role="form">
  <div id="api-tabview-filter" class="form-group">
    <input type="search" id="api-filter" placeholder="Type to filter APIs">
  </div>
</form>-->
      </div><!--/.navbar-collapse -->
    </div>
  </nav>
  <div id="bd" class="yui3-g">

      <div class="yui3-u-1-4">

      </div>
      <div class="yui3-u-3-4">
          
          <div class="apidocs">
              <div id="docs-main">
                  <div class="content content-main">
                      <h1 class="file-heading">File: source/stream-media.js</h1>

<div class="file">
    <pre class="code prettyprint linenums">
/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that if the video codec is not supported, the SDK will not configure the local &lt;code&gt;&quot;offer&quot;&lt;/code&gt; or
 *   &lt;code&gt;&quot;answer&quot;&lt;/code&gt; session description to prefer the codec.
 * &lt;/blockquote&gt;
 * The list of available video codecs to set as the preferred video codec to use to encode
 * sending video data when available encoded video codec for Peer connections
 * configured in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.
 * @attribute VIDEO_CODEC
 * @param {String} AUTO &lt;small&gt;Value &lt;code&gt;&quot;auto&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to not prefer any video codec but rather use the created
 *   local &lt;code&gt;&quot;offer&quot;&lt;/code&gt; / &lt;code&gt;&quot;answer&quot;&lt;/code&gt; session description video codec preference.
 * @param {String} VP8  &lt;small&gt;Value &lt;code&gt;&quot;VP8&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/VP8&quot;&gt;VP8&lt;/a&gt; video codec.
 * @param {String} VP9  &lt;small&gt;Value &lt;code&gt;&quot;VP9&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/VP9&quot;&gt;VP9&lt;/a&gt; video codec.
 * @param {String} H264 &lt;small&gt;Value &lt;code&gt;&quot;H264&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC&quot;&gt;H264&lt;/a&gt; video codec.
 * @type JSON
 * @readOnly
 * @for Skylink
 * @since 0.5.10
 */
Skylink.prototype.VIDEO_CODEC = {
  AUTO: &#x27;auto&#x27;,
  VP8: &#x27;VP8&#x27;,
  H264: &#x27;H264&#x27;,
  VP9: &#x27;VP9&#x27;
  //H264UC: &#x27;H264UC&#x27;
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that if the audio codec is not supported, the SDK will not configure the local &lt;code&gt;&quot;offer&quot;&lt;/code&gt; or
 *   &lt;code&gt;&quot;answer&quot;&lt;/code&gt; session description to prefer the codec.
 * &lt;/blockquote&gt;
 * The list of available audio codecs to set as the preferred audio codec to use to encode
 * sending audio data when available encoded audio codec for Peer connections
 * configured in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.
 * @attribute AUDIO_CODEC
 * @param {String} AUTO &lt;small&gt;Value &lt;code&gt;&quot;auto&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to not prefer any audio codec but rather use the created
 *   local &lt;code&gt;&quot;offer&quot;&lt;/code&gt; / &lt;code&gt;&quot;answer&quot;&lt;/code&gt; session description audio codec preference.
 * @param {String} OPUS &lt;small&gt;Value &lt;code&gt;&quot;opus&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/Opus_(audio_format)&quot;&gt;OPUS&lt;/a&gt; audio codec.
 * @param {String} ISAC &lt;small&gt;Value &lt;code&gt;&quot;ISAC&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/Internet_Speech_Audio_Codec&quot;&gt;ISAC&lt;/a&gt; audio codec.
 * @param {String} ILBC &lt;small&gt;Value &lt;code&gt;&quot;ILBC&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/Internet_Low_Bitrate_Codec&quot;&gt;iLBC&lt;/a&gt; audio codec.
 * @param {String} G722 &lt;small&gt;Value &lt;code&gt;&quot;G722&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/G.722&quot;&gt;G722&lt;/a&gt; audio codec.
 * @param {String} PCMA &lt;small&gt;Value &lt;code&gt;&quot;PCMA&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/G.711&quot;&gt;G711u&lt;/a&gt; audio codec.
 * @param {String} PCMU &lt;small&gt;Value &lt;code&gt;&quot;PCMU&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/G.711&quot;&gt;G711a&lt;/a&gt; audio codec.
 * @type JSON
 * @readOnly
 * @for Skylink
 * @since 0.5.10
 */
Skylink.prototype.AUDIO_CODEC = {
  AUTO: &#x27;auto&#x27;,
  ISAC: &#x27;ISAC&#x27;,
  OPUS: &#x27;opus&#x27;,
  ILBC: &#x27;ILBC&#x27;,
  G722: &#x27;G722&#x27;,
  PCMU: &#x27;PCMU&#x27;,
  PCMA: &#x27;PCMA&#x27;,
  //SILK: &#x27;SILK&#x27;
};

/**
 * The list of available screensharing media sources configured in the
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; method&lt;/a&gt;.
 * @attribute MEDIA_SOURCE
 * @param {String} SCREEN &lt;small&gt;Value &lt;code&gt;&quot;screen&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to share entire screen.
 * @param {String} WINDOW &lt;small&gt;Value &lt;code&gt;&quot;window&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to share application windows.
 * @param {String} TAB &lt;small&gt;Value &lt;code&gt;&quot;tab&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to share browser tab.
 *   &lt;small&gt;Note that this is only supported by from Chrome 52+ and Opera 39+.&lt;/small&gt;
 * @param {String} TAB_AUDIO &lt;small&gt;Value &lt;code&gt;&quot;audio&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to share browser tab audio.
 *   &lt;small&gt;Note that this is only supported by Chrome 52+ and Opera 39+.&lt;/small&gt;
 *   &lt;small&gt;&lt;code&gt;options.audio&lt;/code&gt; has to be enabled with &lt;code&gt;TAB&lt;/code&gt; also requested to enable sharing of tab audio.&lt;/small&gt;
 * @param {String} APPLICATION &lt;small&gt;Value &lt;code&gt;&quot;application&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to share applications.
 *   &lt;small&gt;Note that this is only supported by Firefox currently.&lt;/small&gt;
 * @param {String} BROWSER &lt;small&gt;Value &lt;code&gt;&quot;browser&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to share browser.
 *   &lt;small&gt;Note that this is only supported by Firefox currently, and requires toggling the &lt;code&gt;media.getUserMedia.browser.enabled&lt;/code&gt;
 *   in &lt;code&gt;about:config&lt;/code&gt;.&lt;/small&gt;
 * @param {String} CAMERA &lt;small&gt;Value &lt;code&gt;&quot;camera&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to share camera.
 *   &lt;small&gt;Note that this is only supported by Firefox currently.&lt;/small&gt;
 * @type JSON
 * @readOnly
 * @for Skylink
 * @since 0.5.10
 */
Skylink.prototype.MEDIA_SOURCE = {
  SCREEN: &#x27;screen&#x27;,
  WINDOW: &#x27;window&#x27;,
  TAB: &#x27;tab&#x27;,
  TAB_AUDIO: &#x27;audio&#x27;,
  APPLICATION: &#x27;application&#x27;,
  BROWSER: &#x27;browser&#x27;,
  CAMERA: &#x27;camera&#x27;
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that currently &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt; only configures
 *   the maximum resolution of the Stream due to browser interopability and support.
 * &lt;/blockquote&gt;
 * The list of &lt;a href=&quot;https://en.wikipedia.org/wiki/Graphics_display_resolution#Video_Graphics_Array&quot;&gt;
 * video resolutions&lt;/a&gt; sets configured in the &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;.
 * @attribute VIDEO_RESOLUTION
 * @param {JSON} QQVGA &lt;small&gt;Value &lt;code&gt;{ width: 160, height: 120 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure QQVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} HQVGA &lt;small&gt;Value &lt;code&gt;{ width: 240, height: 160 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure HQVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;3:2&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} QVGA &lt;small&gt;Value &lt;code&gt;{ width: 320, height: 240 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure QVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 * @param {JSON} WQVGA &lt;small&gt;Value &lt;code&gt;{ width: 384, height: 240 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure WQVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:10&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} HVGA &lt;small&gt;Value &lt;code&gt;{ width: 480, height: 320 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure HVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;3:2&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} VGA &lt;small&gt;Value &lt;code&gt;{ width: 640, height: 480 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure VGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 * @param {JSON} WVGA &lt;small&gt;Value &lt;code&gt;{ width: 768, height: 480 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure WVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:10&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} FWVGA &lt;small&gt;Value &lt;code&gt;{ width: 854, height: 480 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure FWVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} SVGA &lt;small&gt;Value &lt;code&gt;{ width: 800, height: 600 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure SVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} DVGA &lt;small&gt;Value &lt;code&gt;{ width: 960, height: 640 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure DVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;3:2&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} WSVGA &lt;small&gt;Value &lt;code&gt;{ width: 1024, height: 576 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure WSVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 * @param {JSON} HD &lt;small&gt;Value &lt;code&gt;{ width: 1280, height: 720 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure HD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on device supports.&lt;/small&gt;
 * @param {JSON} HDPLUS &lt;small&gt;Value &lt;code&gt;{ width: 1600, height: 900 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure HDPLUS resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} FHD &lt;small&gt;Value &lt;code&gt;{ width: 1920, height: 1080 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure FHD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on device supports.&lt;/small&gt;
 * @param {JSON} QHD &lt;small&gt;Value &lt;code&gt;{ width: 2560, height: 1440 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure QHD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} WQXGAPLUS &lt;small&gt;Value &lt;code&gt;{ width: 3200, height: 1800 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure WQXGAPLUS resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} UHD &lt;small&gt;Value &lt;code&gt;{ width: 3840, height: 2160 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure UHD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} UHDPLUS &lt;small&gt;Value &lt;code&gt;{ width: 5120, height: 2880 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure UHDPLUS resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} FUHD &lt;small&gt;Value &lt;code&gt;{ width: 7680, height: 4320 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure FUHD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} QUHD &lt;small&gt;Value &lt;code&gt;{ width: 15360, height: 8640 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure QUHD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @type JSON
 * @readOnly
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype.VIDEO_RESOLUTION = {
  QQVGA: { width: 160, height: 120 /*, aspectRatio: &#x27;4:3&#x27;*/ },
  HQVGA: { width: 240, height: 160 /*, aspectRatio: &#x27;3:2&#x27;*/ },
  QVGA: { width: 320, height: 240 /*, aspectRatio: &#x27;4:3&#x27;*/ },
  WQVGA: { width: 384, height: 240 /*, aspectRatio: &#x27;16:10&#x27;*/ },
  HVGA: { width: 480, height: 320 /*, aspectRatio: &#x27;3:2&#x27;*/ },
  VGA: { width: 640, height: 480 /*, aspectRatio: &#x27;4:3&#x27;*/ },
  WVGA: { width: 768, height: 480 /*, aspectRatio: &#x27;16:10&#x27;*/ },
  FWVGA: { width: 854, height: 480 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  SVGA: { width: 800, height: 600 /*, aspectRatio: &#x27;4:3&#x27;*/ },
  DVGA: { width: 960, height: 640 /*, aspectRatio: &#x27;3:2&#x27;*/ },
  WSVGA: { width: 1024, height: 576 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  HD: { width: 1280, height: 720 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  HDPLUS: { width: 1600, height: 900 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  FHD: { width: 1920, height: 1080 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  QHD: { width: 2560, height: 1440 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  WQXGAPLUS: { width: 3200, height: 1800 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  UHD: { width: 3840, height: 2160 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  UHDPLUS: { width: 5120, height: 2880 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  FUHD: { width: 7680, height: 4320 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  QUHD: { width: 15360, height: 8640 /*, aspectRatio: &#x27;16:9&#x27;*/ }
};

/**
 * The list of &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt; or
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; method&lt;/a&gt; Stream fallback states.
 * @attribute MEDIA_ACCESS_FALLBACK_STATE
 * @param {JSON} FALLBACKING &lt;small&gt;Value &lt;code&gt;0&lt;/code&gt;&lt;/small&gt;
 *   The value of the state when &lt;code&gt;getUserMedia()&lt;/code&gt; will retrieve audio track only
 *   when retrieving audio and video tracks failed.
 *   &lt;small&gt;This can be configured by &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;
 *   &lt;code&gt;audioFallback&lt;/code&gt; option.&lt;/small&gt;
 * @param {JSON} FALLBACKED  &lt;small&gt;Value &lt;code&gt;1&lt;/code&gt;&lt;/small&gt;
 *   The value of the state when &lt;code&gt;getUserMedia()&lt;/code&gt; or &lt;code&gt;shareScreen()&lt;/code&gt;
 *   retrieves camera / screensharing Stream successfully but with missing originally required audio or video tracks.
 * @param {JSON} ERROR       &lt;small&gt;Value &lt;code&gt;-1&lt;/code&gt;&lt;/small&gt;
 *   The value of the state when &lt;code&gt;getUserMedia()&lt;/code&gt; failed to retrieve audio track only
 *   after retrieving audio and video tracks failed.
 * @readOnly
 * @for Skylink
 * @since 0.6.14
 */
Skylink.prototype.MEDIA_ACCESS_FALLBACK_STATE = {
  FALLBACKING: 0,
  FALLBACKED: 1,
  ERROR: -1
};

/**
 * The list of recording states.
 * @attribute RECORDING_STATE
 * @param {Number} START &lt;small&gt;Value &lt;code&gt;0&lt;/code&gt;&lt;/small&gt;
 *   The value of the state when recording session has started.
 * @param {Number} STOP &lt;small&gt;Value &lt;code&gt;1&lt;/code&gt;&lt;/small&gt;
 *   The value of the state when recording session has stopped.&lt;br&gt;
 *   &lt;small&gt;At this stage, the recorded videos will go through the mixin server to compile the videos.&lt;/small&gt;
 * @param {Number} LINK &lt;small&gt;Value &lt;code&gt;2&lt;/code&gt;&lt;/small&gt;
 *   The value of the state when recording session mixin request has been completed.
 * @param {Number} ERROR &lt;small&gt;Value &lt;code&gt;-1&lt;/code&gt;&lt;/small&gt;
 *   The value of the state state when recording session has errors.
 *   &lt;small&gt;This can happen during recording session or during mixin of recording videos,
 *   and at this stage, any current recording session or mixin is aborted.&lt;/small&gt;
 * @type JSON
 * @beta
 * @for Skylink
 * @since 0.6.16
 */
Skylink.prototype.RECORDING_STATE = {
  START: 0,
  STOP: 1,
  LINK: 2,
  ERROR: -1
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   For a better user experience, the functionality is throttled when invoked many times in less
 *   than the milliseconds interval configured in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.
 * &lt;/blockquote&gt;
 * Function that retrieves camera Stream.
 * @method getUserMedia
 * @param {JSON} [options] The camera Stream configuration options.
 * - When not provided, the value is set to &lt;code&gt;{ audio: true, video: true }&lt;/code&gt;.
 *   &lt;small&gt;To fallback to retrieve audio track only when retrieving of audio and video tracks failed,
 *   enable the &lt;code&gt;audioFallback&lt;/code&gt; flag in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;
 * @param {Boolean} [options.useExactConstraints=false] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that by enabling this flag, exact values will be requested when retrieving camera Stream,
 *   but it does not prevent constraints related errors. By default when not enabled,
 *   expected mandatory maximum values (or optional values for source ID) will requested to prevent constraints related
 *   errors, with an exception for &lt;code&gt;options.video.frameRate&lt;/code&gt; option in Safari and IE (any plugin-enabled) browsers,
 *   where the expected maximum value will not be requested due to the lack of support.&lt;/blockquote&gt;
 *   The flag if &lt;code&gt;getUserMedia()&lt;/code&gt; should request for camera Stream to match exact requested values of
 *   &lt;code&gt;options.audio.deviceId&lt;/code&gt; and &lt;code&gt;options.video.deviceId&lt;/code&gt;, &lt;code&gt;options.video.resolution&lt;/code&gt;
 *   and &lt;code&gt;options.video.frameRate&lt;/code&gt; when provided.
 * @param {Boolean|JSON} [options.audio=false] &lt;blockquote class=&quot;info&quot;&gt;
 *    Note that the current Edge browser implementation does not support the &lt;code&gt;options.audio.optional&lt;/code&gt;,
 *    &lt;code&gt;options.audio.deviceId&lt;/code&gt;, &lt;code&gt;options.audio.echoCancellation&lt;/code&gt;.&lt;/blockquote&gt;
 *    The audio configuration options.
 * @param {Boolean} [options.audio.stereo=false] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt; and
 *   the &lt;code&gt;options.codecParams.audio.opus[&quot;sprop-stereo&quot;]&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt; or &lt;code&gt;options.codecParams.audio.opus[&quot;sprop-stereo&quot;]&lt;/code&gt;
 *   is configured, this overrides the &lt;code&gt;options.audio.stereo&lt;/code&gt; setting.&lt;/blockquote&gt;
 *   The flag if OPUS audio codec stereo band should be configured for sending encoded audio data.
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Boolean} [options.audio.usedtx] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt; is configured, this overrides the
 *   &lt;code&gt;options.audio.stereo&lt;/code&gt; setting.  Note that this feature might
 *   not work depending on the browser support and implementation.&lt;/blockquote&gt;
 *   The flag if OPUS audio codec should enable DTX (Discontinuous Transmission) for sending encoded audio data.
 *   &lt;small&gt;This might help to reduce bandwidth as it reduces the bitrate during silence or background noise, and
 *   goes hand-in-hand with the &lt;code&gt;options.voiceActivityDetection&lt;/code&gt; flag in &lt;a href=&quot;#method_joinRoom&quot;&gt;
 *   &lt;code&gt;joinRoom()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Boolean} [options.audio.useinbandfec] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.useinbandfec&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.useinbandfec&lt;/code&gt; is configured, this overrides the
 *   &lt;code&gt;options.audio.useinbandfec&lt;/code&gt; setting. Note that this parameter should only be used
 *   for debugging purposes only.&lt;/blockquote&gt;
 *   The flag if OPUS audio codec has the capability to take advantage of the in-band FEC
 *   (Forward Error Correction) when sending encoded audio data.
 *   &lt;small&gt;This helps to reduce the harm of packet loss by encoding information about the previous packet loss.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Number} [options.audio.maxplaybackrate] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.maxplaybackrate&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.maxplaybackrate&lt;/code&gt; is configured, this overrides the
 *   &lt;code&gt;options.audio.maxplaybackrate&lt;/code&gt; setting.  Note that this feature might
 *   not work depending on the browser support and implementation.
 *   Note that this parameter should only be used for debugging purposes only.&lt;/blockquote&gt;
 *   The OPUS audio codec maximum output sampling rate in Hz (hertz) that is is capable of receiving
 *   decoded audio data, to adjust to the hardware limitations and ensure that any sending audio data
 *   would not encode at a higher sampling rate specified by this.
 *   &lt;small&gt;This value must be between &lt;code&gt;8000&lt;/code&gt; to &lt;code&gt;48000&lt;/code&gt;.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Boolean} [options.audio.mute=false] The flag if audio tracks should be muted upon receiving them.
 *   &lt;small&gt;Providing the value as &lt;code&gt;false&lt;/code&gt; does nothing to &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt;,
 *   but when provided as &lt;code&gt;true&lt;/code&gt;, this sets the &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt; value to
 *   &lt;code&gt;true&lt;/code&gt; and mutes any existing &lt;a href=&quot;#method_shareScreen&quot;&gt;
 *   &lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; audio tracks as well.&lt;/small&gt;
 * @param {Array} [options.audio.optional] &lt;blockquote class=&quot;info&quot;&gt;
 *   This property has been deprecated. &quot;optional&quot; constraints has been moved from specs.&lt;br&gt;
 *   Note that this may result in constraints related error when &lt;code&gt;options.useExactConstraints&lt;/code&gt; value is
 *   &lt;code&gt;true&lt;/code&gt;. If you are looking to set the requested source ID of the audio track,
 *   use &lt;code&gt;options.audio.deviceId&lt;/code&gt; instead.&lt;/blockquote&gt;
 *   The &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API &lt;code&gt;audio: { optional [..] }&lt;/code&gt; property.
 * @param {String} [options.audio.deviceId] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note this is currently not supported in Firefox browsers.
 *   &lt;/blockquote&gt; The audio track source ID of the device to use.
 *   &lt;small&gt;The list of available audio source ID can be retrieved by the &lt;a href=&quot;https://developer.
 * mozilla.org/en-US/docs/Web/API/MediaDevices/enumerateDevices&quot;&gt;&lt;code&gt;navigator.mediaDevices.enumerateDevices&lt;/code&gt;
 *   API&lt;/a&gt;.&lt;/small&gt;
 * @param {Boolean} [options.audio.echoCancellation=true] &lt;blockquote class=&quot;info&quot;&gt;
 *   For Chrome/Opera/IE/Safari/Bowser, the echo cancellation functionality may not work and may produce a terrible
 *   feedback. It is recommended to use headphones or other microphone devices rather than the device
 *   in-built microphones.&lt;/blockquote&gt; The flag to enable echo cancellation for audio track.
 * @param {Boolean|JSON} [options.video=false] &lt;blockquote class=&quot;info&quot;&gt;
 *    Note that the current Edge browser implementation does not support the &lt;code&gt;options.video.optional&lt;/code&gt;,
 *    &lt;code&gt;options.video.deviceId&lt;/code&gt;, &lt;code&gt;options.video.resolution&lt;/code&gt; and
 *    &lt;code&gt;options.video.frameRate&lt;/code&gt;, &lt;code&gt;options.video.facingMode&lt;/code&gt;.&lt;/blockquote&gt;
 *   The video configuration options.
 * @param {Boolean} [options.video.mute=false] The flag if video tracks should be muted upon receiving them.
 *   &lt;small&gt;Providing the value as &lt;code&gt;false&lt;/code&gt; does nothing to &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt;,
 *   but when provided as &lt;code&gt;true&lt;/code&gt;, this sets the &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt; value to
 *   &lt;code&gt;true&lt;/code&gt; and mutes any existing &lt;a href=&quot;#method_shareScreen&quot;&gt;
 *   &lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; video tracks as well.&lt;/small&gt;
 * @param {JSON} [options.video.resolution] The video resolution.
 *   &lt;small&gt;By default, &lt;a href=&quot;#attr_VIDEO_RESOLUTION&quot;&gt;&lt;code&gt;VGA&lt;/code&gt;&lt;/a&gt; resolution option
 *   is selected when not provided.&lt;/small&gt;
 *   [Rel: Skylink.VIDEO_RESOLUTION]
 * @param {Number|JSON} [options.video.resolution.width] The video resolution width.
 * - When provided as a number, it is the video resolution width.
 * - When provided as a JSON, it is the &lt;code&gt;navigator.mediaDevices.getUserMedia()&lt;/code&gt; &lt;code&gt;.width&lt;/code&gt; settings.
 *   Parameters are &lt;code&gt;&quot;ideal&quot;&lt;/code&gt; for ideal resolution width, &lt;code&gt;&quot;exact&quot;&lt;/code&gt; for exact video resolution width,
 *   &lt;code&gt;&quot;min&quot;&lt;/code&gt; for min video resolution width and &lt;code&gt;&quot;max&quot;&lt;/code&gt; for max video resolution width.
 *   Note that this may result in constraints related errors depending on the browser/hardware supports.
 * @param {Number|JSON} [options.video.resolution.height] The video resolution height.
 * - When provided as a number, it is the video resolution height.
 * - When provided as a JSON, it is the &lt;code&gt;navigator.mediaDevices.getUserMedia()&lt;/code&gt; &lt;code&gt;.height&lt;/code&gt; settings.
 *   Parameters are &lt;code&gt;&quot;ideal&quot;&lt;/code&gt; for ideal video resolution height, &lt;code&gt;&quot;exact&quot;&lt;/code&gt; for exact video resolution height,
 *   &lt;code&gt;&quot;min&quot;&lt;/code&gt; for min video resolution height and &lt;code&gt;&quot;max&quot;&lt;/code&gt; for max video resolution height.
 *   Note that this may result in constraints related errors depending on the browser/hardware supports.
 * @param {Number|JSON} [options.video.frameRate] The video &lt;a href=&quot;https://en.wikipedia.org/wiki/Frame_rate&quot;&gt;
 *   frameRate&lt;/a&gt; per second (fps).
 * - When provided as a number, it is the video framerate.
 * - When provided as a JSON, it is the &lt;code&gt;navigator.mediaDevices.getUserMedia()&lt;/code&gt; &lt;code&gt;.frameRate&lt;/code&gt; settings.
 *   Parameters are &lt;code&gt;&quot;ideal&quot;&lt;/code&gt; for ideal video framerate, &lt;code&gt;&quot;exact&quot;&lt;/code&gt; for exact video framerate,
 *   &lt;code&gt;&quot;min&quot;&lt;/code&gt; for min video framerate and &lt;code&gt;&quot;max&quot;&lt;/code&gt; for max video framerate.
 *   Note that this may result in constraints related errors depending on the browser/hardware supports.
 * @param {Array} [options.video.optional] &lt;blockquote class=&quot;info&quot;&gt;
 *   This property has been deprecated. &quot;optional&quot; constraints has been moved from specs.&lt;br&gt;
 *   Note that this may result in constraints related error when &lt;code&gt;options.useExactConstraints&lt;/code&gt; value is
 *   &lt;code&gt;true&lt;/code&gt;. If you are looking to set the requested source ID of the video track,
 *   use &lt;code&gt;options.video.deviceId&lt;/code&gt; instead.&lt;/blockquote&gt;
 *   The &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API &lt;code&gt;video: { optional [..] }&lt;/code&gt; property.
 * @param {String} [options.video.deviceId] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note this is currently not supported in Firefox browsers.
 *   &lt;/blockquote&gt; The video track source ID of the device to use.
 *   &lt;small&gt;The list of available video source ID can be retrieved by the &lt;a href=&quot;https://developer.
 * mozilla.org/en-US/docs/Web/API/MediaDevices/enumerateDevices&quot;&gt;&lt;code&gt;navigator.mediaDevices.enumerateDevices&lt;/code&gt;
 *   API&lt;/a&gt;.&lt;/small&gt;
 * @param {String|JSON} [options.video.facingMode] The video camera facing mode.
 *   &lt;small&gt;The list of available video source ID can be retrieved by the &lt;a href=&quot;https://developer.mozilla.org
 *   /en-US/docs/Web/API/MediaTrackConstraints/facingMode&quot;&gt;MediaTrackConstraints &lt;code&gt;facingMode&lt;/code&gt; API&lt;/a&gt;.&lt;/small&gt;
 * @param {Function} [callback] The callback function fired when request has completed.
 *   &lt;small&gt;Function parameters signature is &lt;code&gt;function (error, success)&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Function request completion is determined by the &lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggering &lt;code&gt;isScreensharing&lt;/code&gt; parameter
 *   payload value as &lt;code&gt;false&lt;/code&gt; for request success.&lt;/small&gt;
 * @param {Error|String} callback.error The error result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are no errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;code&gt;getUserMedia()&lt;/code&gt; error when retrieving camera Stream.&lt;/small&gt;
 * @param {MediaStream} callback.success The success result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the camera Stream object.&lt;/small&gt;
 * @example
 *   // Example 1: Get both audio and video.
 *   skylinkDemo.getUserMedia(function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *   });
 *
 *   // Example 2: Get only audio.
 *   skylinkDemo.getUserMedia({
 *     audio: true
 *   }, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-audio&quot;), success);
 *   });
 *
 *   // Example 3: Configure resolution for video
 *   skylinkDemo.getUserMedia({
 *     audio: true,
 *     video: {
 *       resolution: skylinkDemo.VIDEO_RESOLUTION.HD
 *     }
 *   }, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *   });
 *
 *   // Example 4: Configure stereo flag for OPUS codec audio (OPUS is always used by default)
 *   skylinkDemo.init({
 *     appKey: &quot;xxxxxx&quot;,
 *     audioCodec: skylinkDemo.AUDIO_CODEC.OPUS
 *   }, function (initErr, initSuccess) {
 *     skylinkDemo.getUserMedia({
 *       audio: {
 *         stereo: true
 *       },
 *       video: true
 *     }, function (error, success) {
 *       if (error) return;
 *       attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *     });
 *   });
 *
 *   // Example 5: Configure frameRate for video
 *   skylinkDemo.getUserMedia({
 *     audio: true,
 *     video: {
 *       frameRate: 50
 *     }
 *   }, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *   });
 *
 *   // Example 6: Configure video and audio based on selected sources. Does not work for Firefox currently.
 *   var sources = { audio: [], video: [] };
 *
 *   function selectStream (audioSourceId, videoSourceId) {
 *     if (window.webrtcDetectedBrowser === &#x27;firefox&#x27;) {
 *       console.warn(&quot;Currently this feature is not supported by Firefox browsers!&quot;);
 *       return;
 *     }
 *     skylinkDemo.getUserMedia({
 *       audio: {
 *         optional: [{ sourceId: audioSourceId }]
 *       },
 *       video: {
 *         optional: [{ sourceId: videoSourceId }]
 *       }
 *     }, function (error, success) {
 *       if (error) return;
 *       attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *     });
 *   }
 *
 *   navigator.mediaDevices.enumerateDevices().then(function(devices) {
 *     var selectedAudioSourceId = &quot;&quot;;
 *     var selectedVideoSourceId = &quot;&quot;;
 *     devices.forEach(function(device) {
 *       console.log(device.kind + &quot;: &quot; + device.label + &quot; source ID = &quot; + device.deviceId);
 *       if (device.kind === &quot;audio&quot;) {
 *         selectedAudioSourceId = device.deviceId;
 *       } else {
 *         selectedVideoSourceId = device.deviceId;
 *       }
 *     });
 *     selectStream(selectedAudioSourceId, selectedVideoSourceId);
 *   }).catch(function (error) {
 *      console.error(&quot;Failed&quot;, error);
 *   });
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;If &lt;code&gt;options.audio&lt;/code&gt; value is &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;options.video&lt;/code&gt;
 *   value is &lt;code&gt;false&lt;/code&gt;: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Retrieve camera Stream. &lt;ol&gt;&lt;li&gt;If retrieval was succesful: &lt;ol&gt;
 *   &lt;li&gt;If there is any previous &lt;code&gt;getUserMedia()&lt;/code&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;If there are missing audio or video tracks requested: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Mutes / Unmutes audio and video tracks based on current muted settings in &lt;code&gt;peerInfo.mediaStatus&lt;/code&gt;.
 *   &lt;small&gt;This can be retrieved with &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;If &lt;code&gt;options.audioFallback&lt;/code&gt; is enabled in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;code&gt;options.audio&lt;/code&gt; value is &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;options.video&lt;/code&gt; value is &lt;code&gt;true&lt;/code&gt;: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; event triggers
 *   parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKING&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;Retrieve camera Stream with audio tracks only. &lt;ol&gt;&lt;li&gt;If retrieval was successful: &lt;ol&gt;
 *   &lt;li&gt;If there is any previous &lt;code&gt;getUserMedia()&lt;/code&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; event triggers
 *   parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;Mutes / Unmutes audio and video tracks based on current muted settings in &lt;code&gt;peerInfo.mediaStatus&lt;/code&gt;.
 *   &lt;small&gt;This can be retrieved with &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessError&quot;&gt;&lt;code&gt;mediaAccessError&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallbackError&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; event triggers
 *   parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;ERROR&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt; value as
 *   &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessError&quot;&gt;&lt;code&gt;mediaAccessError&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallbackError&lt;/code&gt; value as
 *   &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype.getUserMedia = function(options,callback) {
  var self = this;

  if (typeof options === &#x27;function&#x27;){
    callback = options;
    options = {
      audio: true,
      video: true
    };

  } else if (typeof options !== &#x27;object&#x27; || options === null) {
    if (typeof options === &#x27;undefined&#x27;) {
      options = {
        audio: true,
        video: true
      };

    } else {
      var invalidOptionsError = &#x27;Please provide a valid options&#x27;;
      log.error(invalidOptionsError, options);
      if (typeof callback === &#x27;function&#x27;) {
        callback(new Error(invalidOptionsError), null);
      }
      return;
    }

  } else if (!options.audio &amp;&amp; !options.video) {
    var noConstraintOptionsSelectedError = &#x27;Please select audio or video&#x27;;
    log.error(noConstraintOptionsSelectedError, options);
    if (typeof callback === &#x27;function&#x27;) {
      callback(new Error(noConstraintOptionsSelectedError), null);
    }
    return;
  }

  /*if (window.location.protocol !== &#x27;https:&#x27; &amp;&amp; window.webrtcDetectedBrowser === &#x27;chrome&#x27; &amp;&amp;
    window.webrtcDetectedVersion &gt; 46) {
    errorMsg = &#x27;getUserMedia() has to be called in https:// application&#x27;;
    log.error(errorMsg, options);
    if (typeof callback === &#x27;function&#x27;) {
      callback(new Error(errorMsg), null);
    }
    return;
  }*/

  self._throttle(function (runFn) {
    if (!runFn) {
      if (self._throttlingShouldThrowError) {
        var throttleLimitError = &#x27;Unable to run as throttle interval has not reached (&#x27; + self._throttlingTimeouts.getUserMedia + &#x27;ms).&#x27;;
        log.error(throttleLimitError);

        if (typeof callback === &#x27;function&#x27;) {
          callback(new Error(throttleLimitError), null);
        }
      }
      return;
    }

    if (typeof callback === &#x27;function&#x27;) {
      var mediaAccessSuccessFn = function (stream) {
        self.off(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn);
        callback(null, stream);
      };
      var mediaAccessErrorFn = function (error) {
        self.off(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn);
        callback(error, null);
      };

      self.once(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn, function (stream, isScreensharing) {
        return !isScreensharing;
      });

      self.once(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn, function (error, isScreensharing) {
        return !isScreensharing;
      });
    }

    // Parse stream settings
    var settings = self._parseStreamSettings(options);
    var successCbFn = function (stream) {
      if (settings.mutedSettings.shouldAudioMuted) {
        self._streamsMutedSettings.audioMuted = true;
      }

      if (settings.mutedSettings.shouldVideoMuted) {
        self._streamsMutedSettings.videoMuted = true;
      }

      self._onStreamAccessSuccess(stream, settings, false, false);
    };
    var errorCbFn = function (error) {
      self._onStreamAccessError(error, settings, false, false);
    };

    if (self._useSafariWebRTC) {
      navigator.mediaDevices.getUserMedia(settings.getUserMediaSettings).then(successCbFn).catch(errorCbFn);

    } else {
      navigator.getUserMedia(settings.getUserMediaSettings, successCbFn, errorCbFn);
    }
  }, &#x27;getUserMedia&#x27;, self._throttlingTimeouts.getUserMedia);
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that if &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; is available despite having
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; available, the
 *   &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; is sent instead of the
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; to Peers.
 * &lt;/blockquote&gt;
 * Function that sends a new &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;
 * to all connected Peers in the Room.
 * @method sendStream
 * @param {JSON|MediaStream} options The &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt;
 *   method&lt;/a&gt; &lt;code&gt;options&lt;/code&gt; parameter settings.
 * - When provided as a &lt;code&gt;MediaStream&lt;/code&gt; object, this configures the &lt;code&gt;options.audio&lt;/code&gt; and
 *   &lt;code&gt;options.video&lt;/code&gt; based on the tracks available in the &lt;code&gt;MediaStream&lt;/code&gt; object,
 *   and configures the &lt;code&gt;options.audio.mute&lt;/code&gt; and &lt;code&gt;options.video.mute&lt;/code&gt; based on the tracks
 *   &lt;code&gt;.enabled&lt;/code&gt; flags in the tracks provided in the &lt;code&gt;MediaStream&lt;/code&gt; object without
 *   invoking &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;.
 *   &lt;small&gt;Object signature matches the &lt;code&gt;options&lt;/code&gt; parameter in the
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;
 * @param {Function} [callback] The callback function fired when request has completed.
 *   &lt;small&gt;Function parameters signature is &lt;code&gt;function (error, success)&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Function request completion is determined by the &lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggering &lt;code&gt;isScreensharing&lt;/code&gt; parameter payload value
 *   as &lt;code&gt;false&lt;/code&gt; for request success when User is in Room without Peers,
 *   or by the &lt;a href=&quot;#event_peerRestart&quot;&gt;&lt;code&gt;peerRestart&lt;/code&gt; event&lt;/a&gt; triggering
 *   &lt;code&gt;isSelfInitiateRestart&lt;/code&gt; parameter payload value as &lt;code&gt;true&lt;/code&gt; for all connected Peers
 *   for request success when User is in Room with Peers.&lt;/small&gt;
 * @param {Error|String} callback.error The error result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are no errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt; error or
 *   when invalid &lt;code&gt;options&lt;/code&gt; is provided.&lt;/small&gt;
 * @param {MediaStream} callback.success The success result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;
 *   Stream object.&lt;/small&gt;
 * @example
 *   // Example 1: Send MediaStream object
 *   function retrieveStreamBySourceForFirefox (sourceId) {
 *     navigator.mediaDevices.getUserMedia({
 *       audio: true,
 *       video: {
 *         sourceId: { exact: sourceId }
 *       }
 *     }).then(function (stream) {
 *       skylinkDemo.sendStream(stream, function (error, success) {
 *         if (err) return;
 *         if (stream === success) {
 *           console.info(&quot;Same MediaStream has been sent&quot;);
 *         }
 *         console.log(&quot;Stream is now being sent to Peers&quot;);
 *         attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *       });
 *     });
 *   }
 *
 *   // Example 2: Send video later
 *   var inRoom = false;
 *
 *   function sendVideo () {
 *     if (!inRoom) return;
 *     skylinkDemo.sendStream({
 *       audio: true,
 *       video: true
 *     }, function (error, success) {
 *       if (error) return;
 *       console.log(&quot;getUserMedia() Stream with video is now being sent to Peers&quot;);
 *       attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *     });
 *   }
 *
 *   skylinkDemo.joinRoom({
 *     audio: true
 *   }, function (jRError, jRSuccess) {
 *     if (jRError) return;
 *     inRoom = true;
 *   });
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;If User is not in Room: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Checks &lt;code&gt;options&lt;/code&gt; provided. &lt;ol&gt;&lt;li&gt;If provided parameter &lt;code&gt;options&lt;/code&gt; is not valid: &lt;ol&gt;
 *   &lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Else if provided parameter &lt;code&gt;options&lt;/code&gt; is a Stream object: &lt;ol&gt;
 *   &lt;li&gt;Checks if there is any audio or video tracks. &lt;ol&gt;&lt;li&gt;If there is no tracks: &lt;ol&gt;
 *   &lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;Set &lt;code&gt;options.audio&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; if Stream has audio tracks.&lt;/li&gt;
 *   &lt;li&gt;Set &lt;code&gt;options.video&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; if Stream has video tracks.&lt;/li&gt;
 *   &lt;li&gt;Mutes / Unmutes audio and video tracks based on current muted settings in
 *   &lt;code&gt;peerInfo.mediaStatus&lt;/code&gt;. &lt;small&gt;This can be retrieved with
 *   &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;&lt;/li&gt;
 *   &lt;li&gt;If there is any previous &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;:
 *   &lt;ol&gt;&lt;li&gt;Invokes &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt; to stop previous Stream.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;Invoke &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options&lt;/code&gt; provided in &lt;code&gt;sendStream()&lt;/code&gt;. &lt;ol&gt;&lt;li&gt;If request has errors: &lt;ol&gt;
 *   &lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;If there is currently no &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt;: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_incomingStream&quot;&gt;&lt;code&gt;incomingStream&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;stream&lt;/code&gt; as
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;Checks if MCU is enabled for App Key provided in &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;. &lt;ol&gt;
 *   &lt;li&gt;If MCU is enabled: &lt;ol&gt;&lt;li&gt;Invoke &lt;a href=&quot;#method_refreshConnection&quot;&gt;&lt;code&gt;refreshConnection()&lt;/code&gt;
 *   method&lt;/a&gt;. &lt;ol&gt;&lt;li&gt;If request has errors: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Else: &lt;ol&gt;&lt;li&gt;If there are connected Peers in the Room: &lt;ol&gt;
 *   &lt;li&gt;Invoke &lt;a href=&quot;#method_refreshConnection&quot;&gt;&lt;code&gt;refreshConnection()&lt;/code&gt; method&lt;/a&gt;. &lt;ol&gt;
 *   &lt;li&gt;If request has errors: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.
 *   &lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.6
 */

Skylink.prototype.sendStream = function(options, callback) {
  var self = this;

  var restartFn = function (stream) {
    if (self._inRoom) {
      if (!self._streams.screenshare) {
        self._trigger(&#x27;incomingStream&#x27;, self._user.sid, stream, true, self.getPeerInfo(), false, stream.id || stream.label);
        self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
      }

      if (Object.keys(self._peerConnections).length &gt; 0 || self._hasMCU) {
        self._refreshPeerConnection(Object.keys(self._peerConnections), false, {}, function (err, success) {
          if (err) {
            log.error(&#x27;Failed refreshing connections for sendStream() -&gt;&#x27;, err);
            if (typeof callback === &#x27;function&#x27;) {
              callback(new Error(&#x27;Failed refreshing connections.&#x27;), null);
            }
            return;
          }
          if (typeof callback === &#x27;function&#x27;) {
            callback(null, stream);
          }
        });
      } else if (typeof callback === &#x27;function&#x27;) {
        callback(null, stream);
      }
    } else {
      var notInRoomAgainError = &#x27;Unable to send stream as user is not in the Room.&#x27;;
      log.error(notInRoomAgainError, stream);
      if (typeof callback === &#x27;function&#x27;) {
        callback(new Error(notInRoomAgainError), null);
      }
    }
  };

  // Note: Sometimes it may be &quot;function&quot; or &quot;object&quot; but then &quot;function&quot; might be mistaken for callback function, so for now fixing it that way
  if ((typeof options !== &#x27;object&#x27; || options === null) &amp;&amp; !(AdapterJS &amp;&amp; AdapterJS.WebRTCPlugin &amp;&amp;
    AdapterJS.WebRTCPlugin.plugin &amp;&amp; [&#x27;function&#x27;, &#x27;object&#x27;].indexOf(typeof options) &gt; -1)) {
    var invalidOptionsError = &#x27;Provided stream settings is invalid&#x27;;
    log.error(invalidOptionsError, options);
    if (typeof callback === &#x27;function&#x27;){
      callback(new Error(invalidOptionsError),null);
    }
    return;
  }

  if (!self._inRoom) {
    var notInRoomError = &#x27;Unable to send stream as user is not in the Room.&#x27;;
    log.error(notInRoomError, options);
    if (typeof callback === &#x27;function&#x27;){
      callback(new Error(notInRoomError),null);
    }
    return;
  }

  if (window.webrtcDetectedBrowser === &#x27;edge&#x27;) {
    var edgeNotSupportError = &#x27;Edge browser currently does not support renegotiation.&#x27;;
    log.error(edgeNotSupportError, options);
    if (typeof callback === &#x27;function&#x27;){
      callback(new Error(edgeNotSupportError),null);
    }
    return;
  }

  if (typeof options.getAudioTracks === &#x27;function&#x27; || typeof options.getVideoTracks === &#x27;function&#x27;) {
    var checkActiveTracksFn = function (tracks) {
      for (var t = 0; t &lt; tracks.length; t++) {
        if (!(tracks[t].ended || (typeof tracks[t].readyState === &#x27;string&#x27; ?
          tracks[t].readyState !== &#x27;live&#x27; : false))) {
          return true;
        }
      }
      return false;
    };

    if (!checkActiveTracksFn( options.getAudioTracks() ) &amp;&amp; !checkActiveTracksFn( options.getVideoTracks() )) {
      var invalidStreamError = &#x27;Provided stream object does not have audio or video tracks.&#x27;;
      log.error(invalidStreamError, options);
      if (typeof callback === &#x27;function&#x27;){
        callback(new Error(invalidStreamError),null);
      }
      return;
    }

    self._onStreamAccessSuccess(options, {
      settings: {
        audio: true,
        video: true
      },
      getUserMediaSettings: {
        audio: true,
        video: true
      }
    }, false, false);

    restartFn(options);

  } else {
    self.getUserMedia(options, function (err, stream) {
      if (err) {
        if (typeof callback === &#x27;function&#x27;) {
          callback(err, null);
        }
        return;
      }
      restartFn(stream);
    });
  }
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that broadcasted events from &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_sendMessage&quot;&gt;&lt;code&gt;sendMessage()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_unlockRoom&quot;&gt;&lt;code&gt;unlockRoom()&lt;/code&gt; method&lt;/a&gt; and
 *   &lt;a href=&quot;#method_lockRoom&quot;&gt;&lt;code&gt;lockRoom()&lt;/code&gt; method&lt;/a&gt; may be queued when
 *   sent within less than an interval.
 * &lt;/blockquote&gt;
 * Function that stops &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;.
 * @method stopStream
 * @example
 *   function stopStream () {
 *     skylinkDemo.stopStream();
 *   }
 *
 *   skylinkDemo.getUserMedia();
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Checks if there is &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;. &lt;ol&gt;
 *   &lt;li&gt;If there is &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;: &lt;ol&gt;
 *   &lt;li&gt;Stop &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; Stream. &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessStopped&quot;&gt;&lt;code&gt;mediaAccessStopped&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;If User is in Room: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_streamEnded&quot;&gt;&lt;code&gt;streamEnded&lt;/code&gt; event&lt;/a&gt; triggers parameter
 *   payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isScreensharing&lt;/code&gt; value as&lt;code&gt;false&lt;/code&gt;
 *   .&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype.stopStream = function () {
  if (this._streams.userMedia) {
    this._stopStreams({
      userMedia: true
    });
  }
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that broadcasted events from &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_sendMessage&quot;&gt;&lt;code&gt;sendMessage()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_unlockRoom&quot;&gt;&lt;code&gt;unlockRoom()&lt;/code&gt; method&lt;/a&gt; and
 *   &lt;a href=&quot;#method_lockRoom&quot;&gt;&lt;code&gt;lockRoom()&lt;/code&gt; method&lt;/a&gt; may be queued when
 *   sent within less than an interval.
 * &lt;/blockquote&gt;
 * Function that mutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; audio or video tracks.
 * @method muteStream
 * @param {JSON} options The Streams muting options.
 * @param {Boolean} [options.audioMuted=true] The flag if all Streams audio
 *   tracks should be muted or not.
 * @param {Boolean} [options.videoMuted=true] The flag if all Streams video
 *   tracks should be muted or not.
 * @example
 *   // Example 1: Mute both audio and video tracks in all Streams
 *   skylinkDemo.muteStream({
 *     audioMuted: true,
 *     videoMuted: true
 *   });
 *
 *   // Example 2: Mute only audio tracks in all Streams
 *   skylinkDemo.muteStream({
 *     audioMuted: true,
 *     videoMuted: false
 *   });
 *
 *   // Example 3: Mute only video tracks in all Streams
 *   skylinkDemo.muteStream({
 *     audioMuted: false,
 *     videoMuted: true
 *   });
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;If provided parameter &lt;code&gt;options&lt;/code&gt; is invalid: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Checks if there is any available Streams: &lt;ol&gt;&lt;li&gt;If there is no available Streams: &lt;ol&gt;
 *   &lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;If User is in Room: &lt;ol&gt;
 *   &lt;li&gt;Checks if there is audio tracks to mute / unmute: &lt;ol&gt;&lt;li&gt;If there is audio tracks to mute / unmute: &lt;ol&gt;
 *   &lt;li&gt;If &lt;code&gt;options.audioMuted&lt;/code&gt; value is not the same as the current
 *   &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt;: &lt;small&gt;This can be retrieved with
 *   &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt; &lt;ol&gt;
 *   &lt;li&gt;&lt;em&gt;For Peer only&lt;/em&gt; &lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt;
 *   triggers with parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;em&gt;For Peer only&lt;/em&gt; &lt;a href=&quot;#event_streamMuted&quot;&gt;&lt;code&gt;streamMuted&lt;/code&gt; event&lt;/a&gt;
 *   triggers with parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Checks if there is video tracks to mute / unmute: &lt;ol&gt;&lt;li&gt;If there is video tracks to mute / unmute: &lt;ol&gt;
 *   &lt;li&gt;If &lt;code&gt;options.videoMuted&lt;/code&gt; value is not the same as the current
 *   &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt;: &lt;small&gt;This can be retrieved with
 *   &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt; &lt;ol&gt;
 *   &lt;li&gt;&lt;em&gt;For Peer only&lt;/em&gt; &lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt;
 *   triggers with parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;em&gt;For Peer only&lt;/em&gt; &lt;a href=&quot;#event_streamMuted&quot;&gt;&lt;code&gt;streamMuted&lt;/code&gt; event&lt;/a&gt; triggers with
 *   parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;If &lt;code&gt;options.audioMuted&lt;/code&gt; value is not the same as the current
 *   &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt; or &lt;code&gt;options.videoMuted&lt;/code&gt; value is not
 *   the same as the current &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt;: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_localMediaMuted&quot;&gt;&lt;code&gt;localMediaMuted&lt;/code&gt; event&lt;/a&gt; triggers.&lt;/li&gt;
 *   &lt;li&gt;If User is in Room: &lt;ol&gt;&lt;li&gt;&lt;a href=&quot;#event_streamMuted&quot;&gt;&lt;code&gt;streamMuted&lt;/code&gt; event&lt;/a&gt;
 *   triggers with parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers with
 *   parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.7
 */
Skylink.prototype.muteStream = function(options) {
  var self = this;

  if (typeof options !== &#x27;object&#x27;) {
    log.error(&#x27;Provided settings is not an object&#x27;);
    return;
  }

  if (!(self._streams.userMedia &amp;&amp; self._streams.userMedia.stream) &amp;&amp;
    !(self._streams.screenshare &amp;&amp; self._streams.screenshare.stream)) {
    log.warn(&#x27;No streams are available to mute / unmute!&#x27;);
    return;
  }

  var audioMuted = typeof options.audioMuted === &#x27;boolean&#x27; ? options.audioMuted : true;
  var videoMuted = typeof options.videoMuted === &#x27;boolean&#x27; ? options.videoMuted : true;
  var hasToggledAudio = false;
  var hasToggledVideo = false;

  if (self._streamsMutedSettings.audioMuted !== audioMuted) {
    self._streamsMutedSettings.audioMuted = audioMuted;
    hasToggledAudio = true;
  }

  if (self._streamsMutedSettings.videoMuted !== videoMuted) {
    self._streamsMutedSettings.videoMuted = videoMuted;
    hasToggledVideo = true;
  }

  if (hasToggledVideo || hasToggledAudio) {
    var streamTracksAvailability = self._muteStreams();

    if (hasToggledVideo &amp;&amp; self._inRoom) {
      self._sendChannelMessage({
        type: self._SIG_MESSAGE_TYPE.MUTE_VIDEO,
        mid: self._user.sid,
        rid: self._room.id,
        muted: self._streamsMutedSettings.videoMuted,
        stamp: (new Date()).getTime()
      });
    }

    if (hasToggledAudio &amp;&amp; self._inRoom) {
      setTimeout(function () {
        self._sendChannelMessage({
          type: self._SIG_MESSAGE_TYPE.MUTE_AUDIO,
          mid: self._user.sid,
          rid: self._room.id,
          muted: self._streamsMutedSettings.audioMuted,
          stamp: (new Date()).getTime()
        });
      }, hasToggledVideo ? 1050 : 0);
    }

    if ((streamTracksAvailability.hasVideo &amp;&amp; hasToggledVideo) ||
      (streamTracksAvailability.hasAudio &amp;&amp; hasToggledAudio)) {

      self._trigger(&#x27;localMediaMuted&#x27;, {
        audioMuted: streamTracksAvailability.hasAudio ? self._streamsMutedSettings.audioMuted : true,
        videoMuted: streamTracksAvailability.hasVideo ? self._streamsMutedSettings.videoMuted : true
      });

      if (self._inRoom) {
        self._trigger(&#x27;streamMuted&#x27;, self._user.sid, self.getPeerInfo(), true,
          self._streams.screenshare &amp;&amp; self._streams.screenshare.stream);
        self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
      }
    }
  }
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that unmutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; audio tracks.
 * @method enableAudio
 * @deprecated true
 * @example
 *   function unmuteAudio () {
 *     skylinkDemo.enableAudio();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.audioMuted&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;options.videoMuted&lt;/code&gt; value with current &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt; value.
 *   &lt;small&gt;See &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt; for more information.&lt;/small&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.enableAudio = function() {
  this.muteStream({
    audioMuted: false,
    videoMuted: this._streamsMutedSettings.videoMuted
  });
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that mutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; audio tracks.
 * @method disableAudio
 * @deprecated true
 * @example
 *   function muteAudio () {
 *     skylinkDemo.disableAudio();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.audioMuted&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and
 *   &lt;code&gt;options.videoMuted&lt;/code&gt; value with current &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt; value.
 *   &lt;small&gt;See &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt; for more information.&lt;/small&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.disableAudio = function() {
  this.muteStream({
    audioMuted: true,
    videoMuted: this._streamsMutedSettings.videoMuted
  });
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that unmutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; video tracks.
 * @method enableVideo
 * @deprecated true
 * @example
 *   function unmuteVideo () {
 *     skylinkDemo.enableVideo();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.videoMuted&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;options.audioMuted&lt;/code&gt; value with current &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt; value.
 *   &lt;small&gt;See &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt; for more information.&lt;/small&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.enableVideo = function() {
  this.muteStream({
    videoMuted: false,
    audioMuted: this._streamsMutedSettings.audioMuted
  });
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that mutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; video tracks.
 * @method disableVideo
 * @deprecated true
 * @example
 *   function muteVideo () {
 *     skylinkDemo.disableVideo();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.videoMuted&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and
 *   &lt;code&gt;options.audioMuted&lt;/code&gt; value with current &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt; value.
 *   &lt;small&gt;See &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt; for more information.&lt;/small&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.disableVideo = function() {
  this.muteStream({
    videoMuted: true,
    audioMuted: this._streamsMutedSettings.audioMuted
  });
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   For a better user experience, the functionality is throttled when invoked many times in less
 *   than the milliseconds interval configured in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.
 *   Note that the Opera and Edge browser does not support screensharing, and as for IE / Safari browsers using
 *   the Temasys Plugin screensharing support, check out the &lt;a href=&quot;https://temasys.com.sg/plugin/#commercial-licensing&quot;&gt;
 *   commercial licensing&lt;/a&gt; for more options.
 * &lt;/blockquote&gt;
 * Function that retrieves screensharing Stream.
 * @method shareScreen
 * @param {JSON|Boolean} [enableAudio=false] The flag if audio tracks should be retrieved.
 * @param {Boolean} [enableAudio.stereo=false] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt; and
 *   the &lt;code&gt;options.codecParams.audio.opus[&quot;sprop-stereo&quot;]&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt; or &lt;code&gt;options.codecParams.audio.opus[&quot;sprop-stereo&quot;]&lt;/code&gt;
 *   is configured, this overrides the &lt;code&gt;options.audio.stereo&lt;/code&gt; setting.&lt;/blockquote&gt;
 *   The flag if OPUS audio codec stereo band should be configured for sending encoded audio data.
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Boolean} [enableAudio.usedtx] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.stereo&lt;/code&gt; is configured, this overrides the
 *   &lt;code&gt;options.audio.stereo&lt;/code&gt; setting.  Note that this feature might
 *   not work depending on the browser support and implementation.&lt;/blockquote&gt;
 *   The flag if OPUS audio codec should enable DTX (Discontinuous Transmission) for sending encoded audio data.
 *   &lt;small&gt;This might help to reduce bandwidth as it reduces the bitrate during silence or background noise, and
 *   goes hand-in-hand with the &lt;code&gt;options.voiceActivityDetection&lt;/code&gt; flag in &lt;a href=&quot;#method_joinRoom&quot;&gt;
 *   &lt;code&gt;joinRoom()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Boolean} [enableAudio.useinbandfec] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.useinbandfec&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.useinbandfec&lt;/code&gt; is configured, this overrides the
 *   &lt;code&gt;options.audio.useinbandfec&lt;/code&gt; setting. Note that this parameter should only be used
 *   for debugging purposes only.&lt;/blockquote&gt;
 *   The flag if OPUS audio codec has the capability to take advantage of the in-band FEC
 *   (Forward Error Correction) when sending encoded audio data.
 *   &lt;small&gt;This helps to reduce the harm of packet loss by encoding information about the previous packet loss.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Number} [enableAudio.maxplaybackrate] &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This property has been deprecated. Configure this with the &lt;code&gt;options.codecParams.audio.opus.maxplaybackrate&lt;/code&gt;
 *   parameter in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt; instead. If the
 *   &lt;code&gt;options.codecParams.audio.opus.maxplaybackrate&lt;/code&gt; is configured, this overrides the
 *   &lt;code&gt;options.audio.maxplaybackrate&lt;/code&gt; setting.  Note that this feature might
 *   not work depending on the browser support and implementation.
 *   Note that this parameter should only be used for debugging purposes only.&lt;/blockquote&gt;
 *   The OPUS audio codec maximum output sampling rate in Hz (hertz) that is is capable of receiving
 *   decoded audio data, to adjust to the hardware limitations and ensure that any sending audio data
 *   would not encode at a higher sampling rate specified by this.
 *   &lt;small&gt;This value must be between &lt;code&gt;8000&lt;/code&gt; to &lt;code&gt;48000&lt;/code&gt;.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Boolean} [enableAudio.echoCancellation=true] &lt;blockquote class=&quot;info&quot;&gt;
 *   For Chrome/Opera/IE/Safari/Bowser, the echo cancellation functionality may not work and may produce a terrible
 *   feedback. It is recommended to use headphones or other microphone devices rather than the device
 *   in-built microphones.&lt;/blockquote&gt; The flag to enable echo cancellation for audio track.
 *   &lt;small&gt;Note that this will not be toggled for Chrome/Opera case when &#x60;mediaSource&#x60; value is &#x60;[&quot;tab&quot;,&quot;audio&quot;]&#x60;.&lt;/small&gt;
 * @param {String|Array} [mediaSource=screen] The screensharing media source to select.
 *   &lt;small&gt;Note that multiple sources are not supported by Firefox as of the time of this release.
 *   Firefox will use the first item specified in the Array in the event that multiple sources are defined.&lt;/small&gt;
 *   &lt;small&gt;E.g. &lt;code&gt;[&quot;screen&quot;, &quot;window&quot;]&lt;/code&gt;, &lt;code&gt;[&quot;tab&quot;, &quot;audio&quot;]&lt;/code&gt;, &lt;code&gt;&quot;screen&quot;&lt;/code&gt; or &lt;code&gt;&quot;tab&quot;&lt;/code&gt;.&lt;/small&gt;
 *   [Rel: Skylink.MEDIA_SOURCE]
 * @param {Function} [callback] The callback function fired when request has completed.
 *   &lt;small&gt;Function parameters signature is &lt;code&gt;function (error, success)&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Function request completion is determined by the &lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggering &lt;code&gt;isScreensharing&lt;/code&gt; parameter payload value
 *   as &lt;code&gt;true&lt;/code&gt; for request success when User is not in the Room or is in Room without Peers,
 *   or by the &lt;a href=&quot;#event_peerRestart&quot;&gt;&lt;code&gt;peerRestart&lt;/code&gt; event&lt;/a&gt; triggering
 *   &lt;code&gt;isSelfInitiateRestart&lt;/code&gt; parameter payload value as &lt;code&gt;true&lt;/code&gt; for all connected Peers
 *   for request success when User is in Room with Peers.&lt;/small&gt;
 * @param {Error|String} callback.error The error result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are no errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;code&gt;shareScreen()&lt;/code&gt; error when retrieving screensharing Stream.&lt;/small&gt;
 * @param {MediaStream} callback.success The success result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the screensharing Stream object.&lt;/small&gt;
 * @example
 *   // Example 1: Share screen with audio
 *   skylinkDemo.shareScreen(function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-screen&quot;), success);
 *   });
 *
 *   // Example 2: Share screen without audio
 *   skylinkDemo.shareScreen(false, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-screen&quot;), success);
 *   });
 * 
 *   // Example 3: Share &quot;window&quot; media source
 *   skylinkDemo.shareScreen(&quot;window&quot;, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-screen&quot;), success);
 *   });
 * 
 *   // Example 4: Share tab and its audio media source
 *   skylinkDemo.shareScreen(true, [&quot;tab&quot;, &quot;audio&quot;], function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-screen&quot;), success);
 *   });
 * 
 *   // Example 5: Share &quot;window&quot; and &quot;screen&quot; media source
 *   skylinkDemo.shareScreen([&quot;window&quot;, &quot;screen&quot;], function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-screen&quot;), success);
 *   });
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Retrieves screensharing Stream. &lt;ol&gt;&lt;li&gt;If retrieval was successful: &lt;ol&gt;&lt;li&gt;If browser is Firefox: &lt;ol&gt;
 *   &lt;li&gt;If there are missing audio or video tracks requested: &lt;ol&gt;
 *   &lt;li&gt;If there is any previous &lt;code&gt;shareScreen()&lt;/code&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt;
 *   triggers parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;If audio is requested: &lt;small&gt;Chrome, Safari and IE currently doesn&#x27;t support retrieval of
 *   audio track together with screensharing video track.&lt;/small&gt; &lt;ol&gt;&lt;li&gt;Retrieves audio Stream: &lt;ol&gt;
 *   &lt;li&gt;If retrieval was successful: &lt;ol&gt;&lt;li&gt;Attempts to attach screensharing Stream video track to audio Stream. &lt;ol&gt;
 *   &lt;li&gt;If attachment was successful: &lt;ol&gt;&lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers parameter payload &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;If there is any previous &lt;code&gt;shareScreen()&lt;/code&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;If there is any previous &lt;code&gt;shareScreen()&lt;/code&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt;
 *   triggers parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt;
 *   triggers parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;
 *   and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessError&quot;&gt;&lt;code&gt;mediaAccessError&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as
 *   &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;If User is in Room: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_incomingStream&quot;&gt;&lt;code&gt;incomingStream&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;stream&lt;/code&gt; as &lt;code&gt;shareScreen()&lt;/code&gt; Stream.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;Checks if MCU is enabled for App Key provided in &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;. &lt;ol&gt;
 *   &lt;li&gt;If MCU is enabled: &lt;ol&gt;&lt;li&gt;Invoke &lt;a href=&quot;#method_refreshConnection&quot;&gt;&lt;code&gt;refreshConnection()&lt;/code&gt; method&lt;/a&gt;.
 *   &lt;ol&gt;&lt;li&gt;If request has errors: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;If there are connected Peers in the Room: &lt;ol&gt;&lt;li&gt;Invoke &lt;a href=&quot;#method_refreshConnection&quot;&gt;
 *   &lt;code&gt;refreshConnection()&lt;/code&gt; method&lt;/a&gt;. &lt;ol&gt;&lt;li&gt;If request has errors: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;
 *   &lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.6.0
 */
Skylink.prototype.shareScreen = function (enableAudio, mediaSource, callback) {
  var self = this;
  var enableAudioSettings = false;
  var useMediaSource = [self.MEDIA_SOURCE.SCREEN];
  var checkIfSourceExistsFn = function (val) {
    for (var prop in self.MEDIA_SOURCE) {
      if (self.MEDIA_SOURCE.hasOwnProperty(prop) &amp;&amp; self.MEDIA_SOURCE[prop] === val) {
        return true;
      }
    }
    return false;
  };

  // shareScreen(&quot;screen&quot;)
  if (enableAudio &amp;&amp; typeof enableAudio === &#x27;string&#x27;) {
    if (checkIfSourceExistsFn(enableAudio)) {
      useMediaSource = [enableAudio];
    }
  // shareScreen([&quot;screen&quot;, &quot;window&quot;])
  } else if (Array.isArray(enableAudio)) {
    var enableAudioArr = [];
    for (var i = 0; i &lt; enableAudio.length; i++) {
      if (checkIfSourceExistsFn(enableAudio[i])) {
        enableAudioArr.push(enableAudio[i]);
      }
    }
    if (enableAudioArr.length &gt; 0) {
      useMediaSource = enableAudioArr;
    }
  // shareScreen({ stereo: true })
  } else if (enableAudio &amp;&amp; typeof enableAudio === &#x27;object&#x27;) {
    enableAudioSettings = {
      usedtx: typeof enableAudio.usedtx === &#x27;boolean&#x27; ? enableAudio.usedtx : null,
      useinbandfec: typeof enableAudio.useinbandfec === &#x27;boolean&#x27; ? enableAudio.useinbandfec : null,
      stereo: enableAudio.stereo === true,
      echoCancellation: enableAudio.echoCancellation !== false,
      deviceId: enableAudio.deviceId
    };
  // shareScreen(true)
  } else if (enableAudio === true) {
    enableAudioSettings = enableAudio === true ? {
      usedtx: null,
      useinbandfec: null,
      stereo: false,
      echoCancellation: true,
      deviceId: null
    } : false;
  // shareScreen(function () {})
  } else if (typeof enableAudio === &#x27;function&#x27;) {
    callback = enableAudio;
    enableAudio = false;
  }

  // shareScreen(.., &quot;screen&quot;)
  if (mediaSource &amp;&amp; typeof mediaSource === &#x27;string&#x27;) {
    if (checkIfSourceExistsFn(mediaSource)) {
      useMediaSource = [mediaSource];
    }
  // shareScreen(.., [&quot;screen&quot;, &quot;window&quot;])
  } else if (Array.isArray(mediaSource)) {
    var mediaSourceArr = [];
    for (var i = 0; i &lt; mediaSource.length; i++) {
      if (checkIfSourceExistsFn(mediaSource[i])) {
        mediaSourceArr.push(mediaSource[i]);
      }
    }
    if (mediaSourceArr.length &gt; 0) {
      useMediaSource = mediaSourceArr;
    }
  // shareScreen(.., function () {})
  } else if (typeof mediaSource === &#x27;function&#x27;) {
    callback = mediaSource;
  }

  if (useMediaSource.indexOf(&#x27;audio&#x27;) &gt; -1 &amp;&amp; useMediaSource.indexOf(&#x27;tab&#x27;) === -1) {
    useMediaSource.splice(useMediaSource.indexOf(&#x27;audio&#x27;), 1);
    if (useMediaSource.length === 0) {
      useMediaSource = [self.MEDIA_SOURCE.SCREEN];
    }
  }

  self._throttle(function (runFn) {
    if (!runFn) {
      if (self._throttlingShouldThrowError) {
        var throttleLimitError = &#x27;Unable to run as throttle interval has not reached (&#x27; + self._throttlingTimeouts.shareScreen + &#x27;ms).&#x27;;
        log.error(throttleLimitError);

        if (typeof callback === &#x27;function&#x27;) {
          callback(new Error(throttleLimitError), null);
        }
      }
      return;
    }

    var settings = {
      settings: {
        audio: enableAudioSettings,
        video: {
          screenshare: true,
          exactConstraints: false
        }
      },
      getUserMediaSettings: {
        audio: false,
        video: {
          mediaSource: useMediaSource
        }
      }
    };

    var mediaAccessSuccessFn = function (stream) {
      self.off(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn);

      if (self._inRoom) {
        self._trigger(&#x27;incomingStream&#x27;, self._user.sid, stream, true, self.getPeerInfo(), true, stream.id || stream.label);
        self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);

        if (Object.keys(self._peerConnections).length &gt; 0 || self._hasMCU) {
          self._refreshPeerConnection(Object.keys(self._peerConnections), false, {}, function (err, success) {
            if (err) {
              log.error(&#x27;Failed refreshing connections for shareScreen() -&gt;&#x27;, err);
              if (typeof callback === &#x27;function&#x27;) {
                callback(new Error(&#x27;Failed refreshing connections.&#x27;), null);
              }
              return;
            }
            if (typeof callback === &#x27;function&#x27;) {
              callback(null, stream);
            }
          });
        } else if (typeof callback === &#x27;function&#x27;) {
          callback(null, stream);
        }
      } else if (typeof callback === &#x27;function&#x27;) {
        callback(null, stream);
      }
    };

    var mediaAccessErrorFn = function (error) {
      self.off(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn);

      if (typeof callback === &#x27;function&#x27;) {
        callback(error, null);
      }
    };

    self.once(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn, function (stream, isScreensharing) {
      return isScreensharing;
    });

    self.once(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn, function (error, isScreensharing) {
      return isScreensharing;
    });

    var getUserMediaAudioSettings = enableAudioSettings ? {
      echoCancellation: enableAudioSettings.echoCancellation
    } : false;

    try {
      var hasDefaultAudioTrack = false;
      if (enableAudioSettings) {
        if (window.webrtcDetectedBrowser === &#x27;firefox&#x27;) {
          hasDefaultAudioTrack = true;
          settings.getUserMediaSettings.audio = getUserMediaAudioSettings;
        } else if (useMediaSource.indexOf(&#x27;audio&#x27;) &gt; -1 &amp;&amp; useMediaSource.indexOf(&#x27;tab&#x27;) &gt; -1) {
          hasDefaultAudioTrack = true;
          settings.getUserMediaSettings.audio = {};
        }
      }

      var successCbFn = function (stream) {
        if (hasDefaultAudioTrack || !enableAudioSettings) {
          self._onStreamAccessSuccess(stream, settings, true, false);
          return;
        }

        settings.getUserMediaSettings.audio = getUserMediaAudioSettings;
        var audioSuccessCbFn = function (audioStream) {
          try {
            audioStream.addTrack(stream.getVideoTracks()[0]);

            self.once(&#x27;mediaAccessSuccess&#x27;, function () {
              self._streams.screenshare.streamClone = stream;
            }, function (stream, isScreensharing) {
              return isScreensharing;
            });

            self._onStreamAccessSuccess(audioStream, settings, true, false);

          } catch (error) {
            log.error(&#x27;Failed retrieving audio stream for screensharing stream&#x27;, error);
            self._onStreamAccessSuccess(stream, settings, true, false);
          }
        };

        var audioErrorCbFn = function (error) {
          log.error(&#x27;Failed retrieving audio stream for screensharing stream&#x27;, error);
          self._onStreamAccessSuccess(stream, settings, true, false);
        };

        if (self._useSafariWebRTC) {
          navigator.mediaDevices.getUserMedia({ audio: getUserMediaAudioSettings }).then(audioSuccessCbFn).catch(audioErrorCbFn);

        } else {
          navigator.getUserMedia({ audio: getUserMediaAudioSettings }, audioSuccessCbFn, audioErrorCbFn);
        }
      };

      var errorCbFn = function (error) {
        self._onStreamAccessError(error, settings, true, false);
      };

      if (self._useSafariWebRTC) {
        navigator.mediaDevices.getUserMedia(settings.getUserMediaSettings).catch(successCbFn).then(errorCbFn);

      } else {
        navigator.getUserMedia(settings.getUserMediaSettings, successCbFn, errorCbFn);
      }
    } catch (error) {
      self._onStreamAccessError(error, settings, true, false);
    }
  }, &#x27;shareScreen&#x27;, self._throttlingTimeouts.shareScreen);
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that broadcasted events from &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_sendMessage&quot;&gt;&lt;code&gt;sendMessage()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_unlockRoom&quot;&gt;&lt;code&gt;unlockRoom()&lt;/code&gt; method&lt;/a&gt; and
 *   &lt;a href=&quot;#method_lockRoom&quot;&gt;&lt;code&gt;lockRoom()&lt;/code&gt; method&lt;/a&gt; may be queued when
 *   sent within less than an interval.
 * &lt;/blockquote&gt;
 * Function that stops &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt;.
 * @method stopScreen
 * @example
 *   function stopScreen () {
 *     skylinkDemo.stopScreen();
 *   }
 *
 *   skylinkDemo.shareScreen();
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Checks if there is &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt;. &lt;ol&gt;
 *   &lt;li&gt;If there is &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt;: &lt;ol&gt;
 *   &lt;li&gt;Stop &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; Stream. &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessStopped&quot;&gt;&lt;code&gt;mediaAccessStopped&lt;/code&gt; event&lt;/a&gt;
 *   triggers parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;If User is in Room: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_streamEnded&quot;&gt;&lt;code&gt;streamEnded&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;If User is in Room: &lt;small&gt;&lt;b&gt;SKIP&lt;/b&gt; this step if &lt;code&gt;stopScreen()&lt;/code&gt;
 *   was invoked from &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt; &lt;ol&gt;
 *   &lt;li&gt;If there is &lt;a href=&quot;#method_getUserMedia&quot;&gt; &lt;code&gt;getUserMedia()&lt;/code&gt;Stream&lt;/a&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_incomingStream&quot;&gt;&lt;code&gt;incomingStream&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;stream&lt;/code&gt; as
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Invoke &lt;a href=&quot;#method_refreshConnection&quot;&gt;&lt;code&gt;refreshConnection()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;
 *   &lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.6.0
 */
Skylink.prototype.stopScreen = function () {
  if (this._streams.screenshare) {
    this._stopStreams({
      screenshare: true
    });

    if (this._inRoom) {
      if (this._streams.userMedia &amp;&amp; this._streams.userMedia.stream) {
        this._trigger(&#x27;incomingStream&#x27;, this._user.sid, this._streams.userMedia.stream, true, this.getPeerInfo(),
          false, this._streams.userMedia.stream.id || this._streams.userMedia.stream.label);
        this._trigger(&#x27;peerUpdated&#x27;, this._user.sid, this.getPeerInfo(), true);
      }
      this._refreshPeerConnection(Object.keys(this._peerConnections), {}, false);
    }
  }
};

/**
 * Function that handles the muting of Stream audio and video tracks.
 * @method _muteStreams
 * @private
 * @for Skylink
 * @since 0.6.15
 */
Skylink.prototype._muteStreams = function () {
  var self = this;
  var hasVideo = false;
  var hasAudio = false;

  var muteFn = function (stream) {
    var audioTracks = stream.getAudioTracks();
    var videoTracks = stream.getVideoTracks();

    for (var a = 0; a &lt; audioTracks.length; a++) {
      audioTracks[a].enabled = !self._streamsMutedSettings.audioMuted;
      hasAudio = true;
    }

    for (var v = 0; v &lt; videoTracks.length; v++) {
      videoTracks[v].enabled = !self._streamsMutedSettings.videoMuted;
      hasVideo = true;
    }
  };

  if (self._streams.userMedia &amp;&amp; self._streams.userMedia.stream) {
    muteFn(self._streams.userMedia.stream);
  }

  if (self._streams.screenshare &amp;&amp; self._streams.screenshare.stream) {
    muteFn(self._streams.screenshare.stream);
  }

  if (self._streams.screenshare &amp;&amp; self._streams.screenshare.streamClone) {
    muteFn(self._streams.screenshare.streamClone);
  }

  if (window.webrtcDetectedBrowser === &#x27;edge&#x27;) {
    for (var peerId in self._peerConnections) {
      if (self._peerConnections.hasOwnProperty(peerId) &amp;&amp; self._peerConnections[peerId]) {
        var localStreams = self._peerConnections[peerId].getLocalStreams();
        for (var s = 0; s &lt; localStreams.length; s++) {
          muteFn(localStreams[s]);
        }
      }
    }
  }

  log.debug(&#x27;Updated Streams muted status -&gt;&#x27;, self._streamsMutedSettings);

  return {
    hasVideo: hasVideo,
    hasAudio: hasAudio
  };
};

/**
 * Function that handles stopping the Stream streaming.
 * @method _stopStreams
 * @private
 * @for Skylink
 * @since 0.6.15
 */
Skylink.prototype._stopStreams = function (options) {
  var self = this;
  var stopFn = function (stream) {
    var streamId = stream.id || stream.label;
    log.debug([null, &#x27;MediaStream&#x27;, streamId, &#x27;Stopping Stream -&gt;&#x27;], stream);

    try {
      var audioTracks = stream.getAudioTracks();
      var videoTracks = stream.getVideoTracks();

      for (var a = 0; a &lt; audioTracks.length; a++) {
        audioTracks[a].stop();
      }

      for (var v = 0; v &lt; videoTracks.length; v++) {
        videoTracks[v].stop();
      }

    } catch (error) {
      stream.stop();
    }

    if (self._streamsStoppedCbs[streamId]) {
      self._streamsStoppedCbs[streamId]();
      delete self._streamsStoppedCbs[streamId];
    }
  };

  var stopUserMedia = false;
  var stopScreenshare = false;
  var hasStoppedMedia = false;

  if (typeof options === &#x27;object&#x27;) {
    stopUserMedia = options.userMedia === true;
    stopScreenshare = options.screenshare === true;
  }

  if (stopUserMedia &amp;&amp; self._streams.userMedia) {
    if (self._streams.userMedia.stream) {
      stopFn(self._streams.userMedia.stream);
    }

    self._streams.userMedia = null;
    hasStoppedMedia = true;
  }

  if (stopScreenshare &amp;&amp; self._streams.screenshare) {
    if (self._streams.screenshare.streamClone) {
      stopFn(self._streams.screenshare.streamClone);
    }

    if (self._streams.screenshare.stream) {
      stopFn(self._streams.screenshare.stream);
    }

    self._streams.screenshare = null;
    hasStoppedMedia = true;
  }

  if (self._inRoom &amp;&amp; hasStoppedMedia) {
    self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
  }

  log.log(&#x27;Stopping Streams with settings -&gt;&#x27;, options);
};

/**
 * Function that parses the &lt;code&gt;getUserMedia()&lt;/code&gt; settings provided.
 * @method _parseStreamSettings
 * @private
 * @for Skylink
 * @since 0.6.15
 */
Skylink.prototype._parseStreamSettings = function(options) {
  var settings = {
    settings: { audio: false, video: false },
    mutedSettings: { shouldAudioMuted: false, shouldVideoMuted: false },
    getUserMediaSettings: { audio: false, video: false }
  };

  if (options.audio) {
    // For Edge to work since they do not support the advanced constraints yet
    settings.settings.audio = {
      stereo: false,
      exactConstraints: !!options.useExactConstraints,
      echoCancellation: true
    };
    settings.getUserMediaSettings.audio = {
      echoCancellation: true
    };

    if (typeof options.audio === &#x27;object&#x27;) {
      if (typeof options.audio.stereo === &#x27;boolean&#x27;) {
        settings.settings.audio.stereo = options.audio.stereo;
      }

      if (typeof options.audio.useinbandfec === &#x27;boolean&#x27;) {
        settings.settings.audio.useinbandfec = options.audio.useinbandfec;
      }

      if (typeof options.audio.usedtx === &#x27;boolean&#x27;) {
        settings.settings.audio.usedtx = options.audio.usedtx;
      }

      if (typeof options.audio.maxplaybackrate === &#x27;number&#x27; &amp;&amp;
        options.audio.maxplaybackrate &gt;= 8000 &amp;&amp; options.audio.maxplaybackrate &lt;= 48000) {
        settings.settings.audio.maxplaybackrate = options.audio.maxplaybackrate;
      }

      if (typeof options.audio.mute === &#x27;boolean&#x27;) {
        settings.mutedSettings.shouldAudioMuted = options.audio.mute;
      }

      // Not supported in Edge browser features
      if (window.webrtcDetectedBrowser !== &#x27;edge&#x27;) {
        if (typeof options.audio.echoCancellation === &#x27;boolean&#x27;) {
          settings.settings.audio.echoCancellation = options.audio.echoCancellation;
          settings.getUserMediaSettings.audio.echoCancellation = options.audio.echoCancellation;
        }

        if (Array.isArray(options.audio.optional)) {
          settings.settings.audio.optional = clone(options.audio.optional);
          settings.getUserMediaSettings.audio.optional = clone(options.audio.optional);
        }

        if (options.audio.deviceId &amp;&amp; typeof options.audio.deviceId === &#x27;string&#x27; &amp;&amp;
          window.webrtcDetectedBrowser !== &#x27;firefox&#x27;) {
          settings.settings.audio.deviceId = options.audio.deviceId;
          settings.getUserMediaSettings.audio.deviceId = options.useExactConstraints ?
            { exact: options.audio.deviceId } : { ideal: options.audio.deviceId };
        }
      }
    }

    if (window.webrtcDetectedBrowser === &#x27;edge&#x27;) {
      settings.getUserMediaSettings.audio = true;
    }
  }

  if (options.video) {
    // For Edge to work since they do not support the advanced constraints yet
    settings.settings.video = {
      resolution: clone(this.VIDEO_RESOLUTION.VGA),
      screenshare: false,
      exactConstraints: !!options.useExactConstraints
    };
    settings.getUserMediaSettings.video = {};

    if (typeof options.video === &#x27;object&#x27;) {
      if (typeof options.video.mute === &#x27;boolean&#x27;) {
        settings.mutedSettings.shouldVideoMuted = options.video.mute;
      }

      if (Array.isArray(options.video.optional)) {
        settings.settings.video.optional = clone(options.video.optional);
        settings.getUserMediaSettings.video.optional = clone(options.video.optional);
      }

      if (options.video.deviceId &amp;&amp; typeof options.video.deviceId === &#x27;string&#x27; &amp;&amp;
        window.webrtcDetectedBrowser !== &#x27;firefox&#x27;) {
        settings.settings.video.deviceId = options.video.deviceId;
        settings.getUserMediaSettings.video.deviceId = options.useExactConstraints ?
          { exact: options.video.deviceId } : { ideal: options.video.deviceId };
      }

      if (options.video.resolution &amp;&amp; typeof options.video.resolution === &#x27;object&#x27;) {
        if ((options.video.resolution.width &amp;&amp; typeof options.video.resolution.width === &#x27;object&#x27;) ||
          typeof options.video.resolution.width === &#x27;number&#x27;) {
          settings.settings.video.resolution.width = options.video.resolution.width;
        }
        if ((options.video.resolution.height &amp;&amp; typeof options.video.resolution.height === &#x27;object&#x27;) ||
          typeof options.video.resolution.height === &#x27;number&#x27;) {
          settings.settings.video.resolution.height = options.video.resolution.height;
        }
      }

      settings.getUserMediaSettings.video.width = typeof settings.settings.video.resolution.width === &#x27;object&#x27; ?
        settings.settings.video.resolution.width : (options.useExactConstraints ?
        { exact: settings.settings.video.resolution.width } : { max: settings.settings.video.resolution.width });

      settings.getUserMediaSettings.video.height = typeof settings.settings.video.resolution.height === &#x27;object&#x27; ?
        settings.settings.video.resolution.height : (options.useExactConstraints ?
        { exact: settings.settings.video.resolution.height } : { max: settings.settings.video.resolution.height });

      if ((options.video.frameRate &amp;&amp; typeof options.video.frameRate === &#x27;object&#x27;) ||
        typeof options.video.frameRate === &#x27;number&#x27; &amp;&amp; !self._isUsingPlugin) {
        settings.settings.video.frameRate = options.video.frameRate;
        settings.getUserMediaSettings.video.frameRate = typeof settings.settings.video.frameRate === &#x27;object&#x27; ?
          settings.settings.video.frameRate : (options.useExactConstraints ?
          { exact: settings.settings.video.frameRate } : { max: settings.settings.video.frameRate });
      }

      if (options.video.facingMode &amp;&amp; [&#x27;string&#x27;, &#x27;object&#x27;].indexOf(typeof options.video.facingMode) &gt; -1 &amp;&amp; self._isUsingPlugin) {
        settings.settings.video.facingMode = options.video.facingMode;
        settings.getUserMediaSettings.video.facingMode = typeof settings.settings.video.facingMode === &#x27;object&#x27; ?
          settings.settings.video.facingMode : (options.useExactConstraints ?
          { exact: settings.settings.video.facingMode } : { max: settings.settings.video.facingMode });
      }
    } else {
      settings.getUserMediaSettings.video = {
        width: options.useExactConstraints ? { exact: settings.settings.video.resolution.width } :
          { max: settings.settings.video.resolution.width },
        height: options.useExactConstraints ? { exact: settings.settings.video.resolution.height } :
          { max: settings.settings.video.resolution.height }
      };
    }

    if (window.webrtcDetectedBrowser === &#x27;edge&#x27;) {
      settings.settings.video = {
        screenshare: false,
        exactConstraints: !!options.useExactConstraints
      };
      settings.getUserMediaSettings.video = true;
    }
  }

  return settings;
};

/**
 * Function that handles the native &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API success callback result.
 * @method _onStreamAccessSuccess
 * @private
 * @for Skylink
 * @since 0.3.0
 */
Skylink.prototype._onStreamAccessSuccess = function(stream, settings, isScreenSharing, isAudioFallback) {
  var self = this;
  var streamId = stream.id || stream.label;
  var streamHasEnded = false;

  log.log([null, &#x27;MediaStream&#x27;, streamId, &#x27;Has access to stream -&gt;&#x27;], stream);

  // Stop previous stream
  if (!isScreenSharing &amp;&amp; self._streams.userMedia) {
    self._stopStreams({
      userMedia: true,
      screenshare: false
    });

  } else if (isScreenSharing &amp;&amp; self._streams.screenshare) {
    self._stopStreams({
      userMedia: false,
      screenshare: true
    });
  }

  self._streamsStoppedCbs[streamId] = function () {
    log.log([null, &#x27;MediaStream&#x27;, streamId, &#x27;Stream has ended&#x27;]);
    streamHasEnded = true;
    self._trigger(&#x27;mediaAccessStopped&#x27;, !!isScreenSharing, !!isAudioFallback, streamId);

    if (self._inRoom) {
      log.debug([null, &#x27;MediaStream&#x27;, streamId, &#x27;Sending Stream ended status to Peers&#x27;]);

      self._sendChannelMessage({
        type: self._SIG_MESSAGE_TYPE.STREAM,
        mid: self._user.sid,
        rid: self._room.id,
        cid: self._key,
        streamId: streamId,
        settings: settings.settings,
        status: &#x27;ended&#x27;
      });

      self._trigger(&#x27;streamEnded&#x27;, self._user.sid, self.getPeerInfo(), true, !!isScreenSharing, streamId);

      if (isScreenSharing &amp;&amp; self._streams.screenshare &amp;&amp; self._streams.screenshare.stream &amp;&amp;
        (self._streams.screenshare.stream.id || self._streams.screenshare.stream.label) === streamId) {
        self._streams.screenshare = null;

      } else if (!isScreenSharing &amp;&amp; self._streams.userMedia &amp;&amp; self._streams.userMedia.stream &amp;&amp;
        (self._streams.userMedia.stream.id || self._streams.userMedia.stream.label) === streamId) {
        self._streams.userMedia = null;
      }
    }
  };

  // Handle event for Chrome / Opera
  if ([&#x27;chrome&#x27;, &#x27;opera&#x27;].indexOf(window.webrtcDetectedBrowser) &gt; -1) {
    stream.oninactive = function () {
      if (self._streamsStoppedCbs[streamId]) {
        self._streamsStoppedCbs[streamId]();
        delete self._streamsStoppedCbs[streamId];
      }
    };

    if (isScreenSharing &amp;&amp; stream.getVideoTracks().length &gt; 0) {
      stream.getVideoTracks()[0].onended = function () {
        setTimeout(function () {
          if (!streamHasEnded &amp;&amp; self._inRoom) {
            self.stopScreen();
          }
        }, 350);
      };
    }

  // Handle event for Firefox (use an interval)
  } else if (window.webrtcDetectedBrowser === &#x27;firefox&#x27;) {
    stream.endedInterval = setInterval(function () {
      if (typeof stream.recordedTime === &#x27;undefined&#x27;) {
        stream.recordedTime = 0;
      }
      if (stream.recordedTime === stream.currentTime) {
        clearInterval(stream.endedInterval);

        if (self._streamsStoppedCbs[streamId]) {
          self._streamsStoppedCbs[streamId]();
          delete self._streamsStoppedCbs[streamId];
        }

      } else {
        stream.recordedTime = stream.currentTime;
      }
    }, 1000);

  } else {
    stream.onended = function () {
      if (self._streamsStoppedCbs[streamId]) {
        self._streamsStoppedCbs[streamId]();
        delete self._streamsStoppedCbs[streamId];
      }
    };
  }

  if ((settings.settings.audio &amp;&amp; stream.getAudioTracks().length === 0) ||
    (settings.settings.video &amp;&amp; stream.getVideoTracks().length === 0)) {

    var tracksNotSameError = &#x27;Expected audio tracks length with &#x27; +
      (settings.settings.audio ? &#x27;1&#x27; : &#x27;0&#x27;) + &#x27; and video tracks length with &#x27; +
      (settings.settings.video ? &#x27;1&#x27; : &#x27;0&#x27;) + &#x27; but received audio tracks length &#x27; +
      &#x27;with &#x27; + stream.getAudioTracks().length + &#x27; and video &#x27; +
      &#x27;tracks length with &#x27; + stream.getVideoTracks().length;

    log.warn([null, &#x27;MediaStream&#x27;, streamId, tracksNotSameError]);

    var requireAudio = !!settings.settings.audio;
    var requireVideo = !!settings.settings.video;

    if (settings.settings.audio &amp;&amp; stream.getAudioTracks().length === 0) {
      settings.settings.audio = false;
    }

    if (settings.settings.video &amp;&amp; stream.getVideoTracks().length === 0) {
      settings.settings.video = false;
    }

    self._trigger(&#x27;mediaAccessFallback&#x27;, {
      error: new Error(tracksNotSameError),
      diff: {
        video: { expected: requireVideo ? 1 : 0, received: stream.getVideoTracks().length },
        audio: { expected: requireAudio ? 1 : 0, received: stream.getAudioTracks().length }
      }
    }, self.MEDIA_ACCESS_FALLBACK_STATE.FALLBACKED, !!isScreenSharing, !!isAudioFallback, streamId);
  }

  self._streams[ isScreenSharing ? &#x27;screenshare&#x27; : &#x27;userMedia&#x27; ] = {
    stream: stream,
    settings: settings.settings,
    constraints: settings.getUserMediaSettings
  };
  self._muteStreams();
  self._trigger(&#x27;mediaAccessSuccess&#x27;, stream, !!isScreenSharing, !!isAudioFallback, streamId);
};

/**
 * Function that handles the native &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API failure callback result.
 * @method _onStreamAccessError
 * @private
 * @for Skylink
 * @since 0.6.15
 */
Skylink.prototype._onStreamAccessError = function(error, settings, isScreenSharing) {
  var self = this;

  if (!isScreenSharing &amp;&amp; settings.settings.audio &amp;&amp; settings.settings.video &amp;&amp; self._audioFallback) {
    log.debug(&#x27;Fallbacking to retrieve audio only Stream&#x27;);

    self._trigger(&#x27;mediaAccessFallback&#x27;, {
      error: error,
      diff: null
    }, self.MEDIA_ACCESS_FALLBACK_STATE.FALLBACKING, false, true);

    var successCbFn = function (stream) {
      self._onStreamAccessSuccess(stream, settings, false, true);
    };

    var errorCbFn = function (error) {
      log.error(&#x27;Failed fallbacking to retrieve audio only Stream -&gt;&#x27;, error);

      self._trigger(&#x27;mediaAccessError&#x27;, error, false, true);
      self._trigger(&#x27;mediaAccessFallback&#x27;, {
        error: error,
        diff: null
      }, self.MEDIA_ACCESS_FALLBACK_STATE.ERROR, false, true);
    };

    if (self._useSafariWebRTC) {
      navigator.mediaDevices.getUserMedia({
        audio: true
      }).then(successCbFn).catch(errorCbFn);

    } else {
      navigator.getUserMedia({
        audio: true
      }, successCbFn, errorCbFn);
    }
    return;
  }

  log.error(&#x27;Failed retrieving &#x27; + (isScreenSharing ? &#x27;screensharing&#x27; : &#x27;camera&#x27;) + &#x27; Stream -&gt;&#x27;, error);

  self._trigger(&#x27;mediaAccessError&#x27;, error, !!isScreenSharing, false);
};

/**
 * Function that handles the &lt;code&gt;RTCPeerConnection.onaddstream&lt;/code&gt; remote MediaStream received.
 * @method _onRemoteStreamAdded
 * @private
 * @for Skylink
 * @since 0.5.2
 */
Skylink.prototype._onRemoteStreamAdded = function(targetMid, stream, isScreenSharing) {
  var self = this;
  var streamId = self._useSafariWebRTC ? (self._peerConnections[targetMid] &amp;&amp;
    self._peerConnections[targetMid].remoteStreamId) : stream.id || stream.label;

  if (!self._peerInformations[targetMid]) {
    log.warn([targetMid, &#x27;MediaStream&#x27;, streamId, &#x27;Received remote stream when peer is not connected. Ignoring stream -&gt;&#x27;], stream);
    return;
  }

  /*if (!self._peerInformations[targetMid].settings.audio &amp;&amp;
    !self._peerInformations[targetMid].settings.video &amp;&amp; !isScreenSharing) {
    log.log([targetMid, &#x27;MediaStream&#x27;, stream.id,
      &#x27;Receive remote stream but ignoring stream as it is empty -&gt;&#x27;
      ], stream);
    return;
  }*/
  log.log([targetMid, &#x27;MediaStream&#x27;, streamId, &#x27;Received remote stream -&gt;&#x27;], stream);

  if (isScreenSharing) {
    log.log([targetMid, &#x27;MediaStream&#x27;, streamId, &#x27;Peer is having a screensharing session with user&#x27;]);
  }

  self._trigger(&#x27;incomingStream&#x27;, targetMid, stream, false, self.getPeerInfo(targetMid), isScreenSharing, streamId);
  self._trigger(&#x27;peerUpdated&#x27;, targetMid, self.getPeerInfo(targetMid), false);
};

/**
 * Function that sets User&#x27;s Stream to send to Peer connection.
 * Priority for &lt;code&gt;shareScreen()&lt;/code&gt; Stream over &lt;code&gt;getUserMedia()&lt;/code&gt; Stream.
 * @method _addLocalMediaStreams
 * @private
 * @for Skylink
 * @since 0.5.2
 */
Skylink.prototype._addLocalMediaStreams = function(peerId) {
  var self = this;

  // NOTE ALEX: here we could do something smarter
  // a mediastream is mainly a container, most of the info
  // are attached to the tracks. We should iterates over track and print
  try {
    log.log([peerId, null, null, &#x27;Adding local stream&#x27;]);

    var pc = self._peerConnections[peerId];
    var peerAgent = ((self._peerInformations[peerId] || {}).agent || {}).name || &#x27;&#x27;;
    var peerVersion = ((self._peerInformations[peerId] || {}).agent || {}).version || 0;
    var offerToReceiveAudio = !(!self._sdpSettings.connection.audio &amp;&amp; peerId !== &#x27;MCU&#x27;);
    var offerToReceiveVideo = !(!self._sdpSettings.connection.video &amp;&amp; peerId !== &#x27;MCU&#x27;) &amp;&amp; self._getSDPEdgeVideoSupports(peerId);

    if (pc) {
      if (pc.signalingState !== self.PEER_CONNECTION_STATE.CLOSED) {
        // Updates the streams accordingly
        var updateStreamFn = function (updatedStream) {
          if (self._useSafariWebRTC) {
            if (updatedStream ? (pc.localStreamId ? updatedStream.id !== pc.localStreamId : true) : true) {
              pc.getSenders().forEach(function (sender) {
                pc.removeTrack(sender);
              });

              if (updatedStream) {
                updatedStream.getTracks().forEach(function (track) {
                  pc.addTrack(track);
                });
                
                pc.localStreamId = updatedStream.id;
                pc.localStream = updatedStream;
              }
            }

          } else {
            var hasStream = false;

            // remove streams
            var streams = pc.getLocalStreams();
            for (var i = 0; i &lt; streams.length; i++) {
              if (updatedStream !== null &amp;&amp; streams[i].id === updatedStream.id) {
                hasStream = true;
                continue;
              }
              // try removeStream
              pc.removeStream(streams[i]);
            }

            if (updatedStream !== null &amp;&amp; !hasStream) {
              if (window.webrtcDetectedBrowser === &#x27;edge&#x27; &amp;&amp; (!offerToReceiveVideo || !offerToReceiveAudio)) {
                try {
                  var cloneStream = updatedStream.clone();
                  var tracks = cloneStream.getTracks();
                  for (var t = 0; t &lt; tracks.length; t++) {
                    if (tracks[t].kind === &#x27;video&#x27; ? !offerToReceiveVideo : !offerToReceiveAudio) {
                      cloneStream.removeTrack(tracks[t]);
                    } else {
                      tracks[t].enabled = tracks[t].kind === &#x27;audio&#x27; ? !self._streamsMutedSettings.audioMuted :
                        !self._streamsMutedSettings.videoMuted;
                    }
                  }
                  pc.addStream(cloneStream);
                } catch (e) {
                  pc.addStream(updatedStream);
                }
              } else {
                pc.addStream(updatedStream);
              }
              pc.addStream(window.webrtcDetectedBrowser === &#x27;edge&#x27; ? updatedStream.clone() : updatedStream);
            }
          }
        };

        if (self._streams.screenshare &amp;&amp; self._streams.screenshare.stream) {
          log.debug([peerId, &#x27;MediaStream&#x27;, null, &#x27;Sending screen&#x27;], self._streams.screenshare.stream);

          updateStreamFn(self._streams.screenshare.stream);

        } else if (self._streams.userMedia &amp;&amp; self._streams.userMedia.stream) {
          log.debug([peerId, &#x27;MediaStream&#x27;, null, &#x27;Sending stream&#x27;], self._streams.userMedia.stream);

          updateStreamFn(self._streams.userMedia.stream);

        } else {
          log.warn([peerId, &#x27;MediaStream&#x27;, null, &#x27;No media to send. Will be only receiving&#x27;]);

          updateStreamFn(null);
        }

      } else {
        log.warn([peerId, &#x27;MediaStream&#x27;, null,
          &#x27;Not adding any stream as signalingState is closed&#x27;]);
      }
    } else {
      log.warn([peerId, &#x27;MediaStream&#x27;, self._mediaStream,
        &#x27;Not adding stream as peerconnection object does not exists&#x27;]);
    }
  } catch (error) {
    if ((error.message || &#x27;&#x27;).indexOf(&#x27;already added&#x27;) &gt; -1) {
      log.warn([peerId, null, null, &#x27;Not re-adding stream as LocalMediaStream is already added&#x27;], error);
    } else {
      // Fix errors thrown like NS_ERROR_UNEXPECTED
      log.error([peerId, null, null, &#x27;Failed adding local stream&#x27;], error);
    }
  }
};

/**
 * Function that handles ended streams.
 * @method _handleEndedStreams
 * @private
 * @for Skylink
 * @since 0.6.16
 */
Skylink.prototype._handleEndedStreams = function (peerId, checkStreamId) {
  var self = this;
  self._streamsSession[peerId] = self._streamsSession[peerId] || {};

  var renderEndedFn = function (streamId) {
    if (self._streamsSession[peerId][streamId]) {
      var peerInfo = clone(self.getPeerInfo(peerId));
      peerInfo.settings.audio = clone(self._streamsSession[peerId][streamId].audio);
      peerInfo.settings.video = clone(self._streamsSession[peerId][streamId].video);
      var hasScreenshare = peerInfo.settings.video &amp;&amp; typeof peerInfo.settings.video === &#x27;object&#x27; &amp;&amp;
        !!peerInfo.settings.video.screenshare;
      self._streamsSession[peerId][streamId] = false;
      self._trigger(&#x27;streamEnded&#x27;, peerId, peerInfo, false, hasScreenshare, streamId);
    }
  };

  if (checkStreamId) {
    renderEndedFn(checkStreamId);
  } else if (self._peerConnections[peerId]) {
    for (var streamId in self._streamsSession[peerId]) {
      if (self._streamsSession[peerId].hasOwnProperty(streamId) &amp;&amp; self._streamsSession[peerId][streamId]) {
        renderEndedFn(streamId);
      }
    }
  }
};
    </pre>
</div>

                  </div>
              </div>
          </div>
      </div>
  </div>
</div>
<script src="../assets/vendor/prettify/prettify-min.js"></script>
<script>prettyPrint();</script>
<script src="../assets/js/yui-prettify.js"></script>
<script src="../assets/../api.js"></script>
<script src="../assets/js/api-filter.js"></script>
<script src="../assets/js/api-list.js"></script>
<script src="../assets/js/api-search.js"></script>
<script src="../assets/js/apidocs.js"></script>
</body>
</html>
