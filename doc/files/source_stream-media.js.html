<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>SkylinkJS 0.6.14</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- font and icon -->
    <link rel="shortcut icon" type="image/ico" href="../assets/favicon.ico">
    <link rel="stylesheet" href="../assets/vendor/prettify/prettify-min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600,700|Source+Sans+Pro" type="text/css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600,700|Source+Code+Pro" type="text/css">
    <!-- styling -->
    <link rel="stylesheet" href="../assets/vendor/css/bootstrap.min.css">
    <link rel="stylesheet" href="../assets/vendor/css/bootstrap-theme.min.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="../assets/css/style.css">
    <!-- scripts -->
    <script src="../assets/vendor/js/jquery.min.js"></script>
    <script src="../assets/vendor/js/bootstrap.min.js"></script>
    <script src="../assets/js/script.js"></script>
    <script src="http://yui.yahooapis.com/combo?3.9.1/build/yui/yui-min.js"></script>
</head>
<body>

<div id="doc">
  <nav id="hd" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a href="" class="navbar-brand">
          <img src="../assets/img/logo.svg" />JS<small>Version: 0.6.14</small>
        </a>
      </div>
      <div id="navbar" class="navbar-collapse collapse">
        <ul id="api-list" class="nav navbar-nav navbar-right">
  <li class="dropdown">
    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Getting Started Examples <span class="caret"></span></a>
    <ul class="dropdown-menu" role="menu">
      <li><a href="https://temasys.com.sg/getting-started-with-webrtc-and-skylinkjs/">Setting up a Video Call</a></li>
      <li><a href="https://temasys.com.sg/screensharing-with-skylinkjs/">Setting up Screensharing</a></li>
      <li><a href="https://temasys.com.sg/building-a-simple-peer-to-peer-webrtc-chat/">Setting up a Chatroom</a></li>
    </ul>
  </li>
  
    <li><a href="../classes/Skylink.html">Documentation</a></li>
  
  <!--<li class="dropdown">
    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Classes <span class="caret"></span></a>
    <ul class="dropdown-menu" role="menu">
      
        <li><a href="../classes/Skylink.html">Skylink</a></li>
      
    </ul>
  </li>-->
  <li><a class="btn btn-info btn-navbar" href="http://developer.temasys.com.sg/">Developer Console</a></li>
  <li><a class="btn btn-info btn-navbar" href="http://support.temasys.com.sg/">Support</a></li>
  <!--<li class="dropdown">
    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Modules <span class="caret"></span></a>
    <ul class="dropdown-menu" role="menu">
      <li><a href="#api-modules">View all Modules</a></li>
      
    </ul>
  </li>-->
</ul>
<!--<form id="api-tabview" class="navbar-form navbar-right" role="form">
  <div id="api-tabview-filter" class="form-group">
    <input type="search" id="api-filter" placeholder="Type to filter APIs">
  </div>
</form>-->
      </div><!--/.navbar-collapse -->
    </div>
  </nav>
  <div id="bd" class="yui3-g">

      <div class="yui3-u-1-4">

      </div>
      <div class="yui3-u-3-4">
          
          <div class="apidocs">
              <div id="docs-main">
                  <div class="content content-main">
                      <h1 class="file-heading">File: source/stream-media.js</h1>

<div class="file">
    <pre class="code prettyprint linenums">
/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that if the video codec is not supported, the SDK will not configure the local &lt;code&gt;&quot;offer&quot;&lt;/code&gt; or
 *   &lt;code&gt;&quot;answer&quot;&lt;/code&gt; session description to prefer the codec.
 * &lt;/blockquote&gt;
 * The list of available video codecs to set as the preferred video codec to use to encode
 * sending video data when available encoded video codec for Peer connections
 * configured in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.
 * @attribute VIDEO_CODEC
 * @param {String} AUTO &lt;small&gt;Value &lt;code&gt;&quot;auto&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to not prefer any video codec but rather use the created
 *   local &lt;code&gt;&quot;offer&quot;&lt;/code&gt; / &lt;code&gt;&quot;answer&quot;&lt;/code&gt; session description video codec preference.
 * @param {String} VP8  &lt;small&gt;Value &lt;code&gt;&quot;VP8&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/VP8&quot;&gt;VP8&lt;/a&gt; video codec.
 * @param {String} H264 &lt;small&gt;Value &lt;code&gt;&quot;H264&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC&quot;&gt;H264&lt;/a&gt; video codec.
 * @type JSON
 * @readOnly
 * @for Skylink
 * @since 0.5.10
 */
Skylink.prototype.VIDEO_CODEC = {
  AUTO: &#x27;auto&#x27;,
  VP8: &#x27;VP8&#x27;,
  H264: &#x27;H264&#x27;
  //H264UC: &#x27;H264UC&#x27;
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that if the audio codec is not supported, the SDK will not configure the local &lt;code&gt;&quot;offer&quot;&lt;/code&gt; or
 *   &lt;code&gt;&quot;answer&quot;&lt;/code&gt; session description to prefer the codec.
 * &lt;/blockquote&gt;
 * The list of available audio codecs to set as the preferred audio codec to use to encode
 * sending audio data when available encoded audio codec for Peer connections
 * configured in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.
 * @attribute AUDIO_CODEC
 * @param {String} AUTO &lt;small&gt;Value &lt;code&gt;&quot;auto&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to not prefer any audio codec but rather use the created
 *   local &lt;code&gt;&quot;offer&quot;&lt;/code&gt; / &lt;code&gt;&quot;answer&quot;&lt;/code&gt; session description audio codec preference.
 * @param {String} OPUS &lt;small&gt;Value &lt;code&gt;&quot;opus&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/Opus_(audio_format)&quot;&gt;OPUS&lt;/a&gt; audio codec.
 * @param {String} ISAC &lt;small&gt;Value &lt;code&gt;&quot;ISAC&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/Internet_Speech_Audio_Codec&quot;&gt;ISAC&lt;/a&gt; audio codec.
 * @type JSON
 * @readOnly
 * @for Skylink
 * @since 0.5.10
 */
Skylink.prototype.AUDIO_CODEC = {
  AUTO: &#x27;auto&#x27;,
  ISAC: &#x27;ISAC&#x27;,
  OPUS: &#x27;opus&#x27;,
  //ILBC: &#x27;ILBC&#x27;,
  //G711: &#x27;G711&#x27;,
  //G722: &#x27;G722&#x27;,
  //SILK: &#x27;SILK&#x27;
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that currently &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt; only configures
 *   the maximum resolution of the Stream due to browser interopability and support.
 * &lt;/blockquote&gt;
 * The list of &lt;a href=&quot;https://en.wikipedia.org/wiki/Graphics_display_resolution#Video_Graphics_Array&quot;&gt;
 * video resolutions&lt;/a&gt; sets configured in the &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;.
 * @attribute VIDEO_RESOLUTION
 * @param {JSON} QQVGA &lt;small&gt;Value &lt;code&gt;{ width: 160, height: 120 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure QQVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @param {JSON} HQVGA &lt;small&gt;Value &lt;code&gt;{ width: 240, height: 160 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure HQVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;3:2&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @param {JSON} QVGA &lt;small&gt;Value &lt;code&gt;{ width: 320, height: 240 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure QVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 * @param {JSON} WQVGA &lt;small&gt;Value &lt;code&gt;{ width: 384, height: 240 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure WQVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:10&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @param {JSON} HVGA &lt;small&gt;Value &lt;code&gt;{ width: 480, height: 320 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure HVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;3:2&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @param {JSON} VGA &lt;small&gt;Value &lt;code&gt;{ width: 640, height: 480 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure VGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 * @param {JSON} WVGA &lt;small&gt;Value &lt;code&gt;{ width: 768, height: 480 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure WVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:10&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @param {JSON} FWVGA &lt;small&gt;Value &lt;code&gt;{ width: 854, height: 480 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure FWVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @param {JSON} SVGA &lt;small&gt;Value &lt;code&gt;{ width: 800, height: 600 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure SVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @param {JSON} DVGA &lt;small&gt;Value &lt;code&gt;{ width: 960, height: 640 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure DVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;3:2&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @param {JSON} WSVGA &lt;small&gt;Value &lt;code&gt;{ width: 1024, height: 576 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure WSVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 * @param {JSON} HD &lt;small&gt;Value &lt;code&gt;{ width: 1280, height: 720 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure HD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 * @param {JSON} HDPLUS &lt;small&gt;Value &lt;code&gt;{ width: 1600, height: 900 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure HDPLUS resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @param {JSON} FHD &lt;small&gt;Value &lt;code&gt;{ width: 1920, height: 1080 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure FHD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @param {JSON} QHD &lt;small&gt;Value &lt;code&gt;{ width: 2560, height: 1440 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure QHD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @param {JSON} WQXGAPLUS &lt;small&gt;Value &lt;code&gt;{ width: 3200, height: 1800 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure WQXGAPLUS resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @param {JSON} UHD &lt;small&gt;Value &lt;code&gt;{ width: 3840, height: 2160 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure UHD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @param {JSON} UHDPLUS &lt;small&gt;Value &lt;code&gt;{ width: 5120, height: 2880 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure UHDPLUS resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @param {JSON} FUHD &lt;small&gt;Value &lt;code&gt;{ width: 7680, height: 4320 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure FUHD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @param {JSON} QUHD &lt;small&gt;Value &lt;code&gt;{ width: 15360, height: 8640 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure QUHD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported.&lt;/small&gt;
 * @type JSON
 * @readOnly
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype.VIDEO_RESOLUTION = {
  QQVGA: { width: 160, height: 120, aspectRatio: &#x27;4:3&#x27; },
  HQVGA: { width: 240, height: 160, aspectRatio: &#x27;3:2&#x27; },
  QVGA: { width: 320, height: 240, aspectRatio: &#x27;4:3&#x27; },
  WQVGA: { width: 384, height: 240, aspectRatio: &#x27;16:10&#x27; },
  HVGA: { width: 480, height: 320, aspectRatio: &#x27;3:2&#x27; },
  VGA: { width: 640, height: 480, aspectRatio: &#x27;4:3&#x27; },
  WVGA: { width: 768, height: 480, aspectRatio: &#x27;16:10&#x27; },
  FWVGA: { width: 854, height: 480, aspectRatio: &#x27;16:9&#x27; },
  SVGA: { width: 800, height: 600, aspectRatio: &#x27;4:3&#x27; },
  DVGA: { width: 960, height: 640, aspectRatio: &#x27;3:2&#x27; },
  WSVGA: { width: 1024, height: 576, aspectRatio: &#x27;16:9&#x27; },
  HD: { width: 1280, height: 720, aspectRatio: &#x27;16:9&#x27; },
  HDPLUS: { width: 1600, height: 900, aspectRatio: &#x27;16:9&#x27; },
  FHD: { width: 1920, height: 1080, aspectRatio: &#x27;16:9&#x27; },
  QHD: { width: 2560, height: 1440, aspectRatio: &#x27;16:9&#x27; },
  WQXGAPLUS: { width: 3200, height: 1800, aspectRatio: &#x27;16:9&#x27; },
  UHD: { width: 3840, height: 2160, aspectRatio: &#x27;16:9&#x27; },
  UHDPLUS: { width: 5120, height: 2880, aspectRatio: &#x27;16:9&#x27; },
  FUHD: { width: 7680, height: 4320, aspectRatio: &#x27;16:9&#x27; },
  QUHD: { width: 15360, height: 8640, aspectRatio: &#x27;16:9&#x27; }
};

/**
 * The list of &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt; Stream fallback states.
 * @attribute MEDIA_ACCESS_FALLBACK_STATE
 * @param {JSON} FALLBACKING &lt;small&gt;Value &lt;code&gt;0&lt;/code&gt;&lt;/small&gt;
 *   The value of the state when &lt;code&gt;getUserMedia()&lt;/code&gt; will retrieve audio track only
 *   when retrieving audio and video tracks failed.
 *   &lt;small&gt;This can be configured by &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;
 *   &lt;code&gt;audioFallback&lt;/code&gt; option.&lt;/small&gt;
 * @param {JSON} FALLBACKED  &lt;small&gt;Value &lt;code&gt;1&lt;/code&gt;&lt;/small&gt;
 *   The value of the state when &lt;code&gt;getUserMedia()&lt;/code&gt; retrieves camera Stream successfully but with
 *   missing originally required audio or video tracks.
 * @param {JSON} ERROR       &lt;small&gt;-1&lt;/code&gt;&lt;/small&gt;
 *   The value of the state when &lt;code&gt;getUserMedia()&lt;/code&gt; failed to retrieve audio track only
 *   after retrieving audio and video tracks failed.
 * @readOnly
 * @for Skylink
 * @since 0.6.14
 */
Skylink.prototype.MEDIA_ACCESS_FALLBACK_STATE = {
  FALLBACKING: 0,
  FALLBACKED: 1,
  ERROR: -1
};

/**
 * Stores the preferred sending Peer connection streaming audio codec.
 * @attribute _selectedAudioCodec
 * @type String
 * @default &quot;auto&quot;
 * @private
 * @for Skylink
 * @since 0.5.10
 */
Skylink.prototype._selectedAudioCodec = &#x27;auto&#x27;;

/**
 * Stores the preferred sending Peer connection streaming video codec.
 * @attribute _selectedVideoCodec
 * @type String
 * @default &quot;auto&quot;
 * @private
 * @for Skylink
 * @since 0.5.10
 */
Skylink.prototype._selectedVideoCodec = &#x27;auto&#x27;;

/**
 * Stores the User&#x27;s &lt;code&gt;getUserMedia()&lt;/code&gt; Stream.
 * @attribute _mediaStream
 * @type MediaStream
 * @private
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._mediaStream = null;

/**
 * Stores the User&#x27;s &lt;code&gt;shareScreen()&lt;/code&gt; Stream.
 * @attribute _mediaScreen
 * @type MediaStream
 * @private
 * @for Skylink
 * @since 0.6.0
 */
Skylink.prototype._mediaScreen = null;

/**
 * Stores the User&#x27;s &lt;code&gt;shareScreen()&lt;/code&gt; Stream clone for storing the video track.
 * Currently Chrome doesn&#x27;t give us the audio track in the stream we receive, so we have to
 *   make another getUserMedia() call to retrieve the audio track only.
 * @attribute _mediaScreenClone
 * @type MediaStream
 * @private
 * @for Skylink
 * @since 0.6.0
 */
Skylink.prototype._mediaScreenClone = null;

/**
 * Stores the default Stream settings for &lt;code&gt;getUserMedia()&lt;/code&gt; method.
 * @attribute _defaultStreamSettings
 * @param {JSON} audio The default Stream audio settings.
 * @param {JSON} video The default Stream video settings.
 * @type JSON
 * @private
 * @for Skylink
 * @since 0.5.7
 */
Skylink.prototype._defaultStreamSettings = {
  audio: {
    stereo: false
  },
  video: {
    resolution: {
      width: 640,
      height: 480
    },
    frameRate: 50
  },
  bandwidth: {
    //audio: 50,
    //video: 256,
    //data: 1638400
  }
};

/**
 * Stores the &lt;code&gt;getUserMedia()&lt;/code&gt; Stream settings.
 * @attribute _streamSettings
 * @param {JSON} audio The Stream audio settings.
 * @param {JSON} video The Stream video settings.
 * @type JSON
 * @private
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._streamSettings = {};

/**
 * Stores the &lt;code&gt;shareScreen()&lt;/code&gt; Stream settings.
 * @attribute _screenSharingStreamSettings
 * @param {JSON} audio The Stream audio settings.
 * @param {JSON} video The Stream video settings.
 * @type JSON
 * @private
 * @for Skylink
 * @since 0.6.1
 */
Skylink.prototype._screenSharingStreamSettings = {
  video: true
};

/**
 * Stores the flag that indicates if screensharing is supported in the browser.
 * @attribute _screenSharingAvailable
 * @type Boolean
 * @private
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._screenSharingAvailable = false;

/**
 * Stores the native &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API constraints for
 *   &lt;code&gt;getUserMedia()&lt;/code&gt; retrieval of Stream.
 * @attribute _getUserMediaSettings
 * @type JSON
 * @private
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._getUserMediaSettings = {};

/**
 * Stores the User&#x27;s Stream (both &lt;code&gt;getUserMedia()&lt;/code&gt; and &lt;code&gt;shareScreen()&lt;/code&gt;) muted status.
 * @attribute _mediaStreamsStatus
 * @param {Boolean} audioMuted The flag that indicates if audio is muted or not available.
 * @param {Boolean} videoMuted The flag that indicates if video is muted or not available.
 * @type JSON
 * @private
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._mediaStreamsStatus = {};

/**
 * Stores the flag that indicates if &lt;code&gt;getUserMedia()&lt;/code&gt; should fallback to retrieve
 *   audio only Stream after retrieval of audio and video Stream had failed.
 * @attribute _audioFallback
 * @type Boolean
 * @default false
 * @private
 * @for Skylink
 * @since 0.5.4
 */
Skylink.prototype._audioFallback = false;

/**
 * Function that retrieves camera Stream.
 * @method getUserMedia
 * @param {JSON} [options] The camera Stream configuration options.
 * - When not provided, the value is set to &lt;code&gt;{ audio: true, video: true }&lt;/code&gt;.
 *   &lt;small&gt;To fallback to retrieve audio track only when retrieving of audio and video tracks failed,
 *   enable the &lt;code&gt;audioFallback&lt;/code&gt; flag in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;
 * @param {Boolean|JSON} [options.audio=false] The audio configuration options.
 * @param {Boolean} [options.audio.stereo=false] The flag if stereo band should be configured
 *   when encoding audio codec is &lt;a href=&quot;#attr_AUDIO_CODEC&quot;&gt;&lt;code&gt;OPUS&lt;/code&gt;&lt;/a&gt; for sending audio data.
 * @param {Boolean} [options.audio.mute=false] The flag if audio tracks should be muted upon receiving them.
 * @param {Array} [options.audio.optional] The &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API
 *   &lt;code&gt;audio: { optional [..] }&lt;/code&gt; property.
 * @param {Boolean|JSON} [options.video=false] The video configuration options.
 * @param {Boolean} [options.video.mute=false] The flag if video tracks should be muted upon receiving them.
 * @param {JSON} [options.video.resolution] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that currently &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt; only configures
 *   the maximum resolution of the camera Stream due to browser interopability and support. &lt;/blockquote&gt;
 *   The video resolution.
 *   &lt;small&gt;By default, &lt;a href=&quot;#attr_VIDEO_RESOLUTION&quot;&gt;&lt;code&gt;VGA&lt;/code&gt;&lt;/a&gt; resolution option
 *   is selected when not provided.&lt;/small&gt;
 *   [Rel: Skylink.VIDEO_RESOLUTION]
 * @param {Number} [options.video.resolution.width] The video resolution width.
 * @param {Number} [options.video.resolution.height] The video resolution height.
 * @param {Number} [options.video.frameRate=50] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that currently &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt; only configures
 *   the maximum frameRate of the camera Stream due to browser interopability and support. For Safari and IE browsers
 *   (plugin-enabled), the maximum frameRate is not configured due to the lack of support.&lt;/blockquote&gt;
 *   The video &lt;a href=&quot;https://en.wikipedia.org/wiki/Frame_rate&quot;&gt;frameRate&lt;/a&gt; per second (fps).
 * @param {Array} [options.video.optional] The &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API
 *   &lt;code&gt;video: { optional [..] }&lt;/code&gt; property.
 * @param {Function} [callback] The callback function fired when request has completed.
 *   &lt;small&gt;Function parameters signature is &lt;code&gt;function (error, success)&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Function request completion is determined by the &lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggering &lt;code&gt;isScreensharing&lt;/code&gt; parameter
 *   payload value as &lt;code&gt;false&lt;/code&gt; for request success.&lt;/small&gt;
 * @param {Error|String} callback.error The error result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are no errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;code&gt;getUserMedia()&lt;/code&gt; error when retrieving camera Stream.&lt;/small&gt;
 * @param {MediaStream} callback.success The success result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the camera Stream object.&lt;/small&gt;
 * @example
 *   // Example 1: Get both audio and video.
 *   skylinkDemo.getUserMedia(function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *   });
 *
 *   // Example 2: Get only audio.
 *   skylinkDemo.getUserMedia({
 *     audio: true
 *   }, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-audio&quot;), success);
 *   });
 *
 *   // Example 3: Configure resolution for video
 *   skylinkDemo.getUserMedia({
 *     audio: true,
 *     video: {
 *       resolution: skylinkDemo.VIDEO_RESOLUTION.HD
 *     }
 *   }, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *   });
 *
 *   // Example 4: Configure stereo flag for OPUS codec audio (OPUS is always used by default)
 *   skylinkDemo.init({
 *     appKey: &quot;xxxxxx&quot;,
 *     audioCodec: skylinkDemo.AUDIO_CODEC.OPUS
 *   }, function (initErr, initSuccess) {
 *     skylinkDemo.getUserMedia({
 *       audio: {
 *         stereo: true
 *       },
 *       video: true
 *     }, function (error, success) {
 *       if (error) return;
 *       attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *     });
 *   });
 *
 *   // Example 5: Configure frameRate for video
 *   skylinkDemo.getUserMedia({
 *     audio: true,
 *     video: {
 *       frameRate: 50
 *     }
 *   }, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *   });
 *
 *   // Example 6: Configure video and audio based on selected sources. Does not work for Firefox currently.
 *   var sources = { audio: [], video: [] };
 *
 *   function selectStream (audioSourceId, videoSourceId) {
 *     skylinkDemo.getUserMedia({
 *       audio: {
 *         optional: [{ sourceId: audioSourceId }]
 *       },
 *       video: {
 *         optional: [{ sourceId: videoSourceId }]
 *       }
 *     }, function (error, success) {
 *       if (error) return;
 *       attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *     });
 *   }
 *
 *   navigator.mediaDevices.enumerateDevices().then(function(devices) {
 *     var selectedAudioSourceId = &quot;&quot;;
 *     var selectedVideoSourceId = &quot;&quot;;
 *     devices.forEach(function(device) {
 *       console.log(device.kind + &quot;: &quot; + device.label + &quot; source ID = &quot; + device.deviceId);
 *       if (device.kind === &quot;audio&quot;) {
 *         selectedAudioSourceId = device.deviceId;
 *       } else {
 *         selectedVideoSourceId = device.deviceId;
 *       }
 *     });
 *     selectStream(selectedAudioSourceId, selectedVideoSourceId);
 *   }).catch(function (error) {
 *      console.error(&quot;Failed&quot;, error);
 *   });
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;When retrieval of camera Stream is successful, &lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers parameter payload &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;ol&gt;
 *   &lt;li&gt;When there are missing required audio or video tracks, &lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;
 *   &lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; triggers parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;
 *   , &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;, &lt;code&gt;isAudioFallback&lt;/code&gt; as
 *   &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;error&lt;/code&gt; is defined.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;When retrieval of camera Stream has failed&lt;ol&gt;
 *   &lt;li&gt;If &lt;code&gt;audioFallback&lt;/code&gt; is enabled in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;
 *   configuration, and &lt;code&gt;options.video&lt;/code&gt; and &lt;code&gt;options.audio&lt;/code&gt; is requested &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; is triggers parameter payload
 *   &lt;code&gt;state&lt;/code&gt; value as &lt;code&gt;FALLBACKING&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;,
 *   &lt;code&gt;isAudioFallback&lt;/code&gt; as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;error&lt;/code&gt; is defined.&lt;/li&gt;
 *   &lt;li&gt;Invokes &lt;code&gt;getUserMedia()&lt;/code&gt; with &lt;code&gt;options.audio&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and
 *   &lt;code&gt;options.video&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;ol&gt;
 *   &lt;li&gt;When retrieval of camera Stream (fallbacked audio only) is successful&lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallback&lt;/code&gt; as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers parameter
 *   payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;When retrieval of camera Stream (fallbacked audio only) has failed &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;ERROR&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallback&lt;/code&gt; as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessError&quot;&gt;&lt;code&gt;mediaAccessError&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallbackError&lt;/code&gt;
 *   as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Else, &lt;a href=&quot;#event_mediaAccessError&quot;&gt;&lt;code&gt;mediaAccessError&lt;/code&gt; event&lt;/a&gt;
 *   triggers parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallbackError&lt;/code&gt; as &lt;code&gt;false&lt;/code&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype.getUserMedia = function(options,callback) {
  var self = this;

  var errorMsg; // j-shint rocks

  if (typeof options === &#x27;function&#x27;){
    callback = options;
    options = {
      audio: true,
      video: true
    };
  }
  else if (typeof options !== &#x27;object&#x27; || options === null) {
    if (typeof options === &#x27;undefined&#x27;) {
      options = {
        audio: true,
        video: true
      };
    } else {
      errorMsg = &#x27;Please provide a valid options&#x27;;
      log.error(errorMsg, options);
      if (typeof callback === &#x27;function&#x27;) {
        callback(new Error(errorMsg), null);
      }
      return;
    }
  }
  else if (!options.audio &amp;&amp; !options.video) {
    errorMsg = &#x27;Please select audio or video&#x27;;
    log.error(errorMsg, options);
    if (typeof callback === &#x27;function&#x27;) {
      callback(new Error(errorMsg), null);
    }
    return;
  }

  /*if (window.location.protocol !== &#x27;https:&#x27; &amp;&amp; window.webrtcDetectedBrowser === &#x27;chrome&#x27; &amp;&amp;
    window.webrtcDetectedVersion &gt; 46) {
    errorMsg = &#x27;getUserMedia() has to be called in https:// application&#x27;;
    log.error(errorMsg, options);
    if (typeof callback === &#x27;function&#x27;) {
      callback(new Error(errorMsg), null);
    }
    return;
  }*/

  // parse stream settings
  self._parseMediaStreamSettings(options);

  // if audio and video is false, do not call getUserMedia
  if (!(options.audio === false &amp;&amp; options.video === false)) {
    // clear previous mediastreams
    self.stopStream();

    setTimeout(function () {
      try {
        if (typeof callback === &#x27;function&#x27;){
          var mediaAccessErrorFn = function (error) {
            callback(error, null);
            self.off(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn);
          };

          var mediaAccessSuccessFn = function (stream) {
            callback(null, stream);
            self.off(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn);
          };

          self.once(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn);
          self.once(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn);
        }

        window.getUserMedia(self._getUserMediaSettings, function (stream) {
          var isSuccess = false;
          var requireAudio = !!options.audio;
          var requireVideo = !!options.video;
          var hasAudio = !requireAudio;
          var hasVideo = !requireVideo;

          // for now we require one MediaStream with both audio and video
          // due to firefox non-supported audio or video
          if (stream &amp;&amp; stream !== null) {
            var notSameTracksError = new Error(
              &#x27;Expected audio tracks length with &#x27; +
              (requireAudio ? &#x27;1&#x27; : &#x27;0&#x27;) + &#x27; and video tracks length with &#x27; +
              (requireVideo ? &#x27;1&#x27; : &#x27;0&#x27;) + &#x27; but received audio tracks length &#x27; +
              &#x27;with &#x27; + stream.getAudioTracks().length + &#x27; and video &#x27; +
              &#x27;tracks length with &#x27; + stream.getVideoTracks().length);

            // do the check
            if (requireAudio) {
              hasAudio = stream.getAudioTracks().length &gt; 0;
            }
            if (requireVideo) {
              hasVideo =  stream.getVideoTracks().length &gt; 0;

              /*if (self._audioFallback &amp;&amp; !hasVideo) {
                hasVideo = true; // to trick isSuccess to be true
                self._trigger(&#x27;mediaAccessFallback&#x27;, notSameTracksError);
              }*/
            }
            if (hasAudio &amp;&amp; hasVideo) {
              isSuccess = true;
            }

            if (!isSuccess) {
              self._trigger(&#x27;mediaAccessFallback&#x27;, {
                error: notSameTracksError,
                diff: {
                  video: { expected: requireAudio ? 1 : 0, received: stream.getVideoTracks().length },
                  audio: { expected: requireVideo ? 1 : 0, received: stream.getAudioTracks().length }
                }
              }, 1, false, false);
            }

            self._onUserMediaSuccess(stream);
          }
        }, function (error) {
          self._onUserMediaError(error, false, true);
        });
      } catch (error) {
        self._onUserMediaError(error, false, true);
      }
    }, window.webrtcDetectedBrowser === &#x27;firefox&#x27; ? 500 : 1);
  } else {
    log.warn([null, &#x27;MediaStream&#x27;, null, &#x27;Not retrieving stream&#x27;]);
  }
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that if &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; is available despite having
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; available, the
 *   &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; is sent instead of the
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; to Peers.
 * &lt;/blockquote&gt;
 * Function that sends a new &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;
 * to all connected Peers in the Room.
 * @method sendStream
 * @param {JSON|MediaStream} options The &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt;
 *   method&lt;/a&gt; &lt;code&gt;options&lt;/code&gt; parameter settings.
 * - When provided as a &lt;code&gt;MediaStream&lt;/code&gt; object, this configures the &lt;code&gt;options.audio&lt;/code&gt; and
 *   &lt;code&gt;options.video&lt;/code&gt; based on the tracks available in the &lt;code&gt;MediaStream&lt;/code&gt; object,
 *   and configures the &lt;code&gt;options.audio.mute&lt;/code&gt; and &lt;code&gt;options.video.mute&lt;/code&gt; based on the tracks
 *   &lt;code&gt;.enabled&lt;/code&gt; flags in the tracks provided in the &lt;code&gt;MediaStream&lt;/code&gt; object without
 *   invoking &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;.
 *   &lt;small&gt;Object signature matches the &lt;code&gt;options&lt;/code&gt; parameter in the
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;
 * @param {Function} [callback] The callback function fired when request has completed.
 *   &lt;small&gt;Function parameters signature is &lt;code&gt;function (error, success)&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Function request completion is determined by the &lt;a href=&quot;#event_peerRestart&quot;&gt;
 *   &lt;code&gt;peerRestart&lt;/code&gt; event&lt;/a&gt; triggering &lt;code&gt;isSelfInitiateRestart&lt;/code&gt; parameter payload
 *   value as &lt;code&gt;true&lt;/code&gt; for all Peers currently in the Room targeted for request success.&lt;/small&gt;
 * @param {Error|String} callback.error The error result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are no errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt; error or
 *   when invalid &lt;code&gt;options&lt;/code&gt; is provided.&lt;/small&gt;
 * @param {MediaStream} callback.success The success result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;
 *   Stream object.&lt;/small&gt;
 * @example
 *   // Example 1: Send MediaStream object
 *   function retrieveStreamBySourceForFirefox (sourceId) {
 *     navigator.mediaDevices.getUserMedia({
 *       audio: true,
 *       video: {
 *         sourceId: { exact: sourceId }
 *       }
 *     }).then(function (stream) {
 *       skylinkDemo.sendStream(stream, function (error, success) {
 *         if (err) return;
 *         if (stream === success) {
 *           console.info(&quot;Same MediaStream has been sent&quot;);
 *         }
 *         console.log(&quot;Stream is now being sent to Peers&quot;);
 *         attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *       });
 *     });
 *   }
 *
 *   // Example 2: Send video later
 *   var inRoom = false;
 *
 *   function sendVideo () {
 *     if (!inRoom) return;
 *     skylinkDemo.sendStream({
 *       audio: true,
 *       video: true
 *     }, function (error, success) {
 *       if (error) return;
 *       console.log(&quot;getUserMedia() Stream with video is now being sent to Peers&quot;);
 *       attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *     });
 *   }
 *
 *   skylinkDemo.joinRoom({
 *     audio: true
 *   }, function (jRError, jRSuccess) {
 *     if (jRError) return;
 *     inRoom = true;
 *   });
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_refreshConnection&quot;&gt;&lt;code&gt;refreshConnection()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;
 *   &lt;li&gt;If User is in the Room, &lt;a href=&quot;#event_incomingStream&quot;&gt;&lt;code&gt;incomingStream&lt;/code&gt; event&lt;/a&gt; triggers with
 *   parameter payload &lt;code&gt;isSelf&lt;/code&gt; as &lt;code&gt;true&lt;/code&gt;, and &lt;a href=&quot;#event_peerUpdate&quot;&gt;
 *   &lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers with parameter payload &lt;code&gt;isSelf&lt;/code&gt;
 *   as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.6
 */

Skylink.prototype.sendStream = function(stream, callback) {
  var self = this;
  var restartCount = 0;
  var peerCount = Object.keys(self._peerConnections).length;

  if (typeof stream !== &#x27;object&#x27; || stream === null) {
    var error = &#x27;Provided stream settings is invalid&#x27;;
    log.error(error, stream);
    if (typeof callback === &#x27;function&#x27;){
      callback(new Error(error),null);
    }
    return;
  }

  var hasNoPeers = Object.keys(self._peerConnections).length === 0;

  // Stream object
  // getAudioTracks or getVideoTracks first because adapterjs
  // has not implemeneted MediaStream as an interface
  // interopability with firefox and chrome
  //MediaStream = MediaStream || webkitMediaStream;
  // NOTE: eventually we should do instanceof
  if (typeof stream.getAudioTracks === &#x27;function&#x27; ||
    typeof stream.getVideoTracks === &#x27;function&#x27;) {
    // stop playback
    self.stopStream();

    self._streamSettings.audio = stream.getAudioTracks().length &gt; 0;
    self._streamSettings.video = stream.getVideoTracks().length &gt; 0;

    //self._mediaStreamsStatus.audioMuted = self._streamSettings.audio === false;
    //self._mediaStreamsStatus.videoMuted = self._streamSettings.video === false;

    if (self._inRoom) {
      self.once(&#x27;mediaAccessSuccess&#x27;, function (stream) {
        if (self._hasMCU) {
          self._restartMCUConnection();
        } else {
          self._trigger(&#x27;incomingStream&#x27;, self._user.sid, self._mediaStream,
            true, self.getPeerInfo(), false);
          for (var peer in self._peerConnections) {
            if (self._peerConnections.hasOwnProperty(peer)) {
              self._restartPeerConnection(peer, true, false, null, true);
            }
          }
        }

        self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
      });
    }

    // send the stream
    if (self._mediaStream !== stream) {
      self._onUserMediaSuccess(stream);
    }

    // The callback is provided and has peers, so require to wait for restart
    if (typeof callback === &#x27;function&#x27; &amp;&amp; !hasNoPeers) {
      self.once(&#x27;peerRestart&#x27;,function(peerId, peerInfo, isSelfInitiatedRestart){
        log.log([null, &#x27;MediaStream&#x27;, stream.id,
          &#x27;Stream was sent. Firing callback&#x27;], stream);
        callback(null,stream);
        restartCount = 0; //reset counter
      },function(peerId, peerInfo, isSelfInitiatedRestart){
        if (isSelfInitiatedRestart){
          restartCount++;
          if (restartCount === peerCount){
            return true;
          }
        }
        return false;
      },false);
    }

    // The callback is provided but there is no peers, so automatically invoke the callback
    if (typeof callback === &#x27;function&#x27; &amp;&amp; hasNoPeers) {
      callback(null, self._mediaStream);
    }

  // Options object
  } else {
    // The callback is provided but there is peers, so require to wait for restart
    if (typeof callback === &#x27;function&#x27; &amp;&amp; !hasNoPeers) {
      self.once(&#x27;peerRestart&#x27;,function(peerId, peerInfo, isSelfInitiatedRestart){
        log.log([null, &#x27;MediaStream&#x27;, stream.id,
          &#x27;Stream was sent. Firing callback&#x27;], stream);
        callback(null,stream);
        restartCount = 0; //reset counter
      },function(peerId, peerInfo, isSelfInitiatedRestart){
        if (isSelfInitiatedRestart){
          restartCount++;
          if (restartCount === peerCount){
            return true;
          }
        }
        return false;
      },false);
    }

    if (self._inRoom) {
      self.once(&#x27;mediaAccessSuccess&#x27;, function (stream) {
        if (self._hasMCU) {
          self._restartMCUConnection();
        } else {
          self._trigger(&#x27;incomingStream&#x27;, self._user.sid, self._mediaStream,
            true, self.getPeerInfo(), false);
          for (var peer in self._peerConnections) {
            if (self._peerConnections.hasOwnProperty(peer)) {
              self._restartPeerConnection(peer, true, false, null, true);
            }
          }
        }

        self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
      });
    }

    // get the mediastream and then wait for it to be retrieved before sending
    self._waitForLocalMediaStream(function (error) {
      if (!error) {
        // The callback is provided but there is not peers, so automatically invoke the callback
        if (typeof callback === &#x27;function&#x27; &amp;&amp; hasNoPeers) {
          callback(null, self._mediaStream);
        }
      } else {
        callback(error, null);
      }
    }, stream);
  }
};

/**
 * Function that stops &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;.
 * @method stopStream
 * @example
 *   function stopStream () {
 *     skylinkDemo.stopStream();
 *   }
 *
 *   skylinkDemo.getUserMedia();
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessStopped&quot;&gt;&lt;code&gt;mediaAccessStopped&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;If User is in the Room, &lt;a href=&quot;#event_streamEnded&quot;&gt;&lt;code&gt;streamEnded&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isSelf&lt;/code&gt; value
 *   as &lt;code&gt;true&lt;/code&gt;, and &lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype.stopStream = function () {
  // if previous line break, recheck again to trigger event
  this._stopLocalMediaStreams({
    userMedia: true
  });
};

/**
 * Function that mutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; audio or video tracks.
 * @method muteStream
 * @param {JSON} options The Streams muting options.
 * @param {Boolean} [options.audioMuted=true] The flag if all Streams audio
 *   tracks should be muted or not.
 * @param {Boolean} [options.videoMuted=true] The flag if all Streams video
 *   tracks should be muted or not.
 * @example
 *   // Example 1: Mute both audio and video tracks in all Streams
 *   skylinkDemo.muteStream({
 *     audioMuted: true,
 *     videoMuted: true
 *   });
 *
 *   // Example 2: Mute only audio tracks in all Streams
 *   skylinkDemo.muteStream({
 *     audioMuted: true,
 *     videoMuted: false
 *   });
 *
 *   // Example 3: Mute only video tracks in all Streams
 *   skylinkDemo.muteStream({
 *     audioMuted: false,
 *     videoMuted: true
 *   });
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;If User is in the Room, &lt;a href=&quot;#event_streamMuted&quot;&gt;&lt;code&gt;streamMuted&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;, and &lt;a href=&quot;#event_peerUpdated&quot;&gt;
 *   &lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload &lt;code&gt;isSelf&lt;/code&gt;
 *   value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.7
 */
Skylink.prototype.muteStream = function(options) {
  var self = this;
  var hasAudioError = false;
  var hasVideoError = false;

  if (typeof options !== &#x27;object&#x27;) {
    log.error(&#x27;Provided settings is not an object&#x27;);
    return;
  }

  if ((!self._mediaStream || self._mediaStream === null) &amp;&amp;
    (!self._mediaScreen || self._mediaScreen === null)) {
    log.warn(&#x27;No streams are available to mute / unmute!&#x27;);
    return;
  }

  // set the muted status
  if (typeof options.audioMuted === &#x27;boolean&#x27;) {
    if (self._streamSettings.audio === false) {
      log.error(&#x27;No audio available to mute / unmute&#x27;);
      hasAudioError = true;
    } else {
      if (options.audioMuted) {
        self._mediaStreamsStatus.audioMuted = true;
      } else {
        self._mediaStreamsStatus.audioMuted = false;
      }
    }
  }
  if (typeof options.videoMuted === &#x27;boolean&#x27;) {
    if (self._streamSettings.video === false) {
      log.error(&#x27;No video available to mute / unmute&#x27;);
      hasVideoError = true;
    } else {
      if (options.videoMuted) {
        self._mediaStreamsStatus.videoMuted = true;
      } else {
        self._mediaStreamsStatus.videoMuted = false;
      }
    }
  }

  var hasTracksOption = self._muteLocalMediaStreams();

  if (self._inRoom) {
    // update to mute status of video tracks
    if (hasTracksOption.hasVideoTracks) {
      // send message
      self._sendChannelMessage({
        type: self._SIG_MESSAGE_TYPE.MUTE_VIDEO,
        mid: self._user.sid,
        rid: self._room.id,
        muted: self._mediaStreamsStatus.videoMuted
      });
    }
    // update to mute status of audio tracks
    if (hasTracksOption.hasAudioTracks) {
      // send message
      // set timeout to do a wait interval of 1s
      setTimeout(function () {
        self._sendChannelMessage({
          type: self._SIG_MESSAGE_TYPE.MUTE_AUDIO,
          mid: self._user.sid,
          rid: self._room.id,
          muted: self._mediaStreamsStatus.audioMuted
        });
      }, 1050);
    }

    if (!hasAudioError || !hasVideoError) {
      self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
    }
  }

  if (!hasAudioError || !hasVideoError) {
    self._trigger(&#x27;streamMuted&#x27;, self._user.sid || null, self.getPeerInfo(), true,
      !!self._mediaScreen &amp;&amp; self._mediaScreen !== null);
  }
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that unmutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; audio tracks.
 * @method enableAudio
 * @deprecated true
 * @example
 *   function unmuteAudio () {
 *     skylinkDemo.enableAudio();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.audioMuted&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.enableAudio = function() {
  this.muteStream({
    audioMuted: false
  });
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that mutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; audio tracks.
 * @method disableAudio
 * @deprecated true
 * @example
 *   function muteAudio () {
 *     skylinkDemo.disableAudio();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.audioMuted&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.disableAudio = function() {
  this.muteStream({
    audioMuted: true
  });
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that unmutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; video tracks.
 * @method enableVideo
 * @deprecated true
 * @example
 *   function unmuteVideo () {
 *     skylinkDemo.enableVideo();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.videoMuted&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.enableVideo = function() {
  this.muteStream({
    videoMuted: false
  });
};

/**
 /**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that mutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; video tracks.
 * @method disableVideo
 * @deprecated true
 * @example
 *   function muteVideo () {
 *     skylinkDemo.disableVideo();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.videoMuted&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.disableVideo = function() {
  this.muteStream({
    videoMuted: true
  });
};

/**
 * Function that retrieves screensharing Stream.
 * @method shareScreen
 * @param {JSON} [enableAudio=false] The flag if audio tracks should be retrieved.

 * @param {Function} [callback] The callback function fired when request has completed.
 *   &lt;small&gt;Function parameters signature is &lt;code&gt;function (error, success)&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Function request completion is determined by the &lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggering &lt;code&gt;isScreensharing&lt;/code&gt; parameter
 *   payload value as &lt;code&gt;true&lt;/code&gt; for request success.&lt;/small&gt;
 * @param {Error|String} callback.error The error result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are no errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;code&gt;shareScreen()&lt;/code&gt; error when retrieving screensharing Stream.&lt;/small&gt;
 * @param {MediaStream} callback.success The success result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the screensharing Stream object.&lt;/small&gt;
 * @example
 *   // Example 1: Share screen with audio
 *   skylinkDemo.shareScreen(function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-screen&quot;), success);
 *   });
 *
 *   // Example 2: Share screen without audio
 *   skylinkDemo.shareScreen(false, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-screen&quot;), success);
 *   });
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;When retrieval of screensharing Stream is successful, &lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers parameter payload &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;true&lt;/code&gt;.&lt;ol&gt;
 *   &lt;li&gt;When there are missing required audio tracks, &lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;
 *   &lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; triggers parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;
 *   , &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;, &lt;code&gt;isAudioFallback&lt;/code&gt; as
 *   &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;error&lt;/code&gt; is defined.&lt;/li&gt;
 *   &lt;li&gt;If User is in Room, &lt;a href=&quot;#event_incomingStream&quot;&gt;&lt;code&gt;incomingStream&lt;/code&gt; event&lt;/a&gt; triggers.&lt;/li&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_refreshConnection&quot;&gt;&lt;code&gt;refreshConnection()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;When retrieval of screensharing Stream has failed, &lt;a href=&quot;#event_mediaAccessError&quot;&gt;
 *   &lt;code&gt;mediaAccessError&lt;/code&gt; event&lt;/a&gt; triggers parameter payload &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallbackError&lt;/code&gt; as &lt;code&gt;false&lt;/code&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.6.0
 */
Skylink.prototype.shareScreen = function (enableAudio, callback) {
  var self = this;
  var hasAudio = false;

  var settings = {
    video: {
      mediaSource: &#x27;window&#x27;
    }
  };

  if (typeof enableAudio === &#x27;function&#x27;) {
    callback = enableAudio;
    enableAudio = true;
  }

  if (typeof enableAudio !== &#x27;boolean&#x27;) {
    enableAudio = true;
  }

  var triggerSuccessFn = function (sStream) {
    if (hasAudio) {
      if (typeof self._streamSettings.audio === &#x27;object&#x27;) {
        self._screenSharingStreamSettings.audio = {
          stereo: !!self._streamSettings.audio.stereo
        };
      } else {
        self._screenSharingStreamSettings.audio = true;
      }
    } else {
      log.warn(&#x27;This screensharing session will not support audio streaming&#x27;);
      self._screenSharingStreamSettings.audio = false;
    }

    var requireAudio = enableAudio === true;
    var requireVideo = true;
    var checkAudio = !requireAudio;
    var checkVideo = !requireVideo;
    var notSameTracksError = new Error(
      &#x27;Expected audio tracks length with &#x27; +
      (requireAudio ? &#x27;1&#x27; : &#x27;0&#x27;) + &#x27; and video tracks length with &#x27; +
      (requireVideo ? &#x27;1&#x27; : &#x27;0&#x27;) + &#x27; but received audio tracks length &#x27; +
      &#x27;with &#x27; + sStream.getAudioTracks().length + &#x27; and video &#x27; +
      &#x27;tracks length with &#x27; + sStream.getVideoTracks().length);

    // do the check
    if (requireAudio) {
      checkAudio = sStream.getAudioTracks().length &gt; 0;
    }
    if (requireVideo) {
      checkVideo =  sStream.getVideoTracks().length &gt; 0;
    }

    if (checkVideo) {
      self._screenSharingStreamSettings.video = true;

      // no audio but has video for screensharing
      if (!checkAudio) {
        self._trigger(&#x27;mediaAccessFallback&#x27;, {
          error: notSameTracksError,
          diff: {
            video: { expected: 1, received: sStream.getVideoTracks().length },
            audio: { expected: requireAudio ? 1 : 0, received: sStream.getAudioTracks().length }
          }
        }, 1, true, false);
        self._screenSharingStreamSettings.audio = false;
      }

      self._onUserMediaSuccess(sStream, true);

    } else {
      self._onUserMediaError(notSameTracksError, true);
    }

    self._timestamp.screen = true;
  };

  if (window.webrtcDetectedBrowser === &#x27;firefox&#x27;) {
    settings.audio = !!enableAudio;
  }

  var throttleFn = function (fn, wait) {
    if (!self._timestamp.func){
      //First time run, need to force timestamp to skip condition
      self._timestamp.func = self._timestamp.now - wait;
    }
    var now = Date.now();

    if (!self._timestamp.screen) {
      if (now - self._timestamp.func &lt; wait) {
        return;
      }
    }
    fn();
    self._timestamp.screen = false;
    self._timestamp.func = now;
  };

  var toShareScreen = function(){
    try {
      window.getUserMedia(settings, function (stream) {
        self.once(&#x27;mediaAccessSuccess&#x27;, function (stream) {
          if (self._inRoom) {
            if (self._hasMCU) {
              self._restartMCUConnection();
            } else {
              self._trigger(&#x27;incomingStream&#x27;, self._user.sid, stream,
                true, self.getPeerInfo(), false);
              for (var peer in self._peerConnections) {
                if (self._peerConnections.hasOwnProperty(peer)) {
                  self._restartPeerConnection(peer, true, false, null, true);
                }
              }
            }
          } else if (typeof callback === &#x27;function&#x27;) {
            callback(null, stream);
          }
        }, function (stream, isScreenSharing) {
          return isScreenSharing;
        });

        if (window.webrtcDetectedBrowser !== &#x27;firefox&#x27; &amp;&amp; enableAudio) {
          window.getUserMedia({
            audio: true
          }, function (audioStream) {
            try {
              audioStream.addTrack(stream.getVideoTracks()[0]);
              self._mediaScreenClone = stream;
              hasAudio = true;
              triggerSuccessFn(audioStream, true);

            } catch (error) {
              log.error(&#x27;Failed retrieving audio stream for screensharing stream&#x27;, error);
              triggerSuccessFn(stream, true);
            }

          }, function (error) {
            log.error(&#x27;Failed retrieving audio stream for screensharing stream&#x27;, error);
            triggerSuccessFn(stream, true);
          });
        } else {
          hasAudio = window.webrtcDetectedBrowser === &#x27;firefox&#x27; ? enableAudio : false;
          triggerSuccessFn(stream, true);
        }

      }, function (error) {
        self._onUserMediaError(error, true, false);

        self._timestamp.screen = true;

        if (typeof callback === &#x27;function&#x27;) {
          callback(error, null);
        }
      });

    } catch (error) {
      self._onUserMediaError(error, true, false);

      if (typeof callback === &#x27;function&#x27;) {
        callback(error, null);
      }
    }
  };

  //self._throttle(toShareScreen,10000)();
  throttleFn(toShareScreen, 10000);
};

/**
 * Function that stops &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt;.
 * @method stopScreen
 * @example
 *   function stopScreen () {
 *     skylinkDemo.stopScreen();
 *   }
 *
 *   skylinkDemo.shareScreen();
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessStopped&quot;&gt;&lt;code&gt;mediaAccessStopped&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;If User is in the Room, &lt;a href=&quot;#event_streamEnded&quot;&gt;&lt;code&gt;streamEnded&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isSelf&lt;/code&gt; value
 *   as &lt;code&gt;true&lt;/code&gt;, and &lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;If User has &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and is in the Room,
 *   the Stream will be sent to Peers and &lt;a href=&quot;#event_incomingStream&quot;&gt;&lt;code&gt;incomingStream&lt;/code&gt; event&lt;/a&gt;
 *   triggers with parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; using the
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;.&lt;/li&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_refreshConnection&quot;&gt;&lt;code&gt;refreshConnection()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.6.0
 */
Skylink.prototype.stopScreen = function () {
  if (this._mediaScreen &amp;&amp; this._mediaScreen !== null) {
    this._stopLocalMediaStreams({
      screenshare: true
    });

    /*// for changes where the audio is not muted in here but the original mediastream has no audio
    if (!this._mediaStreamsStatus.audioMuted &amp;&amp; !this._streamSettings.audio) {
      this._mediaStreamsStatus.audioMuted = true;
    }

    // for changes where the video is not muted in here but the original mediastream has no video
    if (!this._mediaStreamsStatus.videoMuted &amp;&amp; !this._streamSettings.video) {
      this._mediaStreamsStatus.videoMuted = true;
    }*/

    if (this._inRoom) {
      if (this._hasMCU) {
        this._restartMCUConnection();
      } else {
        if (!!this._mediaStream &amp;&amp; this._mediaStream !== null) {
          this._trigger(&#x27;incomingStream&#x27;, this._user.sid, this._mediaStream, true,
            this.getPeerInfo(), false);
        }
        for (var peer in this._peerConnections) {
          if (this._peerConnections.hasOwnProperty(peer)) {
            this._restartPeerConnection(peer, true, false, null, true);
          }
        }
      }
    }
  }
};

/**
 * Function that handles the native &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API success callback result.
 * @method _onUserMediaSuccess
 * @private
 * @for Skylink
 * @since 0.3.0
 */
Skylink.prototype._onUserMediaSuccess = function(stream, isScreenSharing) {
  var self = this;
  log.log([null, &#x27;MediaStream&#x27;, stream.id,
    &#x27;User has granted access to local media&#x27;], stream);

  var streamEnded = function () {
    log.log([null, &#x27;MediaStream&#x27;, stream.id, &#x27;Local mediastream has ended&#x27;], {
      inRoom: self._inRoom,
      currentTime: stream.currentTime,
      ended: typeof stream.active === &#x27;boolean&#x27; ?
        stream.active : stream.ended
    });

    if (self._inRoom) {
      log.debug([null, &#x27;MediaStream&#x27;, stream.id, &#x27;Sending mediastream ended status&#x27;]);
      self._sendChannelMessage({
        type: self._SIG_MESSAGE_TYPE.STREAM,
        mid: self._user.sid,
        rid: self._room.id,
        cid: self._key,
        sessionType: !!isScreenSharing ? &#x27;screensharing&#x27; : &#x27;stream&#x27;,
        status: &#x27;ended&#x27;
      });
    }
    self._trigger(&#x27;streamEnded&#x27;, self._user.sid || null, self.getPeerInfo(), true, !!isScreenSharing);
  };

  // chrome uses the new specs
  if (window.webrtcDetectedBrowser === &#x27;chrome&#x27; || window.webrtcDetectedBrowser === &#x27;opera&#x27;) {
    stream.oninactive = streamEnded;
  // Workaround for local stream.onended because firefox has not yet implemented it
  } else if (window.webrtcDetectedBrowser === &#x27;firefox&#x27;) {
    stream.endedInterval = setInterval(function () {
      if (typeof stream.recordedTime === &#x27;undefined&#x27;) {
        stream.recordedTime = 0;
      }

      if (stream.recordedTime === stream.currentTime) {
        clearInterval(stream.endedInterval);
        // trigger that it has ended
        streamEnded();

      } else {
        stream.recordedTime = stream.currentTime;
      }

    }, 1000);
  } else {
    stream.onended = streamEnded;
  }

  // check if readyStateChange is done
  if (!isScreenSharing) {
    self._mediaStream = stream;
  } else {
    self._mediaScreen = stream;

    /*// for the case where local user media (audio) is not available for screensharing audio is, do not mute it
    if (!self._streamSettings.audio) {
      self._mediaStreamsStatus.audioMuted = !self._screenSharingStreamSettings.audio;
    }

    // for the case where local user media (video) is not available for screensharing video is, do not mute it
    // logically, this should always pass because screensharing will always require video
    if (!self._streamSettings.video) {
      self._mediaStreamsStatus.videoMuted = !self._screenSharingStreamSettings.video;
    }*/
  }

  self._muteLocalMediaStreams();

  self._wait(function () {
    self._trigger(&#x27;mediaAccessSuccess&#x27;, stream, !!isScreenSharing);
  }, function () {
    if (!isScreenSharing) {
      return self._mediaStream &amp;&amp; self._mediaStream !== null;
    } else {
      return self._mediaScreen &amp;&amp; self._mediaScreen !== null;
    }
  });

  /*self._condition(&#x27;readyStateChange&#x27;, function () {
    // check if users is in the room already
    self._condition(&#x27;peerJoined&#x27;, function () {
      self._trigger(&#x27;incomingStream&#x27;, self._user.sid, stream, true,
        self.getPeerInfo(), !!isScreenSharing);
    }, function () {
      return self._inRoom;
    }, function (peerId, peerInfo, isSelf) {
      return isSelf;
    });
  }, function () {
    return self._readyState === self.READY_STATE_CHANGE.COMPLETED;
  }, function (state) {
    return state === self.READY_STATE_CHANGE.COMPLETED;
  });*/
};

/**
 * Function that handles the native &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API failure callback result.
 * @method _onUserMediaError
 * @private
 * @for Skylink
 * @since 0.5.4
 */
Skylink.prototype._onUserMediaError = function(error, isScreenSharing, audioFallback) {
  var self = this;
  var hasAudioVideoRequest = !!self._streamSettings.video &amp;&amp; !!self._streamSettings.audio;

  if (self._audioFallback &amp;&amp; hasAudioVideoRequest &amp;&amp; audioFallback) {
    // redefined the settings for video as false
    self._streamSettings.video = false;
    self._getUserMediaSettings.video = false;

    log.debug([null, &#x27;MediaStream&#x27;, null, &#x27;Falling back to audio stream call&#x27;]);

    self._trigger(&#x27;mediaAccessFallback&#x27;, {
      error: error,
      diff: null
    }, 0, false, true);

    window.getUserMedia({
      audio: true
    }, function(stream) {
      self._onUserMediaSuccess(stream);
      self._trigger(&#x27;mediaAccessFallback&#x27;, {
        error: null,
        diff: {
          video: { expected: 1, received: stream.getVideoTracks().length },
          audio: { expected: 1, received: stream.getAudioTracks().length }
        }
      }, 1, false, true);
    }, function(error) {
      log.error([null, &#x27;MediaStream&#x27;, null,
        &#x27;Failed retrieving audio in audio fallback:&#x27;], error);
      self._trigger(&#x27;mediaAccessError&#x27;, error, !!isScreenSharing, true);
      self._trigger(&#x27;mediaAccessFallback&#x27;, {
        error: error,
        diff: null
      }, -1, false, true);
    });
  } else {
    log.error([null, &#x27;MediaStream&#x27;, null, &#x27;Failed retrieving stream:&#x27;], error);
   self._trigger(&#x27;mediaAccessError&#x27;, error, !!isScreenSharing, false);
  }
};

/**
 * Function that handles the &lt;code&gt;RTCPeerConnection.onaddstream&lt;/code&gt; remote MediaStream received.
 * @method _onRemoteStreamAdded
 * @private
 * @for Skylink
 * @since 0.5.2
 */
Skylink.prototype._onRemoteStreamAdded = function(targetMid, stream, isScreenSharing) {
  var self = this;

  if (!self._peerInformations[targetMid]) {
    log.error([targetMid, &#x27;MediaStream&#x27;, stream.id,
        &#x27;Received remote stream when peer is not connected. &#x27; +
        &#x27;Ignoring stream -&gt;&#x27;], stream);
    return;
  }

  if (!self._peerInformations[targetMid].settings.audio &amp;&amp;
    !self._peerInformations[targetMid].settings.video &amp;&amp; !isScreenSharing) {
    log.log([targetMid, &#x27;MediaStream&#x27;, stream.id,
      &#x27;Receive remote stream but ignoring stream as it is empty -&gt;&#x27;
      ], stream);
    return;
  }
  log.log([targetMid, &#x27;MediaStream&#x27;, stream.id,
    &#x27;Received remote stream -&gt;&#x27;], stream);

  if (isScreenSharing) {
    log.log([targetMid, &#x27;MediaStream&#x27;, stream.id,
      &#x27;Peer is having a screensharing session with user&#x27;]);
  }

  self._trigger(&#x27;incomingStream&#x27;, targetMid, stream,
    false, self.getPeerInfo(targetMid), !!isScreenSharing);
};

/**
 * Function that parses the &lt;code&gt;getUserMedia()&lt;/code&gt; audio settings provided.
 * This parses correctly for the native &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API audio constraints and
 *   sets any missing values to default.
 * @method _parseAudioStreamSettings
 * @private
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype._parseAudioStreamSettings = function (audioOptions) {
  audioOptions = (typeof audioOptions === &#x27;object&#x27;) ?
    audioOptions : !!audioOptions;

  var hasOptional = false;

  // Cleaning of unwanted keys
  if (audioOptions !== false) {
    audioOptions = (typeof audioOptions === &#x27;boolean&#x27;) ? {} : audioOptions;
    var tempAudioOptions = {};
    tempAudioOptions.stereo = !!audioOptions.stereo;
    tempAudioOptions.optional = [];

    if (Array.isArray(audioOptions.optional)) {
      tempAudioOptions.optional = audioOptions.optional;
      hasOptional = true;
    }

    audioOptions = tempAudioOptions;
  }

  var userMedia = (typeof audioOptions === &#x27;object&#x27;) ?
    true : audioOptions;

  if (hasOptional) {
    userMedia = {
      optional: audioOptions.optional
    };
  }

  return {
    settings: audioOptions,
    userMedia: userMedia
  };
};

/**
 * Function that parses the &lt;code&gt;getUserMedia()&lt;/code&gt; video settings provided.
 * This parses correctly for the native &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API video constraints and
 *   sets any missing values to default.
 * @method _parseVideoStreamSettings
 * @private
 * @for Skylink
 * @since 0.5.8
 */
Skylink.prototype._parseVideoStreamSettings = function (videoOptions) {
  videoOptions = (typeof videoOptions === &#x27;object&#x27;) ?
    videoOptions : !!videoOptions;

  var userMedia = false;

  // Cleaning of unwanted keys
  if (videoOptions !== false) {
    videoOptions = (typeof videoOptions === &#x27;boolean&#x27;) ?
      { resolution: {} } : videoOptions;
    var tempVideoOptions = {};
    // set the resolution parsing
    videoOptions.resolution = videoOptions.resolution || {};
    tempVideoOptions.resolution = tempVideoOptions.resolution || {};
    // set resolution
    tempVideoOptions.resolution.width = videoOptions.resolution.width ||
      this._defaultStreamSettings.video.resolution.width;
    tempVideoOptions.resolution.height = videoOptions.resolution.height ||
      this._defaultStreamSettings.video.resolution.height;
    // set the framerate
    tempVideoOptions.frameRate = videoOptions.frameRate ||
      this._defaultStreamSettings.video.frameRate;
    // set the screenshare option
    tempVideoOptions.screenshare = false;

    tempVideoOptions.optional = [];

    if (Array.isArray(videoOptions.optional)) {
      tempVideoOptions.optional = videoOptions.optional;
    }

    videoOptions = tempVideoOptions;

    userMedia = {
      mandatory: {
        //minWidth: videoOptions.resolution.width,
        //minHeight: videoOptions.resolution.height,
        maxWidth: videoOptions.resolution.width,
        maxHeight: videoOptions.resolution.height,
        //minFrameRate: videoOptions.frameRate,
        maxFrameRate: videoOptions.frameRate
      },
      optional: tempVideoOptions.optional
    };

    //Remove maxFrameRate for AdapterJS to work with Safari
    if (window.webrtcDetectedType === &#x27;plugin&#x27;) {
      delete userMedia.mandatory.maxFrameRate;
    }

    // Check if screensharing is available and enabled
    /*if (this._screenSharingAvailable &amp;&amp; videoOptions.screenshare) {
      userMedia.optional.push({ sourceId: AdapterJS.WebRTCPlugin.plugin.screensharingKey });
    }*/

    //For Edge
    if (window.webrtcDetectedBrowser === &#x27;edge&#x27;) {
      userMedia = true;
    }
  }

  return {
    settings: videoOptions,
    userMedia: userMedia
  };
};

/**
 * Function that parses the &lt;code&gt;joinRoom()&lt;/code&gt; bandwidth settings provided.
 * This parses and sets any missing values to default.
 * @method _parseBandwidthSettings
 * @private
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype._parseBandwidthSettings = function (bwOptions) {
  this._streamSettings.bandwidth = {};

  bwOptions = (typeof bwOptions === &#x27;object&#x27;) ?
    bwOptions : {};

  // Configure the audio bandwidth. Recommended = 50
  if (typeof bwOptions.audio === &#x27;number&#x27;) {
    this._streamSettings.bandwidth.audio = bwOptions.audio;
  }

  // Configure the video bandwidth. Recommended = 256
  if (typeof bwOptions.video === &#x27;number&#x27;) {
    this._streamSettings.bandwidth.video = bwOptions.video;
  }

  // Configure the data bandwidth. Recommended = 1638400
  if (typeof bwOptions.data === &#x27;number&#x27;) {
    this._streamSettings.bandwidth.data = bwOptions.data;
  }
};

/**
 * Function that parses the &lt;code&gt;getUserMedia()&lt;/code&gt; audio/video mute settings provided.
 * This parses and sets any missing values to default.
 * @method _parseMutedSettings
 * @private
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype._parseMutedSettings = function (options) {
  // the stream options
  options = (typeof options === &#x27;object&#x27;) ?
    options : { audio: false, video: false };

  var updateAudioMuted = (typeof options.audio === &#x27;object&#x27;) ?
    !!options.audio.mute : false;//!options.audio;
  var updateVideoMuted = (typeof options.video === &#x27;object&#x27;) ?
    !!options.video.mute : false;//!options.video;

  return {
    audioMuted: updateAudioMuted,
    videoMuted: updateVideoMuted
  };
};

/**
 * Function that parses the &lt;code&gt;getUserMedia()&lt;/code&gt; default settings received from the API result.
 * @method _parseDefaultMediaStreamSettings
 * @private
 * @for Skylink
 * @since 0.5.7
 */
Skylink.prototype._parseDefaultMediaStreamSettings = function(options) {
  var hasMediaChanged = false;

  // prevent undefined error
  options = options || {};

  log.debug(&#x27;Parsing stream settings. Default stream options:&#x27;, options);

  options.maxWidth = (typeof options.maxWidth === &#x27;number&#x27;) ? options.maxWidth :
    640;
  options.maxHeight = (typeof options.maxHeight === &#x27;number&#x27;) ? options.maxHeight :
    480;

  // parse video resolution. that&#x27;s for now
  this._defaultStreamSettings.video.resolution.width = options.maxWidth;
  this._defaultStreamSettings.video.resolution.height = options.maxHeight;

  log.debug(&#x27;Parsed default media stream settings&#x27;, this._defaultStreamSettings);
};

/**
 * Function that parses the &lt;code&gt;getUserMedia()&lt;/code&gt; settings provided.
 * @method _parseMediaStreamSettings
 * @private
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._parseMediaStreamSettings = function(options) {
  var hasMediaChanged = false;

  options = options || {};

  log.debug(&#x27;Parsing stream settings. Stream options:&#x27;, options);

  // Set audio settings
  var audioSettings = this._parseAudioStreamSettings(options.audio);
  // check for change
  this._streamSettings.audio = audioSettings.settings;
  this._getUserMediaSettings.audio = audioSettings.userMedia;

  // Set video settings
  var videoSettings = this._parseVideoStreamSettings(options.video);
  // check for change
  this._streamSettings.video = videoSettings.settings;
  this._getUserMediaSettings.video = videoSettings.userMedia;

  // Set user media status options
  var mutedSettings = this._parseMutedSettings(options);

  this._mediaStreamsStatus = mutedSettings;

  log.debug(&#x27;Parsed user media stream settings&#x27;, this._streamSettings);

  log.debug(&#x27;User media status:&#x27;, this._mediaStreamsStatus);
};

/**
 * Function that sets User&#x27;s Stream to send to Peer connection.
 * Priority for &lt;code&gt;shareScreen()&lt;/code&gt; Stream over &lt;code&gt;getUserMedia()&lt;/code&gt; Stream.
 * @method _addLocalMediaStreams
 * @private
 * @for Skylink
 * @since 0.5.2
 */
Skylink.prototype._addLocalMediaStreams = function(peerId) {
  // NOTE ALEX: here we could do something smarter
  // a mediastream is mainly a container, most of the info
  // are attached to the tracks. We should iterates over track and print
  try {
    log.log([peerId, null, null, &#x27;Adding local stream&#x27;]);

    var pc = this._peerConnections[peerId];

    if (pc) {
      if (pc.signalingState !== this.PEER_CONNECTION_STATE.CLOSED) {
        // Updates the streams accordingly
        var updateStreamFn = function (updatedStream) {
          var hasStream = false;

          // remove streams
          var streams = pc.getLocalStreams();
          for (var i = 0; i &lt; streams.length; i++) {
            if (updatedStream !== null &amp;&amp; streams[i].id === updatedStream.id) {
              hasStream = true;
              continue;
            }
            // try removeStream
            pc.removeStream(streams[i]);
          }

          if (updatedStream !== null &amp;&amp; !hasStream) {
            pc.addStream(updatedStream);
          }
        };

        if (this._mediaScreen &amp;&amp; this._mediaScreen !== null) {
          log.debug([peerId, &#x27;MediaStream&#x27;, null, &#x27;Sending screen&#x27;], this._mediaScreen);

          updateStreamFn(this._mediaScreen);

        } else if (this._mediaStream &amp;&amp; this._mediaStream !== null) {
          log.debug([peerId, &#x27;MediaStream&#x27;, null, &#x27;Sending stream&#x27;], this._mediaStream);

          updateStreamFn(this._mediaStream);

        } else {
          log.warn([peerId, &#x27;MediaStream&#x27;, null, &#x27;No media to send. Will be only receiving&#x27;]);

          updateStreamFn(null);
        }

      } else {
        log.warn([peerId, &#x27;MediaStream&#x27;, null,
          &#x27;Not adding any stream as signalingState is closed&#x27;]);
      }
    } else {
      log.warn([peerId, &#x27;MediaStream&#x27;, this._mediaStream,
        &#x27;Not adding stream as peerconnection object does not exists&#x27;]);
    }
  } catch (error) {
    if ((error.message || &#x27;&#x27;).indexOf(&#x27;already added&#x27;) &gt; -1) {
      log.warn([peerId, null, null, &#x27;Not re-adding stream as LocalMediaStream is already added&#x27;], error);
    } else {
      // Fix errors thrown like NS_ERROR_UNEXPECTED
      log.error([peerId, null, null, &#x27;Failed adding local stream&#x27;], error);
    }
  }
};

/**
 * Function that handles the muting of Stream audio and video tracks.
 * @method _muteLocalMediaStreams
 * @private
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._muteLocalMediaStreams = function () {
  var hasAudioTracks = false;
  var hasVideoTracks = false;

  var audioTracks;
  var videoTracks;
  var a, v;

  // Loop and enable tracks accordingly (mediaStream)
  if (this._mediaStream &amp;&amp; this._mediaStream !== null) {
    audioTracks = this._mediaStream.getAudioTracks();
    videoTracks = this._mediaStream.getVideoTracks();

    hasAudioTracks = audioTracks.length &gt; 0 || hasAudioTracks;
    hasVideoTracks = videoTracks.length &gt; 0 || hasVideoTracks;

    // loop audio tracks
    for (a = 0; a &lt; audioTracks.length; a++) {
      if (this._mediaStreamsStatus.audioMuted) {
        audioTracks[a].enabled = false;
      } else {
        audioTracks[a].enabled = true;
      }
    }
    // loop video tracks
    for (v = 0; v &lt; videoTracks.length; v++) {
      if (this._mediaStreamsStatus.videoMuted) {
        videoTracks[v].enabled = false;
      } else {
        videoTracks[v].enabled = true;
      }
    }
  }

  // Loop and enable tracks accordingly (mediaScreen)
  if (this._mediaScreen &amp;&amp; this._mediaScreen !== null) {
    audioTracks = this._mediaScreen.getAudioTracks();
    videoTracks = this._mediaScreen.getVideoTracks();

    hasAudioTracks = hasAudioTracks || audioTracks.length &gt; 0;
    hasVideoTracks = hasVideoTracks || videoTracks.length &gt; 0;

    // loop audio tracks
    for (a = 0; a &lt; audioTracks.length; a++) {
      if (this._mediaStreamsStatus.audioMuted) {
        audioTracks[a].enabled = false;
      } else {
        audioTracks[a].enabled = true;
      }
    }
    // loop video tracks
    for (v = 0; v &lt; videoTracks.length; v++) {
      if (this._mediaStreamsStatus.videoMuted) {
        videoTracks[v].enabled = false;
      } else {
        videoTracks[v].enabled = true;
      }
    }
  }

  // Loop and enable tracks accordingly (mediaScreenClone)
  if (this._mediaScreenClone &amp;&amp; this._mediaScreenClone !== null) {
    videoTracks = this._mediaScreen.getVideoTracks();

    hasVideoTracks = hasVideoTracks || videoTracks.length &gt; 0;

    // loop video tracks
    for (v = 0; v &lt; videoTracks.length; v++) {
      if (this._mediaStreamsStatus.videoMuted) {
        videoTracks[v].enabled = false;
      } else {
        videoTracks[v].enabled = true;
      }
    }
  }

  // update accordingly if failed
  if (!hasAudioTracks) {
    //this._mediaStreamsStatus.audioMuted = true;
    this._streamSettings.audio = false;
  }
  if (!hasVideoTracks) {
    //this._mediaStreamsStatus.videoMuted = true;
    this._streamSettings.video = false;
  }

  log.log(&#x27;Update to muted status -&gt;&#x27;, this._mediaStreamsStatus);

  return {
    hasAudioTracks: hasAudioTracks,
    hasVideoTracks: hasVideoTracks
  };
};

/**
 * Function that handles stopping the Stream streaming.
 * @method _stopLocalMediaStreams
 * @private
 * @for Skylink
 * @since 0.6.3
 */
Skylink.prototype._stopLocalMediaStreams = function (options) {
  var self = this;
  var stopUserMedia = false;
  var stopScreenshare = false;
  var triggerStopped = false;

  if (typeof options === &#x27;object&#x27;) {
    stopUserMedia = options.userMedia === true;
    stopScreenshare = options.screenshare === true;
  }

  var stopTracksFn = function (stream) {
    var audioTracks = stream.getAudioTracks();
    var videoTracks = stream.getVideoTracks();

    for (var i = 0; i &lt; audioTracks.length; i++) {
      audioTracks[i].stop();
    }

    for (var j = 0; j &lt; videoTracks.length; j++) {
      videoTracks[j].stop();
    }
  };

  var stopFn = function (stream, name) {
    //if (window.webrtcDetectedBrowser === &#x27;chrome&#x27; &amp;&amp; window.webrtcDetectedVersion &gt; 44) {
    // chrome/opera/firefox uses mediastreamtrack.stop()
    if ([&#x27;chrome&#x27;, &#x27;opera&#x27;, &#x27;firefox&#x27;].indexOf(window.webrtcDetectedBrowser) &gt; -1) {
      stopTracksFn(stream);
    } else {
      try {
        stream.stop();
      } catch (error) {
        log.warn(&#x27;Failed stopping MediaStreamTracks for &#x27; + name + &#x27;.&#x27; +
          &#x27; Stopping MediaStream instead&#x27;, error);
        stopTracksFn(stream);
      }
    }
  };

  if (stopScreenshare) {
    log.log([null, &#x27;MediaStream&#x27;, self._selectedRoom, &#x27;Stopping screensharing MediaStream&#x27;]);

    if (this._mediaScreen &amp;&amp; this._mediaScreen !== null) {
      stopFn(this._mediaScreen, &#x27;_mediaScreen&#x27;);
      this._mediaScreen = null;
      triggerStopped = true;
    }

    if (this._mediaScreenClone &amp;&amp; this._mediaScreenClone !== null) {
      stopFn(this._mediaScreenClone, &#x27;_mediaScreenClone&#x27;);
      this._mediaScreenClone = null;
    }

    if (triggerStopped) {
      this._screenSharingStreamSettings.audio = false;
      this._screenSharingStreamSettings.video = false;
      this._trigger(&#x27;mediaAccessStopped&#x27;, true);
    }

  } else {
    log.log([null, &#x27;MediaStream&#x27;, self._selectedRoom, &#x27;Screensharing MediaStream will not be stopped&#x27;]);
  }

  if (stopUserMedia) {
    log.log([null, &#x27;MediaStream&#x27;, self._selectedRoom, &#x27;Stopping user\&#x27;s MediaStream&#x27;]);

    if (this._mediaStream &amp;&amp; this._mediaStream !== null) {
      stopFn(this._mediaStream, &#x27;_mediaStream&#x27;);
      this._mediaStream = null;
      triggerStopped = true;
    }

    if (triggerStopped) {
      this._streamSettings.audio = false;
      this._streamSettings.video = false;
      this._trigger(&#x27;mediaAccessStopped&#x27;, false);
    }
  } else {
    log.log([null, &#x27;MediaStream&#x27;, self._selectedRoom, &#x27;User\&#x27;s MediaStream will not be stopped&#x27;]);
  }

  // prevent triggering when user is not in the room
  if (this._inRoom) {
    this._trigger(&#x27;peerUpdated&#x27;, this._user.sid, this.getPeerInfo(), true);
  }
};

/**
 * Function that waits for Stream to be retrieved before firing callback.
 * @method _waitForLocalMediaStream
 * @private
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype._waitForLocalMediaStream = function(callback, options) {
  var self = this;
  options = options || {};

  // get the stream
  if (options.manualGetUserMedia === true) {
    self._trigger(&#x27;mediaAccessRequired&#x27;);
  }
  // If options video or audio false, do the opposite to throw a true.
  var requireAudio = !!options.audio;
  var requireVideo = !!options.video;

  log.log(&#x27;Requested audio:&#x27;, requireAudio);
  log.log(&#x27;Requested video:&#x27;, requireVideo);

  // check if it requires audio or video
  if (!requireAudio &amp;&amp; !requireVideo &amp;&amp; !options.manualGetUserMedia) {
    // set to default
    if (options.audio === false &amp;&amp; options.video === false) {
      self._parseMediaStreamSettings(options);
    }

    callback(null);
    return;
  }

  // get the user media
  if (!options.manualGetUserMedia &amp;&amp; (options.audio || options.video)) {
    self.getUserMedia({
      audio: options.audio,
      video: options.video

    }, function (error, success) {
      if (error) {
        callback(error);
      } else {
        callback(null, success);
      }
    });
  }

  // clear previous mediastreams
  self.stopStream();

  if (options.manualGetUserMedia === true) {
    var current50Block = 0;
    var mediaAccessRequiredFailure = false;
    // wait for available audio or video stream
    self._wait(function () {
      if (mediaAccessRequiredFailure === true) {
        self._onUserMediaError(new Error(&#x27;Waiting for stream timeout&#x27;), false, false);
      } else {
        callback(null, self._mediaStream);
      }
    }, function () {
      current50Block += 1;
      if (current50Block === 600) {
        mediaAccessRequiredFailure = true;
        return true;
      }

      if (self._mediaStream &amp;&amp; self._mediaStream !== null) {
        return true;
      }
    }, 50);
  }
};
    </pre>
</div>

                  </div>
              </div>
          </div>
      </div>
  </div>
</div>
<script src="../assets/vendor/prettify/prettify-min.js"></script>
<script>prettyPrint();</script>
<script src="../assets/js/yui-prettify.js"></script>
<script src="../assets/../api.js"></script>
<script src="../assets/js/api-filter.js"></script>
<script src="../assets/js/api-list.js"></script>
<script src="../assets/js/api-search.js"></script>
<script src="../assets/js/apidocs.js"></script>
</body>
</html>
