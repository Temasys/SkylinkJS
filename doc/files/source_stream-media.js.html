<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>SkylinkJS 0.6.16</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- font and icon -->
    <link rel="shortcut icon" type="image/ico" href="../assets/favicon.ico">
    <link rel="stylesheet" href="../assets/vendor/prettify/prettify-min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600,700|Source+Sans+Pro" type="text/css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600,700|Source+Code+Pro" type="text/css">
    <!-- styling -->
    <link rel="stylesheet" href="../assets/vendor/css/bootstrap.min.css">
    <link rel="stylesheet" href="../assets/vendor/css/bootstrap-theme.min.css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="../assets/css/style.css">
    <!-- scripts -->
    <script src="../assets/vendor/js/jquery.min.js"></script>
    <script src="../assets/vendor/js/bootstrap.min.js"></script>
    <script src="../assets/js/script.js"></script>
    <script src="http://yui.yahooapis.com/combo?3.9.1/build/yui/yui-min.js"></script>
</head>
<body>

<div id="doc">
  <nav id="hd" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a href="" class="navbar-brand">
          <img src="../assets/img/logo.svg" />JS<small>Version: 0.6.16</small>
        </a>
      </div>
      <div id="navbar" class="navbar-collapse collapse">
        <ul id="api-list" class="nav navbar-nav navbar-right">
  <li class="dropdown">
    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Getting Started Examples <span class="caret"></span></a>
    <ul class="dropdown-menu" role="menu">
      <li><a href="https://temasys.com.sg/getting-started-with-webrtc-and-skylinkjs/">Setting up a Video Call</a></li>
      <li><a href="https://temasys.com.sg/screensharing-with-skylinkjs/">Setting up Screensharing</a></li>
      <li><a href="https://temasys.com.sg/building-a-simple-peer-to-peer-webrtc-chat/">Setting up a Chatroom</a></li>
    </ul>
  </li>
  
    <li><a href="../classes/Skylink.html">Documentation</a></li>
  
  <!--<li class="dropdown">
    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Classes <span class="caret"></span></a>
    <ul class="dropdown-menu" role="menu">
      
        <li><a href="../classes/Skylink.html">Skylink</a></li>
      
    </ul>
  </li>-->
  <li><a class="btn btn-info btn-navbar" href="http://developer.temasys.com.sg/">Developer Console</a></li>
  <li><a class="btn btn-info btn-navbar" href="http://support.temasys.com.sg/">Support</a></li>
  <!--<li class="dropdown">
    <a href="#" class="dropdown-toggle" data-toggle="dropdown">Modules <span class="caret"></span></a>
    <ul class="dropdown-menu" role="menu">
      <li><a href="#api-modules">View all Modules</a></li>
      
    </ul>
  </li>-->
</ul>
<!--<form id="api-tabview" class="navbar-form navbar-right" role="form">
  <div id="api-tabview-filter" class="form-group">
    <input type="search" id="api-filter" placeholder="Type to filter APIs">
  </div>
</form>-->
      </div><!--/.navbar-collapse -->
    </div>
  </nav>
  <div id="bd" class="yui3-g">

      <div class="yui3-u-1-4">

      </div>
      <div class="yui3-u-3-4">
          
          <div class="apidocs">
              <div id="docs-main">
                  <div class="content content-main">
                      <h1 class="file-heading">File: source/stream-media.js</h1>

<div class="file">
    <pre class="code prettyprint linenums">
/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that if the video codec is not supported, the SDK will not configure the local &lt;code&gt;&quot;offer&quot;&lt;/code&gt; or
 *   &lt;code&gt;&quot;answer&quot;&lt;/code&gt; session description to prefer the codec.
 * &lt;/blockquote&gt;
 * The list of available video codecs to set as the preferred video codec to use to encode
 * sending video data when available encoded video codec for Peer connections
 * configured in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.
 * @attribute VIDEO_CODEC
 * @param {String} AUTO &lt;small&gt;Value &lt;code&gt;&quot;auto&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to not prefer any video codec but rather use the created
 *   local &lt;code&gt;&quot;offer&quot;&lt;/code&gt; / &lt;code&gt;&quot;answer&quot;&lt;/code&gt; session description video codec preference.
 * @param {String} VP8  &lt;small&gt;Value &lt;code&gt;&quot;VP8&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/VP8&quot;&gt;VP8&lt;/a&gt; video codec.
 * @param {String} VP9  &lt;small&gt;Value &lt;code&gt;&quot;VP9&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/VP9&quot;&gt;VP9&lt;/a&gt; video codec.
 * @param {String} H264 &lt;small&gt;Value &lt;code&gt;&quot;H264&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/H.264/MPEG-4_AVC&quot;&gt;H264&lt;/a&gt; video codec.
 * @type JSON
 * @readOnly
 * @for Skylink
 * @since 0.5.10
 */
Skylink.prototype.VIDEO_CODEC = {
  AUTO: &#x27;auto&#x27;,
  VP8: &#x27;VP8&#x27;,
  H264: &#x27;H264&#x27;,
  VP9: &#x27;VP9&#x27;
  //H264UC: &#x27;H264UC&#x27;
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that if the audio codec is not supported, the SDK will not configure the local &lt;code&gt;&quot;offer&quot;&lt;/code&gt; or
 *   &lt;code&gt;&quot;answer&quot;&lt;/code&gt; session description to prefer the codec.
 * &lt;/blockquote&gt;
 * The list of available audio codecs to set as the preferred audio codec to use to encode
 * sending audio data when available encoded audio codec for Peer connections
 * configured in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.
 * @attribute AUDIO_CODEC
 * @param {String} AUTO &lt;small&gt;Value &lt;code&gt;&quot;auto&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to not prefer any audio codec but rather use the created
 *   local &lt;code&gt;&quot;offer&quot;&lt;/code&gt; / &lt;code&gt;&quot;answer&quot;&lt;/code&gt; session description audio codec preference.
 * @param {String} OPUS &lt;small&gt;Value &lt;code&gt;&quot;opus&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/Opus_(audio_format)&quot;&gt;OPUS&lt;/a&gt; audio codec.
 * @param {String} ISAC &lt;small&gt;Value &lt;code&gt;&quot;ISAC&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/Internet_Speech_Audio_Codec&quot;&gt;ISAC&lt;/a&gt; audio codec.
 * @param {String} G722 &lt;small&gt;Value &lt;code&gt;&quot;G722&quot;&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to prefer the &lt;a href=&quot;https://en.wikipedia.org/wiki/G.722&quot;&gt;G722&lt;/a&gt; audio codec.
 * @type JSON
 * @readOnly
 * @for Skylink
 * @since 0.5.10
 */
Skylink.prototype.AUDIO_CODEC = {
  AUTO: &#x27;auto&#x27;,
  ISAC: &#x27;ISAC&#x27;,
  OPUS: &#x27;opus&#x27;,
  //ILBC: &#x27;ILBC&#x27;,
  //G711: &#x27;G711&#x27;,
  G722: &#x27;G722&#x27;
  //SILK: &#x27;SILK&#x27;
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that currently &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt; only configures
 *   the maximum resolution of the Stream due to browser interopability and support.
 * &lt;/blockquote&gt;
 * The list of &lt;a href=&quot;https://en.wikipedia.org/wiki/Graphics_display_resolution#Video_Graphics_Array&quot;&gt;
 * video resolutions&lt;/a&gt; sets configured in the &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;.
 * @attribute VIDEO_RESOLUTION
 * @param {JSON} QQVGA &lt;small&gt;Value &lt;code&gt;{ width: 160, height: 120 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure QQVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} HQVGA &lt;small&gt;Value &lt;code&gt;{ width: 240, height: 160 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure HQVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;3:2&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} QVGA &lt;small&gt;Value &lt;code&gt;{ width: 320, height: 240 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure QVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 * @param {JSON} WQVGA &lt;small&gt;Value &lt;code&gt;{ width: 384, height: 240 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure WQVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:10&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} HVGA &lt;small&gt;Value &lt;code&gt;{ width: 480, height: 320 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure HVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;3:2&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} VGA &lt;small&gt;Value &lt;code&gt;{ width: 640, height: 480 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure VGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 * @param {JSON} WVGA &lt;small&gt;Value &lt;code&gt;{ width: 768, height: 480 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure WVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:10&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} FWVGA &lt;small&gt;Value &lt;code&gt;{ width: 854, height: 480 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure FWVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} SVGA &lt;small&gt;Value &lt;code&gt;{ width: 800, height: 600 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure SVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;4:3&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} DVGA &lt;small&gt;Value &lt;code&gt;{ width: 960, height: 640 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure DVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;3:2&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} WSVGA &lt;small&gt;Value &lt;code&gt;{ width: 1024, height: 576 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure WSVGA resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 * @param {JSON} HD &lt;small&gt;Value &lt;code&gt;{ width: 1280, height: 720 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure HD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on device supports.&lt;/small&gt;
 * @param {JSON} HDPLUS &lt;small&gt;Value &lt;code&gt;{ width: 1600, height: 900 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure HDPLUS resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} FHD &lt;small&gt;Value &lt;code&gt;{ width: 1920, height: 1080 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure FHD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on device supports.&lt;/small&gt;
 * @param {JSON} QHD &lt;small&gt;Value &lt;code&gt;{ width: 2560, height: 1440 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure QHD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} WQXGAPLUS &lt;small&gt;Value &lt;code&gt;{ width: 3200, height: 1800 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure WQXGAPLUS resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} UHD &lt;small&gt;Value &lt;code&gt;{ width: 3840, height: 2160 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure UHD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} UHDPLUS &lt;small&gt;Value &lt;code&gt;{ width: 5120, height: 2880 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure UHDPLUS resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} FUHD &lt;small&gt;Value &lt;code&gt;{ width: 7680, height: 4320 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure FUHD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @param {JSON} QUHD &lt;small&gt;Value &lt;code&gt;{ width: 15360, height: 8640 }&lt;/code&gt;&lt;/small&gt;
 *   The value of the option to configure QUHD resolution.
 *   &lt;small&gt;Aspect ratio: &lt;code&gt;16:9&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Note that configurating this resolution may not be supported depending on browser and device supports.&lt;/small&gt;
 * @type JSON
 * @readOnly
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype.VIDEO_RESOLUTION = {
  QQVGA: { width: 160, height: 120 /*, aspectRatio: &#x27;4:3&#x27;*/ },
  HQVGA: { width: 240, height: 160 /*, aspectRatio: &#x27;3:2&#x27;*/ },
  QVGA: { width: 320, height: 240 /*, aspectRatio: &#x27;4:3&#x27;*/ },
  WQVGA: { width: 384, height: 240 /*, aspectRatio: &#x27;16:10&#x27;*/ },
  HVGA: { width: 480, height: 320 /*, aspectRatio: &#x27;3:2&#x27;*/ },
  VGA: { width: 640, height: 480 /*, aspectRatio: &#x27;4:3&#x27;*/ },
  WVGA: { width: 768, height: 480 /*, aspectRatio: &#x27;16:10&#x27;*/ },
  FWVGA: { width: 854, height: 480 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  SVGA: { width: 800, height: 600 /*, aspectRatio: &#x27;4:3&#x27;*/ },
  DVGA: { width: 960, height: 640 /*, aspectRatio: &#x27;3:2&#x27;*/ },
  WSVGA: { width: 1024, height: 576 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  HD: { width: 1280, height: 720 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  HDPLUS: { width: 1600, height: 900 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  FHD: { width: 1920, height: 1080 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  QHD: { width: 2560, height: 1440 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  WQXGAPLUS: { width: 3200, height: 1800 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  UHD: { width: 3840, height: 2160 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  UHDPLUS: { width: 5120, height: 2880 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  FUHD: { width: 7680, height: 4320 /*, aspectRatio: &#x27;16:9&#x27;*/ },
  QUHD: { width: 15360, height: 8640 /*, aspectRatio: &#x27;16:9&#x27;*/ }
};

/**
 * The list of &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt; or
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; method&lt;/a&gt; Stream fallback states.
 * @attribute MEDIA_ACCESS_FALLBACK_STATE
 * @param {JSON} FALLBACKING &lt;small&gt;Value &lt;code&gt;0&lt;/code&gt;&lt;/small&gt;
 *   The value of the state when &lt;code&gt;getUserMedia()&lt;/code&gt; will retrieve audio track only
 *   when retrieving audio and video tracks failed.
 *   &lt;small&gt;This can be configured by &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;
 *   &lt;code&gt;audioFallback&lt;/code&gt; option.&lt;/small&gt;
 * @param {JSON} FALLBACKED  &lt;small&gt;Value &lt;code&gt;1&lt;/code&gt;&lt;/small&gt;
 *   The value of the state when &lt;code&gt;getUserMedia()&lt;/code&gt; or &lt;code&gt;shareScreen()&lt;/code&gt;
 *   retrieves camera / screensharing Stream successfully but with missing originally required audio or video tracks.
 * @param {JSON} ERROR       &lt;small&gt;Value &lt;code&gt;-1&lt;/code&gt;&lt;/small&gt;
 *   The value of the state when &lt;code&gt;getUserMedia()&lt;/code&gt; failed to retrieve audio track only
 *   after retrieving audio and video tracks failed.
 * @readOnly
 * @for Skylink
 * @since 0.6.14
 */
Skylink.prototype.MEDIA_ACCESS_FALLBACK_STATE = {
  FALLBACKING: 0,
  FALLBACKED: 1,
  ERROR: -1
};

/**
 * The list of recording states.
 * @attribute RECORDING_STATE
 * @param {Number} START &lt;small&gt;Value &lt;code&gt;0&lt;/code&gt;&lt;/small&gt;
 *   The value of the state when recording session has started.
 * @param {Number} STOP &lt;small&gt;Value &lt;code&gt;1&lt;/code&gt;&lt;/small&gt;
 *   The value of the state when recording session has stopped.&lt;br&gt;
 *   &lt;small&gt;At this stage, the recorded videos will go through the mixin server to compile the videos.&lt;/small&gt;
 * @param {Number} LINK &lt;small&gt;Value &lt;code&gt;2&lt;/code&gt;&lt;/small&gt;
 *   The value of the state when recording session mixin request has been completed.
 * @param {Number} ERROR &lt;small&gt;Value &lt;code&gt;-1&lt;/code&gt;&lt;/small&gt;
 *   The value of the state state when recording session has errors.
 *   &lt;small&gt;This can happen during recording session or during mixin of recording videos,
 *   and at this stage, any current recording session or mixin is aborted.&lt;/small&gt;
 * @type JSON
 * @beta
 * @for Skylink
 * @since 0.6.16
 */
Skylink.prototype.RECORDING_STATE = {
  START: 0,
  STOP: 1,
  LINK: 2,
  ERROR: -1
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   For a better user experience, the functionality is throttled when invoked many times in less
 *   than the milliseconds interval configured in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.
 * &lt;/blockquote&gt;
 * Function that retrieves camera Stream.
 * @method getUserMedia
 * @param {JSON} [options] The camera Stream configuration options.
 * - When not provided, the value is set to &lt;code&gt;{ audio: true, video: true }&lt;/code&gt;.
 *   &lt;small&gt;To fallback to retrieve audio track only when retrieving of audio and video tracks failed,
 *   enable the &lt;code&gt;audioFallback&lt;/code&gt; flag in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;
 * @param {Boolean} [options.useExactConstraints=false] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that by enabling this flag, exact values will be requested when retrieving camera Stream,
 *   but it does not prevent constraints related errors. By default when not enabled,
 *   expected mandatory maximum values (or optional values for source ID) will requested to prevent constraints related
 *   errors, with an exception for &lt;code&gt;options.video.frameRate&lt;/code&gt; option in Safari and IE (any plugin-enabled) browsers,
 *   where the expected maximum value will not be requested due to the lack of support.&lt;/blockquote&gt;
 *   The flag if &lt;code&gt;getUserMedia()&lt;/code&gt; should request for camera Stream to match exact requested values of
 *   &lt;code&gt;options.audio.deviceId&lt;/code&gt; and &lt;code&gt;options.video.deviceId&lt;/code&gt;, &lt;code&gt;options.video.resolution&lt;/code&gt;
 *   and &lt;code&gt;options.video.frameRate&lt;/code&gt; when provided.
 * @param {Boolean|JSON} [options.audio=false] The audio configuration options.
 * @param {Boolean} [options.audio.stereo=false] The flag if stereo band should be configured
 *   when encoding audio codec is &lt;a href=&quot;#attr_AUDIO_CODEC&quot;&gt;&lt;code&gt;OPUS&lt;/code&gt;&lt;/a&gt; for sending / receiving audio data.
 *   &lt;small&gt;Note that Peers may override the &quot;receiving&quot; &lt;code&gt;stereo&lt;/code&gt; config depending on the Peers configuration.&lt;/small&gt;
 * @param {Boolean} [options.audio.usedtx] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that this feature might not work depending on the browser support and implementation.&lt;/blockquote&gt;
 *   The flag if DTX (Discontinuous Transmission) should be configured when encoding audio codec
 *   is &lt;a href=&quot;#attr_AUDIO_CODEC&quot;&gt;&lt;code&gt;OPUS&lt;/code&gt;&lt;/a&gt; for sending / receiving audio data.
 *   &lt;small&gt;This might help to reduce bandwidth it reduces the bitrate during silence or background noise.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 *   &lt;small&gt;Note that Peers may override the &quot;receiving&quot; &lt;code&gt;usedtx&lt;/code&gt; config depending on the Peers configuration.&lt;/small&gt;
 * @param {Boolean} [options.audio.useinbandfec] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that this feature might not work depending on the browser support and implementation.&lt;/blockquote&gt;
 *   The flag if capability to take advantage of in-band FEC (Forward Error Correction) should be
 *   configured when encoding audio codec is &lt;a href=&quot;#attr_AUDIO_CODEC&quot;&gt;&lt;code&gt;OPUS&lt;/code&gt;&lt;/a&gt; for sending / receiving audio data.
 *   &lt;small&gt;This might help to reduce the harm of packet loss by encoding information about the previous packet.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 *   &lt;small&gt;Note that Peers may override the &quot;receiving&quot; &lt;code&gt;useinbandfec&lt;/code&gt; config depending on the Peers configuration.&lt;/small&gt;
 * @param {Number} [options.audio.maxplaybackrate] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that this feature might not work depending on the browser support and implementation.&lt;/blockquote&gt;
 *   The maximum output sampling rate rendered in Hertz (Hz) when encoding audio codec is
 *   &lt;a href=&quot;#attr_AUDIO_CODEC&quot;&gt;&lt;code&gt;OPUS&lt;/code&gt;&lt;/a&gt; for sending / receiving audio data.
 *   &lt;small&gt;This value must be between &lt;code&gt;8000&lt;/code&gt; to &lt;code&gt;48000&lt;/code&gt;.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 *   &lt;small&gt;Note that Peers may override the &quot;receiving&quot; &lt;code&gt;maxplaybackrate&lt;/code&gt; config depending on the Peers configuration.&lt;/small&gt;
 * @param {Boolean} [options.audio.mute=false] The flag if audio tracks should be muted upon receiving them.
 *   &lt;small&gt;Providing the value as &lt;code&gt;false&lt;/code&gt; does nothing to &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt;,
 *   but when provided as &lt;code&gt;true&lt;/code&gt;, this sets the &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt; value to
 *   &lt;code&gt;true&lt;/code&gt; and mutes any existing &lt;a href=&quot;#method_shareScreen&quot;&gt;
 *   &lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; audio tracks as well.&lt;/small&gt;
 * @param {Array} [options.audio.optional] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that this may result in constraints related error when &lt;code&gt;options.useExactConstraints&lt;/code&gt; value is
 *   &lt;code&gt;true&lt;/code&gt;. If you are looking to set the requested source ID of the audio track,
 *   use &lt;code&gt;options.audio.deviceId&lt;/code&gt; instead.&lt;/blockquote&gt;
 *   The &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API &lt;code&gt;audio: { optional [..] }&lt;/code&gt; property.
 * @param {String} [options.audio.deviceId] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note this is currently not supported in Firefox browsers.
 *   &lt;/blockquote&gt; The audio track source ID of the device to use.
 *   &lt;small&gt;The list of available audio source ID can be retrieved by the &lt;a href=&quot;https://developer.
 * mozilla.org/en-US/docs/Web/API/MediaDevices/enumerateDevices&quot;&gt;&lt;code&gt;navigator.mediaDevices.enumerateDevices&lt;/code&gt;
 *   API&lt;/a&gt;.&lt;/small&gt;
 * @param {Boolean} [options.audio.echoCancellation=false] The flag to enable audio tracks echo cancellation.
 * @param {Boolean|JSON} [options.video=false] The video configuration options.
 * @param {Boolean} [options.video.mute=false] The flag if video tracks should be muted upon receiving them.
 *   &lt;small&gt;Providing the value as &lt;code&gt;false&lt;/code&gt; does nothing to &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt;,
 *   but when provided as &lt;code&gt;true&lt;/code&gt;, this sets the &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt; value to
 *   &lt;code&gt;true&lt;/code&gt; and mutes any existing &lt;a href=&quot;#method_shareScreen&quot;&gt;
 *   &lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; video tracks as well.&lt;/small&gt;
 * @param {JSON} [options.video.resolution] The video resolution.
 *   &lt;small&gt;By default, &lt;a href=&quot;#attr_VIDEO_RESOLUTION&quot;&gt;&lt;code&gt;VGA&lt;/code&gt;&lt;/a&gt; resolution option
 *   is selected when not provided.&lt;/small&gt;
 *   [Rel: Skylink.VIDEO_RESOLUTION]
 * @param {Number|JSON} [options.video.resolution.width] The video resolution width.
 * - When provided as a number, it is the video resolution width.
 * - When provided as a JSON, it is the &lt;code&gt;navigator.mediaDevices.getUserMedia()&lt;/code&gt; &lt;code&gt;.width&lt;/code&gt; settings.
 *   Parameters are &lt;code&gt;&quot;ideal&quot;&lt;/code&gt; for ideal resolution width, &lt;code&gt;&quot;exact&quot;&lt;/code&gt; for exact video resolution width,
 *   &lt;code&gt;&quot;min&quot;&lt;/code&gt; for min video resolution width and &lt;code&gt;&quot;max&quot;&lt;/code&gt; for max video resolution width.
 *   Note that this may result in constraints related errors depending on the browser/hardware supports.
 * @param {Number|JSON} [options.video.resolution.height] The video resolution height.
 * - When provided as a number, it is the video resolution height.
 * - When provided as a JSON, it is the &lt;code&gt;navigator.mediaDevices.getUserMedia()&lt;/code&gt; &lt;code&gt;.height&lt;/code&gt; settings.
 *   Parameters are &lt;code&gt;&quot;ideal&quot;&lt;/code&gt; for ideal video resolution height, &lt;code&gt;&quot;exact&quot;&lt;/code&gt; for exact video resolution height,
 *   &lt;code&gt;&quot;min&quot;&lt;/code&gt; for min video resolution height and &lt;code&gt;&quot;max&quot;&lt;/code&gt; for max video resolution height.
 *   Note that this may result in constraints related errors depending on the browser/hardware supports.
 * @param {Number|JSON} [options.video.frameRate] The video &lt;a href=&quot;https://en.wikipedia.org/wiki/Frame_rate&quot;&gt;
 *   frameRate&lt;/a&gt; per second (fps).
 * - When provided as a number, it is the video framerate.
 * - When provided as a JSON, it is the &lt;code&gt;navigator.mediaDevices.getUserMedia()&lt;/code&gt; &lt;code&gt;.frameRate&lt;/code&gt; settings.
 *   Parameters are &lt;code&gt;&quot;ideal&quot;&lt;/code&gt; for ideal video framerate, &lt;code&gt;&quot;exact&quot;&lt;/code&gt; for exact video framerate,
 *   &lt;code&gt;&quot;min&quot;&lt;/code&gt; for min video framerate and &lt;code&gt;&quot;max&quot;&lt;/code&gt; for max video framerate.
 *   Note that this may result in constraints related errors depending on the browser/hardware supports.
 * @param {Array} [options.video.optional] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that this may result in constraints related error when &lt;code&gt;options.useExactConstraints&lt;/code&gt; value is
 *   &lt;code&gt;true&lt;/code&gt;. If you are looking to set the requested source ID of the video track,
 *   use &lt;code&gt;options.video.deviceId&lt;/code&gt; instead.&lt;/blockquote&gt;
 *   The &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API &lt;code&gt;video: { optional [..] }&lt;/code&gt; property.
 * @param {String} [options.video.deviceId] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note this is currently not supported in Firefox browsers.
 *   &lt;/blockquote&gt; The video track source ID of the device to use.
 *   &lt;small&gt;The list of available video source ID can be retrieved by the &lt;a href=&quot;https://developer.
 * mozilla.org/en-US/docs/Web/API/MediaDevices/enumerateDevices&quot;&gt;&lt;code&gt;navigator.mediaDevices.enumerateDevices&lt;/code&gt;
 *   API&lt;/a&gt;.&lt;/small&gt;
 * @param {Function} [callback] The callback function fired when request has completed.
 *   &lt;small&gt;Function parameters signature is &lt;code&gt;function (error, success)&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Function request completion is determined by the &lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggering &lt;code&gt;isScreensharing&lt;/code&gt; parameter
 *   payload value as &lt;code&gt;false&lt;/code&gt; for request success.&lt;/small&gt;
 * @param {Error|String} callback.error The error result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are no errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;code&gt;getUserMedia()&lt;/code&gt; error when retrieving camera Stream.&lt;/small&gt;
 * @param {MediaStream} callback.success The success result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the camera Stream object.&lt;/small&gt;
 * @example
 *   // Example 1: Get both audio and video.
 *   skylinkDemo.getUserMedia(function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *   });
 *
 *   // Example 2: Get only audio.
 *   skylinkDemo.getUserMedia({
 *     audio: true
 *   }, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-audio&quot;), success);
 *   });
 *
 *   // Example 3: Configure resolution for video
 *   skylinkDemo.getUserMedia({
 *     audio: true,
 *     video: {
 *       resolution: skylinkDemo.VIDEO_RESOLUTION.HD
 *     }
 *   }, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *   });
 *
 *   // Example 4: Configure stereo flag for OPUS codec audio (OPUS is always used by default)
 *   skylinkDemo.init({
 *     appKey: &quot;xxxxxx&quot;,
 *     audioCodec: skylinkDemo.AUDIO_CODEC.OPUS
 *   }, function (initErr, initSuccess) {
 *     skylinkDemo.getUserMedia({
 *       audio: {
 *         stereo: true
 *       },
 *       video: true
 *     }, function (error, success) {
 *       if (error) return;
 *       attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *     });
 *   });
 *
 *   // Example 5: Configure frameRate for video
 *   skylinkDemo.getUserMedia({
 *     audio: true,
 *     video: {
 *       frameRate: 50
 *     }
 *   }, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *   });
 *
 *   // Example 6: Configure video and audio based on selected sources. Does not work for Firefox currently.
 *   var sources = { audio: [], video: [] };
 *
 *   function selectStream (audioSourceId, videoSourceId) {
 *     if (window.webrtcDetectedBrowser === &#x27;firefox&#x27;) {
 *       console.warn(&quot;Currently this feature is not supported by Firefox browsers!&quot;);
 *       return;
 *     }
 *     skylinkDemo.getUserMedia({
 *       audio: {
 *         optional: [{ sourceId: audioSourceId }]
 *       },
 *       video: {
 *         optional: [{ sourceId: videoSourceId }]
 *       }
 *     }, function (error, success) {
 *       if (error) return;
 *       attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *     });
 *   }
 *
 *   navigator.mediaDevices.enumerateDevices().then(function(devices) {
 *     var selectedAudioSourceId = &quot;&quot;;
 *     var selectedVideoSourceId = &quot;&quot;;
 *     devices.forEach(function(device) {
 *       console.log(device.kind + &quot;: &quot; + device.label + &quot; source ID = &quot; + device.deviceId);
 *       if (device.kind === &quot;audio&quot;) {
 *         selectedAudioSourceId = device.deviceId;
 *       } else {
 *         selectedVideoSourceId = device.deviceId;
 *       }
 *     });
 *     selectStream(selectedAudioSourceId, selectedVideoSourceId);
 *   }).catch(function (error) {
 *      console.error(&quot;Failed&quot;, error);
 *   });
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;If &lt;code&gt;options.audio&lt;/code&gt; value is &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;options.video&lt;/code&gt;
 *   value is &lt;code&gt;false&lt;/code&gt;: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Retrieve camera Stream. &lt;ol&gt;&lt;li&gt;If retrieval was succesful: &lt;ol&gt;
 *   &lt;li&gt;If there is any previous &lt;code&gt;getUserMedia()&lt;/code&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;If there are missing audio or video tracks requested: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Mutes / Unmutes audio and video tracks based on current muted settings in &lt;code&gt;peerInfo.mediaStatus&lt;/code&gt;.
 *   &lt;small&gt;This can be retrieved with &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;If &lt;code&gt;options.audioFallback&lt;/code&gt; is enabled in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;code&gt;options.audio&lt;/code&gt; value is &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;options.video&lt;/code&gt; value is &lt;code&gt;true&lt;/code&gt;: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; event triggers
 *   parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKING&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;Retrieve camera Stream with audio tracks only. &lt;ol&gt;&lt;li&gt;If retrieval was successful: &lt;ol&gt;
 *   &lt;li&gt;If there is any previous &lt;code&gt;getUserMedia()&lt;/code&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; event triggers
 *   parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;Mutes / Unmutes audio and video tracks based on current muted settings in &lt;code&gt;peerInfo.mediaStatus&lt;/code&gt;.
 *   &lt;small&gt;This can be retrieved with &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessError&quot;&gt;&lt;code&gt;mediaAccessError&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallbackError&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; event triggers
 *   parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;ERROR&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt; value as
 *   &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessError&quot;&gt;&lt;code&gt;mediaAccessError&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallbackError&lt;/code&gt; value as
 *   &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype.getUserMedia = function(options,callback) {
  var self = this;

  if (typeof options === &#x27;function&#x27;){
    callback = options;
    options = {
      audio: true,
      video: true
    };

  } else if (typeof options !== &#x27;object&#x27; || options === null) {
    if (typeof options === &#x27;undefined&#x27;) {
      options = {
        audio: true,
        video: true
      };

    } else {
      var invalidOptionsError = &#x27;Please provide a valid options&#x27;;
      log.error(invalidOptionsError, options);
      if (typeof callback === &#x27;function&#x27;) {
        callback(new Error(invalidOptionsError), null);
      }
      return;
    }

  } else if (!options.audio &amp;&amp; !options.video) {
    var noConstraintOptionsSelectedError = &#x27;Please select audio or video&#x27;;
    log.error(noConstraintOptionsSelectedError, options);
    if (typeof callback === &#x27;function&#x27;) {
      callback(new Error(noConstraintOptionsSelectedError), null);
    }
    return;
  }

  /*if (window.location.protocol !== &#x27;https:&#x27; &amp;&amp; window.webrtcDetectedBrowser === &#x27;chrome&#x27; &amp;&amp;
    window.webrtcDetectedVersion &gt; 46) {
    errorMsg = &#x27;getUserMedia() has to be called in https:// application&#x27;;
    log.error(errorMsg, options);
    if (typeof callback === &#x27;function&#x27;) {
      callback(new Error(errorMsg), null);
    }
    return;
  }*/

  self._throttle(function (runFn) {
    if (!runFn) {
      if (self._throttlingShouldThrowError) {
        var throttleLimitError = &#x27;Unable to run as throttle interval has not reached (&#x27; + self._throttlingTimeouts.getUserMedia + &#x27;ms).&#x27;;
        log.error(throttleLimitError);

        if (typeof callback === &#x27;function&#x27;) {
          callback(new Error(throttleLimitError), null);
        }
      }
      return;
    }

    if (typeof callback === &#x27;function&#x27;) {
      var mediaAccessSuccessFn = function (stream) {
        self.off(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn);
        callback(null, stream);
      };
      var mediaAccessErrorFn = function (error) {
        self.off(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn);
        callback(error, null);
      };

      self.once(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn, function (stream, isScreensharing) {
        return !isScreensharing;
      });

      self.once(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn, function (error, isScreensharing) {
        return !isScreensharing;
      });
    }

    // Parse stream settings
    var settings = self._parseStreamSettings(options);

    navigator.getUserMedia(settings.getUserMediaSettings, function (stream) {
      if (settings.mutedSettings.shouldAudioMuted) {
        self._streamsMutedSettings.audioMuted = true;
      }

      if (settings.mutedSettings.shouldVideoMuted) {
        self._streamsMutedSettings.videoMuted = true;
      }

      self._onStreamAccessSuccess(stream, settings, false, false);

    }, function (error) {
      self._onStreamAccessError(error, settings, false, false);
    });
  }, &#x27;getUserMedia&#x27;, self._throttlingTimeouts.getUserMedia);
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that if &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; is available despite having
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; available, the
 *   &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; is sent instead of the
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; to Peers.
 * &lt;/blockquote&gt;
 * Function that sends a new &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;
 * to all connected Peers in the Room.
 * @method sendStream
 * @param {JSON|MediaStream} options The &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt;
 *   method&lt;/a&gt; &lt;code&gt;options&lt;/code&gt; parameter settings.
 * - When provided as a &lt;code&gt;MediaStream&lt;/code&gt; object, this configures the &lt;code&gt;options.audio&lt;/code&gt; and
 *   &lt;code&gt;options.video&lt;/code&gt; based on the tracks available in the &lt;code&gt;MediaStream&lt;/code&gt; object,
 *   and configures the &lt;code&gt;options.audio.mute&lt;/code&gt; and &lt;code&gt;options.video.mute&lt;/code&gt; based on the tracks
 *   &lt;code&gt;.enabled&lt;/code&gt; flags in the tracks provided in the &lt;code&gt;MediaStream&lt;/code&gt; object without
 *   invoking &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;.
 *   &lt;small&gt;Object signature matches the &lt;code&gt;options&lt;/code&gt; parameter in the
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;
 * @param {Function} [callback] The callback function fired when request has completed.
 *   &lt;small&gt;Function parameters signature is &lt;code&gt;function (error, success)&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Function request completion is determined by the &lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggering &lt;code&gt;isScreensharing&lt;/code&gt; parameter payload value
 *   as &lt;code&gt;false&lt;/code&gt; for request success when User is in Room without Peers,
 *   or by the &lt;a href=&quot;#event_peerRestart&quot;&gt;&lt;code&gt;peerRestart&lt;/code&gt; event&lt;/a&gt; triggering
 *   &lt;code&gt;isSelfInitiateRestart&lt;/code&gt; parameter payload value as &lt;code&gt;true&lt;/code&gt; for all connected Peers
 *   for request success when User is in Room with Peers.&lt;/small&gt;
 * @param {Error|String} callback.error The error result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are no errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt; error or
 *   when invalid &lt;code&gt;options&lt;/code&gt; is provided.&lt;/small&gt;
 * @param {MediaStream} callback.success The success result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt;
 *   Stream object.&lt;/small&gt;
 * @example
 *   // Example 1: Send MediaStream object
 *   function retrieveStreamBySourceForFirefox (sourceId) {
 *     navigator.mediaDevices.getUserMedia({
 *       audio: true,
 *       video: {
 *         sourceId: { exact: sourceId }
 *       }
 *     }).then(function (stream) {
 *       skylinkDemo.sendStream(stream, function (error, success) {
 *         if (err) return;
 *         if (stream === success) {
 *           console.info(&quot;Same MediaStream has been sent&quot;);
 *         }
 *         console.log(&quot;Stream is now being sent to Peers&quot;);
 *         attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *       });
 *     });
 *   }
 *
 *   // Example 2: Send video later
 *   var inRoom = false;
 *
 *   function sendVideo () {
 *     if (!inRoom) return;
 *     skylinkDemo.sendStream({
 *       audio: true,
 *       video: true
 *     }, function (error, success) {
 *       if (error) return;
 *       console.log(&quot;getUserMedia() Stream with video is now being sent to Peers&quot;);
 *       attachMediaStream(document.getElementById(&quot;my-video&quot;), success);
 *     });
 *   }
 *
 *   skylinkDemo.joinRoom({
 *     audio: true
 *   }, function (jRError, jRSuccess) {
 *     if (jRError) return;
 *     inRoom = true;
 *   });
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;If User is not in Room: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Checks &lt;code&gt;options&lt;/code&gt; provided. &lt;ol&gt;&lt;li&gt;If provided parameter &lt;code&gt;options&lt;/code&gt; is not valid: &lt;ol&gt;
 *   &lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Else if provided parameter &lt;code&gt;options&lt;/code&gt; is a Stream object: &lt;ol&gt;
 *   &lt;li&gt;Checks if there is any audio or video tracks. &lt;ol&gt;&lt;li&gt;If there is no tracks: &lt;ol&gt;
 *   &lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;Set &lt;code&gt;options.audio&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; if Stream has audio tracks.&lt;/li&gt;
 *   &lt;li&gt;Set &lt;code&gt;options.video&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; if Stream has video tracks.&lt;/li&gt;
 *   &lt;li&gt;Mutes / Unmutes audio and video tracks based on current muted settings in
 *   &lt;code&gt;peerInfo.mediaStatus&lt;/code&gt;. &lt;small&gt;This can be retrieved with
 *   &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt;&lt;/li&gt;
 *   &lt;li&gt;If there is any previous &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;:
 *   &lt;ol&gt;&lt;li&gt;Invokes &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt; to stop previous Stream.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;Invoke &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options&lt;/code&gt; provided in &lt;code&gt;sendStream()&lt;/code&gt;. &lt;ol&gt;&lt;li&gt;If request has errors: &lt;ol&gt;
 *   &lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;If there is currently no &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt;: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_incomingStream&quot;&gt;&lt;code&gt;incomingStream&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;stream&lt;/code&gt; as
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;Checks if MCU is enabled for App Key provided in &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;. &lt;ol&gt;
 *   &lt;li&gt;If MCU is enabled: &lt;ol&gt;&lt;li&gt;Invoke &lt;a href=&quot;#method_refreshConnection&quot;&gt;&lt;code&gt;refreshConnection()&lt;/code&gt;
 *   method&lt;/a&gt;. &lt;ol&gt;&lt;li&gt;If request has errors: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Else: &lt;ol&gt;&lt;li&gt;If there are connected Peers in the Room: &lt;ol&gt;
 *   &lt;li&gt;Invoke &lt;a href=&quot;#method_refreshConnection&quot;&gt;&lt;code&gt;refreshConnection()&lt;/code&gt; method&lt;/a&gt;. &lt;ol&gt;
 *   &lt;li&gt;If request has errors: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.
 *   &lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.6
 */

Skylink.prototype.sendStream = function(options, callback) {
  var self = this;

  var restartFn = function (stream) {
    if (self._inRoom) {
      if (!self._streams.screenshare) {
        self._trigger(&#x27;incomingStream&#x27;, self._user.sid, stream, true, self.getPeerInfo(), false, stream.id || stream.label);
        self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
      }

      if (Object.keys(self._peerConnections).length &gt; 0 || self._hasMCU) {
        self._refreshPeerConnection(Object.keys(self._peerConnections), false, function (err, success) {
          if (err) {
            log.error(&#x27;Failed refreshing connections for sendStream() -&gt;&#x27;, err);
            if (typeof callback === &#x27;function&#x27;) {
              callback(new Error(&#x27;Failed refreshing connections.&#x27;), null);
            }
            return;
          }
          if (typeof callback === &#x27;function&#x27;) {
            callback(null, stream);
          }
        });
      } else if (typeof callback === &#x27;function&#x27;) {
        callback(null, stream);
      }
    } else {
      var notInRoomAgainError = &#x27;Unable to send stream as user is not in the Room.&#x27;;
      log.error(notInRoomAgainError, stream);
      if (typeof callback === &#x27;function&#x27;) {
        callback(new Error(notInRoomAgainError), null);
      }
    }
  };

  if (typeof options !== &#x27;object&#x27; || options === null) {
    var invalidOptionsError = &#x27;Provided stream settings is invalid&#x27;;
    log.error(invalidOptionsError, options);
    if (typeof callback === &#x27;function&#x27;){
      callback(new Error(invalidOptionsError),null);
    }
    return;
  }

  if (!self._inRoom) {
    var notInRoomError = &#x27;Unable to send stream as user is not in the Room.&#x27;;
    log.error(notInRoomError, options);
    if (typeof callback === &#x27;function&#x27;){
      callback(new Error(notInRoomError),null);
    }
    return;
  }

  if (typeof options.getAudioTracks === &#x27;function&#x27; || typeof options.getVideoTracks === &#x27;function&#x27;) {
    var checkActiveTracksFn = function (tracks) {
      for (var t = 0; t &lt; tracks.length; t++) {
        if (!(tracks[t].ended || (typeof tracks[t].readyState === &#x27;string&#x27; ?
          tracks[t].readyState !== &#x27;live&#x27; : false))) {
          return true;
        }
      }
      return false;
    };

    if (!checkActiveTracksFn( options.getAudioTracks() ) &amp;&amp; !checkActiveTracksFn( options.getVideoTracks() )) {
      var invalidStreamError = &#x27;Provided stream object does not have audio or video tracks.&#x27;;
      log.error(invalidStreamError, options);
      if (typeof callback === &#x27;function&#x27;){
        callback(new Error(invalidStreamError),null);
      }
      return;
    }

    self._onStreamAccessSuccess(options, {
      settings: {
        audio: true,
        video: true
      },
      getUserMediaSettings: {
        audio: true,
        video: true
      }
    }, false, false);

    restartFn(options);

  } else {
    self.getUserMedia(options, function (err, stream) {
      if (err) {
        if (typeof callback === &#x27;function&#x27;) {
          callback(err, null);
        }
        return;
      }
      restartFn(stream);
    });
  }
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that broadcasted events from &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_sendMessage&quot;&gt;&lt;code&gt;sendMessage()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_unlockRoom&quot;&gt;&lt;code&gt;unlockRoom()&lt;/code&gt; method&lt;/a&gt; and
 *   &lt;a href=&quot;#method_lockRoom&quot;&gt;&lt;code&gt;lockRoom()&lt;/code&gt; method&lt;/a&gt; may be queued when
 *   sent within less than an interval.
 * &lt;/blockquote&gt;
 * Function that stops &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;.
 * @method stopStream
 * @example
 *   function stopStream () {
 *     skylinkDemo.stopStream();
 *   }
 *
 *   skylinkDemo.getUserMedia();
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Checks if there is &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;. &lt;ol&gt;
 *   &lt;li&gt;If there is &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;: &lt;ol&gt;
 *   &lt;li&gt;Stop &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; Stream. &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessStopped&quot;&gt;&lt;code&gt;mediaAccessStopped&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;If User is in Room: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_streamEnded&quot;&gt;&lt;code&gt;streamEnded&lt;/code&gt; event&lt;/a&gt; triggers parameter
 *   payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isScreensharing&lt;/code&gt; value as&lt;code&gt;false&lt;/code&gt;
 *   .&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.6
 */
Skylink.prototype.stopStream = function () {
  if (this._streams.userMedia) {
    this._stopStreams({
      userMedia: true
    });
  }
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that broadcasted events from &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_sendMessage&quot;&gt;&lt;code&gt;sendMessage()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_unlockRoom&quot;&gt;&lt;code&gt;unlockRoom()&lt;/code&gt; method&lt;/a&gt; and
 *   &lt;a href=&quot;#method_lockRoom&quot;&gt;&lt;code&gt;lockRoom()&lt;/code&gt; method&lt;/a&gt; may be queued when
 *   sent within less than an interval.
 * &lt;/blockquote&gt;
 * Function that mutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; audio or video tracks.
 * @method muteStream
 * @param {JSON} options The Streams muting options.
 * @param {Boolean} [options.audioMuted=true] The flag if all Streams audio
 *   tracks should be muted or not.
 * @param {Boolean} [options.videoMuted=true] The flag if all Streams video
 *   tracks should be muted or not.
 * @example
 *   // Example 1: Mute both audio and video tracks in all Streams
 *   skylinkDemo.muteStream({
 *     audioMuted: true,
 *     videoMuted: true
 *   });
 *
 *   // Example 2: Mute only audio tracks in all Streams
 *   skylinkDemo.muteStream({
 *     audioMuted: true,
 *     videoMuted: false
 *   });
 *
 *   // Example 3: Mute only video tracks in all Streams
 *   skylinkDemo.muteStream({
 *     audioMuted: false,
 *     videoMuted: true
 *   });
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;If provided parameter &lt;code&gt;options&lt;/code&gt; is invalid: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Checks if there is any available Streams: &lt;ol&gt;&lt;li&gt;If there is no available Streams: &lt;ol&gt;
 *   &lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;If User is in Room: &lt;ol&gt;
 *   &lt;li&gt;Checks if there is audio tracks to mute / unmute: &lt;ol&gt;&lt;li&gt;If there is audio tracks to mute / unmute: &lt;ol&gt;
 *   &lt;li&gt;If &lt;code&gt;options.audioMuted&lt;/code&gt; value is not the same as the current
 *   &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt;: &lt;small&gt;This can be retrieved with
 *   &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt; &lt;ol&gt;
 *   &lt;li&gt;&lt;em&gt;For Peer only&lt;/em&gt; &lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt;
 *   triggers with parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;em&gt;For Peer only&lt;/em&gt; &lt;a href=&quot;#event_streamMuted&quot;&gt;&lt;code&gt;streamMuted&lt;/code&gt; event&lt;/a&gt;
 *   triggers with parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Checks if there is video tracks to mute / unmute: &lt;ol&gt;&lt;li&gt;If there is video tracks to mute / unmute: &lt;ol&gt;
 *   &lt;li&gt;If &lt;code&gt;options.videoMuted&lt;/code&gt; value is not the same as the current
 *   &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt;: &lt;small&gt;This can be retrieved with
 *   &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt; &lt;ol&gt;
 *   &lt;li&gt;&lt;em&gt;For Peer only&lt;/em&gt; &lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt;
 *   triggers with parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;em&gt;For Peer only&lt;/em&gt; &lt;a href=&quot;#event_streamMuted&quot;&gt;&lt;code&gt;streamMuted&lt;/code&gt; event&lt;/a&gt; triggers with
 *   parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;If &lt;code&gt;options.audioMuted&lt;/code&gt; value is not the same as the current
 *   &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt; or &lt;code&gt;options.videoMuted&lt;/code&gt; value is not
 *   the same as the current &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt;: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_localMediaMuted&quot;&gt;&lt;code&gt;localMediaMuted&lt;/code&gt; event&lt;/a&gt; triggers.&lt;/li&gt;
 *   &lt;li&gt;If User is in Room: &lt;ol&gt;&lt;li&gt;&lt;a href=&quot;#event_streamMuted&quot;&gt;&lt;code&gt;streamMuted&lt;/code&gt; event&lt;/a&gt;
 *   triggers with parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers with
 *   parameter payload &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.7
 */
Skylink.prototype.muteStream = function(options) {
  var self = this;

  if (typeof options !== &#x27;object&#x27;) {
    log.error(&#x27;Provided settings is not an object&#x27;);
    return;
  }

  if (!(self._streams.userMedia &amp;&amp; self._streams.userMedia.stream) &amp;&amp;
    !(self._streams.screenshare &amp;&amp; self._streams.screenshare.stream)) {
    log.warn(&#x27;No streams are available to mute / unmute!&#x27;);
    return;
  }

  var audioMuted = typeof options.audioMuted === &#x27;boolean&#x27; ? options.audioMuted : true;
  var videoMuted = typeof options.videoMuted === &#x27;boolean&#x27; ? options.videoMuted : true;
  var hasToggledAudio = false;
  var hasToggledVideo = false;

  if (self._streamsMutedSettings.audioMuted !== audioMuted) {
    self._streamsMutedSettings.audioMuted = audioMuted;
    hasToggledAudio = true;
  }

  if (self._streamsMutedSettings.videoMuted !== videoMuted) {
    self._streamsMutedSettings.videoMuted = videoMuted;
    hasToggledVideo = true;
  }

  if (hasToggledVideo || hasToggledAudio) {
    var streamTracksAvailability = self._muteStreams();

    if (hasToggledVideo &amp;&amp; self._inRoom) {
      self._sendChannelMessage({
        type: self._SIG_MESSAGE_TYPE.MUTE_VIDEO,
        mid: self._user.sid,
        rid: self._room.id,
        muted: self._streamsMutedSettings.videoMuted,
        stamp: (new Date()).getTime()
      });
    }

    if (hasToggledAudio &amp;&amp; self._inRoom) {
      setTimeout(function () {
        self._sendChannelMessage({
          type: self._SIG_MESSAGE_TYPE.MUTE_AUDIO,
          mid: self._user.sid,
          rid: self._room.id,
          muted: self._streamsMutedSettings.audioMuted,
          stamp: (new Date()).getTime()
        });
      }, hasToggledVideo ? 1050 : 0);
    }

    if ((streamTracksAvailability.hasVideo &amp;&amp; hasToggledVideo) ||
      (streamTracksAvailability.hasAudio &amp;&amp; hasToggledAudio)) {

      self._trigger(&#x27;localMediaMuted&#x27;, {
        audioMuted: streamTracksAvailability.hasAudio ? self._streamsMutedSettings.audioMuted : true,
        videoMuted: streamTracksAvailability.hasVideo ? self._streamsMutedSettings.videoMuted : true
      });

      if (self._inRoom) {
        self._trigger(&#x27;streamMuted&#x27;, self._user.sid, self.getPeerInfo(), true,
          self._streams.screenshare &amp;&amp; self._streams.screenshare.stream);
        self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
      }
    }
  }
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that unmutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; audio tracks.
 * @method enableAudio
 * @deprecated true
 * @example
 *   function unmuteAudio () {
 *     skylinkDemo.enableAudio();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.audioMuted&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;options.videoMuted&lt;/code&gt; value with current &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt; value.
 *   &lt;small&gt;See &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt; for more information.&lt;/small&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.enableAudio = function() {
  this.muteStream({
    audioMuted: false,
    videoMuted: this._streamsMutedSettings.videoMuted
  });
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that mutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; audio tracks.
 * @method disableAudio
 * @deprecated true
 * @example
 *   function muteAudio () {
 *     skylinkDemo.disableAudio();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.audioMuted&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and
 *   &lt;code&gt;options.videoMuted&lt;/code&gt; value with current &lt;code&gt;peerInfo.mediaStatus.videoMuted&lt;/code&gt; value.
 *   &lt;small&gt;See &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt; for more information.&lt;/small&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.disableAudio = function() {
  this.muteStream({
    audioMuted: true,
    videoMuted: this._streamsMutedSettings.videoMuted
  });
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that unmutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; video tracks.
 * @method enableVideo
 * @deprecated true
 * @example
 *   function unmuteVideo () {
 *     skylinkDemo.enableVideo();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.videoMuted&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt; and
 *   &lt;code&gt;options.audioMuted&lt;/code&gt; value with current &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt; value.
 *   &lt;small&gt;See &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt; for more information.&lt;/small&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.enableVideo = function() {
  this.muteStream({
    videoMuted: false,
    audioMuted: this._streamsMutedSettings.audioMuted
  });
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;&lt;b&gt;Deprecation Warning!&lt;/b&gt;
 *   This method has been deprecated. Use &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; instead.
 * &lt;/blockquote&gt;
 * Function that mutes both &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt; and
 * &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; video tracks.
 * @method disableVideo
 * @deprecated true
 * @example
 *   function muteVideo () {
 *     skylinkDemo.disableVideo();
 *   }
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt; with
 *   &lt;code&gt;options.videoMuted&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and
 *   &lt;code&gt;options.audioMuted&lt;/code&gt; value with current &lt;code&gt;peerInfo.mediaStatus.audioMuted&lt;/code&gt; value.
 *   &lt;small&gt;See &lt;a href=&quot;#method_getPeerInfo&quot;&gt;&lt;code&gt;getPeerInfo()&lt;/code&gt; method&lt;/a&gt; for more information.&lt;/small&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.5.5
 */
Skylink.prototype.disableVideo = function() {
  this.muteStream({
    videoMuted: true,
    audioMuted: this._streamsMutedSettings.audioMuted
  });
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   For a better user experience, the functionality is throttled when invoked many times in less
 *   than the milliseconds interval configured in the &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;.
 * &lt;/blockquote&gt;
 * Function that retrieves screensharing Stream.
 * @method shareScreen
 * @param {JSON|Boolean} [enableAudio=false] The flag if audio tracks should be retrieved.
 * @param {Boolean} [enableAudio.stereo=false] The flag if stereo band should be configured
 *   when encoding audio codec is &lt;a href=&quot;#attr_AUDIO_CODEC&quot;&gt;&lt;code&gt;OPUS&lt;/code&gt;&lt;/a&gt; for sending audio data.
 * @param {Boolean} [enableAudio.usedtx] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that this feature might not work depending on the browser support and implementation.&lt;/blockquote&gt;
 *   The flag if DTX (Discontinuous Transmission) should be configured when encoding audio codec
 *   is &lt;a href=&quot;#attr_AUDIO_CODEC&quot;&gt;&lt;code&gt;OPUS&lt;/code&gt;&lt;/a&gt; for sending audio data.
 *   &lt;small&gt;This might help to reduce bandwidth it reduces the bitrate during silence or background noise.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Boolean} [enableAudio.useinbandfec] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that this feature might not work depending on the browser support and implementation.&lt;/blockquote&gt;
 *   The flag if capability to take advantage of in-band FEC (Forward Error Correction) should be
 *   configured when encoding audio codec is &lt;a href=&quot;#attr_AUDIO_CODEC&quot;&gt;&lt;code&gt;OPUS&lt;/code&gt;&lt;/a&gt; for sending audio data.
 *   &lt;small&gt;This might help to reduce the harm of packet loss by encoding information about the previous packet.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Number} [enableAudio.maxplaybackrate] &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that this feature might not work depending on the browser support and implementation.&lt;/blockquote&gt;
 *   The maximum output sampling rate rendered in Hertz (Hz) when encoding audio codec is
 *   &lt;a href=&quot;#attr_AUDIO_CODEC&quot;&gt;&lt;code&gt;OPUS&lt;/code&gt;&lt;/a&gt; for sending audio data.
 *   &lt;small&gt;This value must be between &lt;code&gt;8000&lt;/code&gt; to &lt;code&gt;48000&lt;/code&gt;.&lt;/small&gt;
 *   &lt;small&gt;When not provided, the default browser configuration is used.&lt;/small&gt;
 * @param {Boolean} [enableAudio.echoCancellation=false] The flag to enable audio tracks echo cancellation.
 * @param {Function} [callback] The callback function fired when request has completed.
 *   &lt;small&gt;Function parameters signature is &lt;code&gt;function (error, success)&lt;/code&gt;&lt;/small&gt;
 *   &lt;small&gt;Function request completion is determined by the &lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggering &lt;code&gt;isScreensharing&lt;/code&gt; parameter payload value
 *   as &lt;code&gt;true&lt;/code&gt; for request success when User is not in the Room or is in Room without Peers,
 *   or by the &lt;a href=&quot;#event_peerRestart&quot;&gt;&lt;code&gt;peerRestart&lt;/code&gt; event&lt;/a&gt; triggering
 *   &lt;code&gt;isSelfInitiateRestart&lt;/code&gt; parameter payload value as &lt;code&gt;true&lt;/code&gt; for all connected Peers
 *   for request success when User is in Room with Peers.&lt;/small&gt;
 * @param {Error|String} callback.error The error result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are no errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the &lt;code&gt;shareScreen()&lt;/code&gt; error when retrieving screensharing Stream.&lt;/small&gt;
 * @param {MediaStream} callback.success The success result in request.
 *   &lt;small&gt;Defined as &lt;code&gt;null&lt;/code&gt; when there are errors in request&lt;/small&gt;
 *   &lt;small&gt;Object signature is the screensharing Stream object.&lt;/small&gt;
 * @example
 *   // Example 1: Share screen with audio
 *   skylinkDemo.shareScreen(function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-screen&quot;), success);
 *   });
 *
 *   // Example 2: Share screen without audio
 *   skylinkDemo.shareScreen(false, function (error, success) {
 *     if (error) return;
 *     attachMediaStream(document.getElementById(&quot;my-screen&quot;), success);
 *   });
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Retrieves screensharing Stream. &lt;ol&gt;&lt;li&gt;If retrieval was successful: &lt;ol&gt;&lt;li&gt;If browser is Firefox: &lt;ol&gt;
 *   &lt;li&gt;If there are missing audio or video tracks requested: &lt;ol&gt;
 *   &lt;li&gt;If there is any previous &lt;code&gt;shareScreen()&lt;/code&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt;
 *   triggers parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;If audio is requested: &lt;small&gt;Chrome, Safari and IE currently doesn&#x27;t support retrieval of
 *   audio track together with screensharing video track.&lt;/small&gt; &lt;ol&gt;&lt;li&gt;Retrieves audio Stream: &lt;ol&gt;
 *   &lt;li&gt;If retrieval was successful: &lt;ol&gt;&lt;li&gt;Attempts to attach screensharing Stream video track to audio Stream. &lt;ol&gt;
 *   &lt;li&gt;If attachment was successful: &lt;ol&gt;&lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;
 *   &lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers parameter payload &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;If there is any previous &lt;code&gt;shareScreen()&lt;/code&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;If there is any previous &lt;code&gt;shareScreen()&lt;/code&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;Invokes &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessFallback&quot;&gt;&lt;code&gt;mediaAccessFallback&lt;/code&gt; event&lt;/a&gt;
 *   triggers parameter payload &lt;code&gt;state&lt;/code&gt; as &lt;code&gt;FALLBACKED&lt;/code&gt;, &lt;code&gt;isScreensharing&lt;/code&gt;
 *   value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt; triggers
 *   parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt;
 *   value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessSuccess&quot;&gt;&lt;code&gt;mediaAccessSuccess&lt;/code&gt; event&lt;/a&gt;
 *   triggers parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;
 *   and &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessError&quot;&gt;&lt;code&gt;mediaAccessError&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isAudioFallback&lt;/code&gt; value as
 *   &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;If User is in Room: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_incomingStream&quot;&gt;&lt;code&gt;incomingStream&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;stream&lt;/code&gt; as &lt;code&gt;shareScreen()&lt;/code&gt; Stream.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;Checks if MCU is enabled for App Key provided in &lt;a href=&quot;#method_init&quot;&gt;&lt;code&gt;init()&lt;/code&gt; method&lt;/a&gt;. &lt;ol&gt;
 *   &lt;li&gt;If MCU is enabled: &lt;ol&gt;&lt;li&gt;Invoke &lt;a href=&quot;#method_refreshConnection&quot;&gt;&lt;code&gt;refreshConnection()&lt;/code&gt; method&lt;/a&gt;.
 *   &lt;ol&gt;&lt;li&gt;If request has errors: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;Else: &lt;ol&gt;
 *   &lt;li&gt;If there are connected Peers in the Room: &lt;ol&gt;&lt;li&gt;Invoke &lt;a href=&quot;#method_refreshConnection&quot;&gt;
 *   &lt;code&gt;refreshConnection()&lt;/code&gt; method&lt;/a&gt;. &lt;ol&gt;&lt;li&gt;If request has errors: &lt;ol&gt;&lt;li&gt;&lt;b&gt;ABORT&lt;/b&gt; and return error.&lt;/li&gt;
 *   &lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.6.0
 */
Skylink.prototype.shareScreen = function (enableAudio, callback) {
  var self = this;
  var enableAudioSettings = {
    stereo: true
  };

  if (typeof enableAudio === &#x27;function&#x27;) {
    callback = enableAudio;
    enableAudio = true;

  } else if (enableAudio &amp;&amp; typeof enableAudio === &#x27;object&#x27;) {
    enableAudioSettings.usedtx = typeof enableAudio.usedtx === &#x27;boolean&#x27; ? enableAudio.usedtx : null;
    enableAudioSettings.useinbandfec = typeof enableAudio.useinbandfec === &#x27;boolean&#x27; ? enableAudio.useinbandfec : null;
    enableAudioSettings.stereo = enableAudio.stereo === true;
    enableAudioSettings.echoCancellation = enableAudio.echoCancellation === true;
  }

  self._throttle(function (runFn) {
    if (!runFn) {
      if (self._throttlingShouldThrowError) {
        var throttleLimitError = &#x27;Unable to run as throttle interval has not reached (&#x27; + self._throttlingTimeouts.shareScreen + &#x27;ms).&#x27;;
        log.error(throttleLimitError);

        if (typeof callback === &#x27;function&#x27;) {
          callback(new Error(throttleLimitError), null);
        }
      }
      return;
    }

    var settings = {
      settings: {
        audio: enableAudio === true || (enableAudio &amp;&amp; typeof enableAudio === &#x27;object&#x27;) ? enableAudioSettings : false,
        video: {
          screenshare: true,
          exactConstraints: false
        }
      },
      getUserMediaSettings: {
        video: {
          mediaSource: &#x27;window&#x27;
        }
      }
    };

    var mediaAccessSuccessFn = function (stream) {
      self.off(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn);

      if (self._inRoom) {
        self._trigger(&#x27;incomingStream&#x27;, self._user.sid, stream, true, self.getPeerInfo(), true, stream.id || stream.label);
        self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);

        if (Object.keys(self._peerConnections).length &gt; 0 || self._hasMCU) {
          self._refreshPeerConnection(Object.keys(self._peerConnections), false, function (err, success) {
            if (err) {
              log.error(&#x27;Failed refreshing connections for shareScreen() -&gt;&#x27;, err);
              if (typeof callback === &#x27;function&#x27;) {
                callback(new Error(&#x27;Failed refreshing connections.&#x27;), null);
              }
              return;
            }
            if (typeof callback === &#x27;function&#x27;) {
              callback(null, stream);
            }
          });
        } else if (typeof callback === &#x27;function&#x27;) {
          callback(null, stream);
        }
      } else if (typeof callback === &#x27;function&#x27;) {
        callback(null, stream);
      }
    };

    var mediaAccessErrorFn = function (error) {
      self.off(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn);

      if (typeof callback === &#x27;function&#x27;) {
        callback(error, null);
      }
    };

    self.once(&#x27;mediaAccessSuccess&#x27;, mediaAccessSuccessFn, function (stream, isScreensharing) {
      return isScreensharing;
    });

    self.once(&#x27;mediaAccessError&#x27;, mediaAccessErrorFn, function (error, isScreensharing) {
      return isScreensharing;
    });

    try {
      if (enableAudio &amp;&amp; window.webrtcDetectedBrowser === &#x27;firefox&#x27;) {
        settings.getUserMediaSettings.audio = true;
      }

      navigator.getUserMedia(settings.getUserMediaSettings, function (stream) {
        if (window.webrtcDetectedBrowser === &#x27;firefox&#x27; || !enableAudio) {
          self._onStreamAccessSuccess(stream, settings, true, false);
          return;
        }

        navigator.getUserMedia({
          audio: true

        }, function (audioStream) {
          try {
            audioStream.addTrack(stream.getVideoTracks()[0]);

            self.once(&#x27;mediaAccessSuccess&#x27;, function () {
              self._streams.screenshare.streamClone = stream;
            }, function (stream, isScreensharing) {
              return isScreensharing;
            });

            self._onStreamAccessSuccess(audioStream, settings, true, false);

          } catch (error) {
            log.error(&#x27;Failed retrieving audio stream for screensharing stream&#x27;, error);
            self._onStreamAccessSuccess(stream, settings, true, false);
          }
        }, function (error) {
          log.error(&#x27;Failed retrieving audio stream for screensharing stream&#x27;, error);
          self._onStreamAccessSuccess(stream, settings, true, false);
        });

      }, function (error) {
        self._onStreamAccessError(error, settings, true, false);
      });

    } catch (error) {
      self._onStreamAccessError(error, settings, true, false);
    }
  }, &#x27;shareScreen&#x27;, self._throttlingTimeouts.shareScreen);
};

/**
 * &lt;blockquote class=&quot;info&quot;&gt;
 *   Note that broadcasted events from &lt;a href=&quot;#method_muteStream&quot;&gt;&lt;code&gt;muteStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopStream&quot;&gt;&lt;code&gt;stopStream()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_stopScreen&quot;&gt;&lt;code&gt;stopScreen()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_sendMessage&quot;&gt;&lt;code&gt;sendMessage()&lt;/code&gt; method&lt;/a&gt;,
 *   &lt;a href=&quot;#method_unlockRoom&quot;&gt;&lt;code&gt;unlockRoom()&lt;/code&gt; method&lt;/a&gt; and
 *   &lt;a href=&quot;#method_lockRoom&quot;&gt;&lt;code&gt;lockRoom()&lt;/code&gt; method&lt;/a&gt; may be queued when
 *   sent within less than an interval.
 * &lt;/blockquote&gt;
 * Function that stops &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt;.
 * @method stopScreen
 * @example
 *   function stopScreen () {
 *     skylinkDemo.stopScreen();
 *   }
 *
 *   skylinkDemo.shareScreen();
 * @trigger &lt;ol class=&quot;desc-seq&quot;&gt;
 *   &lt;li&gt;Checks if there is &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt;. &lt;ol&gt;
 *   &lt;li&gt;If there is &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt;: &lt;ol&gt;
 *   &lt;li&gt;Stop &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; Stream&lt;/a&gt; Stream. &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_mediaAccessStopped&quot;&gt;&lt;code&gt;mediaAccessStopped&lt;/code&gt; event&lt;/a&gt;
 *   triggers parameter payload &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and
 *   &lt;code&gt;isAudioFallback&lt;/code&gt; value as &lt;code&gt;false&lt;/code&gt;.&lt;/li&gt;&lt;li&gt;If User is in Room: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_streamEnded&quot;&gt;&lt;code&gt;streamEnded&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;isScreensharing&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;
 *   &lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;li&gt;If User is in Room: &lt;small&gt;&lt;b&gt;SKIP&lt;/b&gt; this step if &lt;code&gt;stopScreen()&lt;/code&gt;
 *   was invoked from &lt;a href=&quot;#method_shareScreen&quot;&gt;&lt;code&gt;shareScreen()&lt;/code&gt; method&lt;/a&gt;.&lt;/small&gt; &lt;ol&gt;
 *   &lt;li&gt;If there is &lt;a href=&quot;#method_getUserMedia&quot;&gt; &lt;code&gt;getUserMedia()&lt;/code&gt;Stream&lt;/a&gt; Stream: &lt;ol&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_incomingStream&quot;&gt;&lt;code&gt;incomingStream&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt; and &lt;code&gt;stream&lt;/code&gt; as
 *   &lt;a href=&quot;#method_getUserMedia&quot;&gt;&lt;code&gt;getUserMedia()&lt;/code&gt; Stream&lt;/a&gt;.&lt;/li&gt;
 *   &lt;li&gt;&lt;a href=&quot;#event_peerUpdated&quot;&gt;&lt;code&gt;peerUpdated&lt;/code&gt; event&lt;/a&gt; triggers parameter payload
 *   &lt;code&gt;isSelf&lt;/code&gt; value as &lt;code&gt;true&lt;/code&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;
 *   &lt;li&gt;Invoke &lt;a href=&quot;#method_refreshConnection&quot;&gt;&lt;code&gt;refreshConnection()&lt;/code&gt; method&lt;/a&gt;.&lt;/li&gt;
 *   &lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/li&gt;&lt;/ol&gt;
 * @for Skylink
 * @since 0.6.0
 */
Skylink.prototype.stopScreen = function () {
  if (this._streams.screenshare) {
    this._stopStreams({
      screenshare: true
    });

    if (this._inRoom) {
      if (this._streams.userMedia &amp;&amp; this._streams.userMedia.stream) {
        this._trigger(&#x27;incomingStream&#x27;, this._user.sid, this._streams.userMedia.stream, true, this.getPeerInfo(),
          false, this._streams.userMedia.stream.id || this._streams.userMedia.stream.label);
        this._trigger(&#x27;peerUpdated&#x27;, this._user.sid, this.getPeerInfo(), true);
      }
      this._refreshPeerConnection(Object.keys(this._peerConnections), false);
    }
  }
};

/**
 * Function that handles the muting of Stream audio and video tracks.
 * @method _muteStreams
 * @private
 * @for Skylink
 * @since 0.6.15
 */
Skylink.prototype._muteStreams = function () {
  var self = this;
  var hasVideo = false;
  var hasAudio = false;

  var muteFn = function (stream) {
    var audioTracks = stream.getAudioTracks();
    var videoTracks = stream.getVideoTracks();

    for (var a = 0; a &lt; audioTracks.length; a++) {
      audioTracks[a].enabled = !self._streamsMutedSettings.audioMuted;
      hasAudio = true;
    }

    for (var v = 0; v &lt; videoTracks.length; v++) {
      videoTracks[v].enabled = !self._streamsMutedSettings.videoMuted;
      hasVideo = true;
    }
  };

  if (self._streams.userMedia &amp;&amp; self._streams.userMedia.stream) {
    muteFn(self._streams.userMedia.stream);
  }

  if (self._streams.screenshare &amp;&amp; self._streams.screenshare.stream) {
    muteFn(self._streams.screenshare.stream);
  }

  if (self._streams.screenshare &amp;&amp; self._streams.screenshare.streamClone) {
    muteFn(self._streams.screenshare.streamClone);
  }

  log.debug(&#x27;Updated Streams muted status -&gt;&#x27;, self._streamsMutedSettings);

  return {
    hasVideo: hasVideo,
    hasAudio: hasAudio
  };
};

/**
 * Function that handles stopping the Stream streaming.
 * @method _stopStreams
 * @private
 * @for Skylink
 * @since 0.6.15
 */
Skylink.prototype._stopStreams = function (options) {
  var self = this;
  var stopFn = function (stream) {
    var streamId = stream.id || stream.label;
    log.debug([null, &#x27;MediaStream&#x27;, streamId, &#x27;Stopping Stream -&gt;&#x27;], stream);

    try {
      var audioTracks = stream.getAudioTracks();
      var videoTracks = stream.getVideoTracks();

      for (var a = 0; a &lt; audioTracks.length; a++) {
        audioTracks[a].stop();
      }

      for (var v = 0; v &lt; videoTracks.length; v++) {
        videoTracks[v].stop();
      }

    } catch (error) {
      stream.stop();
    }

    if (self._streamsStoppedCbs[streamId]) {
      self._streamsStoppedCbs[streamId]();
      delete self._streamsStoppedCbs[streamId];
    }
  };

  var stopUserMedia = false;
  var stopScreenshare = false;
  var hasStoppedMedia = false;

  if (typeof options === &#x27;object&#x27;) {
    stopUserMedia = options.userMedia === true;
    stopScreenshare = options.screenshare === true;
  }

  if (stopUserMedia &amp;&amp; self._streams.userMedia) {
    if (self._streams.userMedia.stream) {
      stopFn(self._streams.userMedia.stream);
    }

    self._streams.userMedia = null;
    hasStoppedMedia = true;
  }

  if (stopScreenshare &amp;&amp; self._streams.screenshare) {
    if (self._streams.screenshare.streamClone) {
      stopFn(self._streams.screenshare.streamClone);
    }

    if (self._streams.screenshare.stream) {
      stopFn(self._streams.screenshare.stream);
    }

    self._streams.screenshare = null;
    hasStoppedMedia = true;
  }

  if (self._inRoom &amp;&amp; hasStoppedMedia) {
    self._trigger(&#x27;peerUpdated&#x27;, self._user.sid, self.getPeerInfo(), true);
  }

  log.log(&#x27;Stopping Streams with settings -&gt;&#x27;, options);
};

/**
 * Function that parses the &lt;code&gt;getUserMedia()&lt;/code&gt; settings provided.
 * @method _parseStreamSettings
 * @private
 * @for Skylink
 * @since 0.6.15
 */
Skylink.prototype._parseStreamSettings = function(options) {
  var settings = {
    settings: { audio: false, video: false },
    mutedSettings: { shouldAudioMuted: false, shouldVideoMuted: false },
    getUserMediaSettings: { audio: false, video: false }
  };

  if (options.audio) {
    // For Edge to work since they do not support the advanced constraints yet
    if (window.webrtcDetectedBrowser === &#x27;edge&#x27;) {
      settings.getUserMediaSettings.audio = true;
    } else {
      settings.settings.audio = {
        stereo: false,
        exactConstraints: !!options.useExactConstraints,
        echoCancellation: false
      };
      settings.getUserMediaSettings.audio = {
        echoCancellation: false
      };

      if (typeof options.audio === &#x27;object&#x27;) {
        if (typeof options.audio.stereo === &#x27;boolean&#x27;) {
          settings.settings.audio.stereo = options.audio.stereo;
        }

        if (typeof options.audio.useinbandfec === &#x27;boolean&#x27;) {
          settings.settings.audio.useinbandfec = options.audio.useinbandfec;
        }

        if (typeof options.audio.usedtx === &#x27;boolean&#x27;) {
          settings.settings.audio.usedtx = options.audio.usedtx;
        }

        if (typeof options.audio.maxplaybackrate === &#x27;number&#x27; &amp;&amp;
          options.audio.maxplaybackrate &gt;= 8000 &amp;&amp; options.audio.maxplaybackrate &lt;= 48000) {
          settings.settings.audio.maxplaybackrate = options.audio.maxplaybackrate;
        }

        if (typeof options.audio.mute === &#x27;boolean&#x27;) {
          settings.mutedSettings.shouldAudioMuted = options.audio.mute;
        }

        if (typeof options.audio.echoCancellation === &#x27;boolean&#x27;) {
          settings.settings.audio.echoCancellation = options.audio.echoCancellation;
          settings.getUserMediaSettings.audio.echoCancellation = options.audio.echoCancellation;
        }

        if (Array.isArray(options.audio.optional)) {
          settings.settings.audio.optional = clone(options.audio.optional);
          settings.getUserMediaSettings.audio.optional = clone(options.audio.optional);
        }

        if (options.audio.deviceId &amp;&amp; typeof options.audio.deviceId === &#x27;string&#x27; &amp;&amp;
          window.webrtcDetectedBrowser !== &#x27;firefox&#x27;) {
          settings.settings.audio.deviceId = options.audio.deviceId;

          if (options.useExactConstraints) {
            settings.getUserMediaSettings.audio.deviceId = { exact: options.audio.deviceId };

          } else {
            if (!Array.isArray(settings.getUserMediaSettings.audio.optional)) {
              settings.getUserMediaSettings.audio.optional = [];
            }

            settings.getUserMediaSettings.audio.optional.push({
              sourceId: options.audio.deviceId
            });
          }
        }
      }
    }
  }

  if (options.video) {
    // For Edge to work since they do not support the advanced constraints yet
    if (window.webrtcDetectedBrowser === &#x27;edge&#x27;) {
      settings.getUserMediaSettings.video = true;
    } else {
      settings.settings.video = {
        resolution: clone(this.VIDEO_RESOLUTION.VGA),
        screenshare: false,
        exactConstraints: !!options.useExactConstraints
      };
      settings.getUserMediaSettings.video = {};

      if (typeof options.video === &#x27;object&#x27;) {
        if (typeof options.video.mute === &#x27;boolean&#x27;) {
          settings.mutedSettings.shouldVideoMuted = options.video.mute;
        }

        if (Array.isArray(options.video.optional)) {
          settings.settings.video.optional = clone(options.video.optional);
          settings.getUserMediaSettings.video.optional = clone(options.video.optional);
        }

        if (options.video.deviceId &amp;&amp; typeof options.video.deviceId === &#x27;string&#x27; &amp;&amp;
          window.webrtcDetectedBrowser !== &#x27;firefox&#x27;) {
          settings.settings.video.deviceId = options.video.deviceId;

          if (options.useExactConstraints) {
            settings.getUserMediaSettings.video.deviceId = { exact: options.video.deviceId };

          } else {
            if (!Array.isArray(settings.getUserMediaSettings.video.optional)) {
              settings.getUserMediaSettings.video.optional = [];
            }

            settings.getUserMediaSettings.video.optional.push({
              sourceId: options.video.deviceId
            });
          }
        }

        if (options.video.resolution &amp;&amp; typeof options.video.resolution === &#x27;object&#x27;) {
          if ((options.video.resolution.width &amp;&amp; typeof options.video.resolution.width === &#x27;object&#x27;) ||
            typeof options.video.resolution.width === &#x27;number&#x27;) {
            settings.settings.video.resolution.width = options.video.resolution.width;
          }
          if ((options.video.resolution.height &amp;&amp; typeof options.video.resolution.height === &#x27;object&#x27;) ||
            typeof options.video.resolution.height === &#x27;number&#x27;) {
            settings.settings.video.resolution.height = options.video.resolution.height;
          }
        }

        settings.getUserMediaSettings.video.width = typeof settings.settings.video.resolution.width === &#x27;object&#x27; ?
          settings.settings.video.resolution.width : (options.useExactConstraints ?
          { exact: settings.settings.video.resolution.width } : { max: settings.settings.video.resolution.width });

        settings.getUserMediaSettings.video.height = typeof settings.settings.video.resolution.height === &#x27;object&#x27; ?
          settings.settings.video.resolution.height : (options.useExactConstraints ?
          { exact: settings.settings.video.resolution.height } : { max: settings.settings.video.resolution.height });

        if ((options.video.frameRate &amp;&amp; typeof options.video.frameRate === &#x27;object&#x27;) || typeof object.video.frameRate === &#x27;number&#x27;) {
          //
          if (!(typeof options.video.frameRate === &#x27;number&#x27; &amp;&amp; !options.useExactConstraints &amp;&amp; self._isUsingPlugin)) {
            settings.settings.video.frameRate = options.video.frameRate;
            settings.getUserMediaSettings.video.frameRate = typeof settings.settings.video.frameRate === &#x27;object&#x27; ?
              settings.settings.video.frameRate : (options.useExactConstraints ?
              { exact: settings.settings.video.frameRate } : { max: settings.settings.video.frameRate });
          }
        }
      } else if (options.useExactConstraints) {
        settings.getUserMediaSettings.video = {
          width: { exact: settings.settings.video.resolution.width },
          height: { exact: settings.settings.video.resolution.height }
        };

      } else {
        settings.getUserMediaSettings.video.mandatory = {
          maxWidth: settings.settings.video.resolution.width,
          maxHeight: settings.settings.video.resolution.height
        };
      }
    }
  }

  return settings;
};

/**
 * Function that handles the native &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API success callback result.
 * @method _onStreamAccessSuccess
 * @private
 * @for Skylink
 * @since 0.3.0
 */
Skylink.prototype._onStreamAccessSuccess = function(stream, settings, isScreenSharing, isAudioFallback) {
  var self = this;
  var streamId = stream.id || stream.label;

  log.log([null, &#x27;MediaStream&#x27;, streamId, &#x27;Has access to stream -&gt;&#x27;], stream);

  // Stop previous stream
  if (!isScreenSharing &amp;&amp; self._streams.userMedia) {
    self._stopStreams({
      userMedia: true,
      screenshare: false
    });

  } else if (isScreenSharing &amp;&amp; self._streams.screenshare) {
    self._stopStreams({
      userMedia: false,
      screenshare: true
    });
  }

  self._streamsStoppedCbs[streamId] = function () {
    log.log([null, &#x27;MediaStream&#x27;, streamId, &#x27;Stream has ended&#x27;]);

    self._trigger(&#x27;mediaAccessStopped&#x27;, !!isScreenSharing, !!isAudioFallback, streamId);

    if (self._inRoom) {
      log.debug([null, &#x27;MediaStream&#x27;, streamId, &#x27;Sending Stream ended status to Peers&#x27;]);

      self._sendChannelMessage({
        type: self._SIG_MESSAGE_TYPE.STREAM,
        mid: self._user.sid,
        rid: self._room.id,
        cid: self._key,
        streamId: streamId,
        settings: settings.settings,
        status: &#x27;ended&#x27;
      });

      self._trigger(&#x27;streamEnded&#x27;, self._user.sid, self.getPeerInfo(), true, !!isScreenSharing, streamId);

      if (isScreenSharing &amp;&amp; self._streams.screenshare &amp;&amp; self._streams.screenshare.stream &amp;&amp;
        (self._streams.screenshare.stream.id || self._streams.screenshare.stream.label) === streamId) {
        self._streams.screenshare = null;

      } else if (!isScreenSharing &amp;&amp; self._streams.userMedia &amp;&amp; self._streams.userMedia.stream &amp;&amp;
        (self._streams.userMedia.stream.id || self._streams.userMedia.stream.label) === streamId) {
        self._streams.userMedia = null;
      }
    }
  };

  // Handle event for Chrome / Opera
  if ([&#x27;chrome&#x27;, &#x27;opera&#x27;].indexOf(window.webrtcDetectedBrowser) &gt; -1) {
    stream.oninactive = function () {
      if (self._streamsStoppedCbs[streamId]) {
        self._streamsStoppedCbs[streamId]();
        delete self._streamsStoppedCbs[streamId];
      }
    };

  // Handle event for Firefox (use an interval)
  } else if (window.webrtcDetectedBrowser === &#x27;firefox&#x27;) {
    stream.endedInterval = setInterval(function () {
      if (typeof stream.recordedTime === &#x27;undefined&#x27;) {
        stream.recordedTime = 0;
      }
      if (stream.recordedTime === stream.currentTime) {
        clearInterval(stream.endedInterval);

        if (self._streamsStoppedCbs[streamId]) {
          self._streamsStoppedCbs[streamId]();
          delete self._streamsStoppedCbs[streamId];
        }

      } else {
        stream.recordedTime = stream.currentTime;
      }
    }, 1000);

  } else {
    stream.onended = function () {
      if (self._streamsStoppedCbs[streamId]) {
        self._streamsStoppedCbs[streamId]();
        delete self._streamsStoppedCbs[streamId];
      }
    };
  }

  if ((settings.settings.audio &amp;&amp; stream.getAudioTracks().length === 0) ||
    (settings.settings.video &amp;&amp; stream.getVideoTracks().length === 0)) {

    var tracksNotSameError = &#x27;Expected audio tracks length with &#x27; +
      (settings.settings.audio ? &#x27;1&#x27; : &#x27;0&#x27;) + &#x27; and video tracks length with &#x27; +
      (settings.settings.video ? &#x27;1&#x27; : &#x27;0&#x27;) + &#x27; but received audio tracks length &#x27; +
      &#x27;with &#x27; + stream.getAudioTracks().length + &#x27; and video &#x27; +
      &#x27;tracks length with &#x27; + stream.getVideoTracks().length;

    log.warn([null, &#x27;MediaStream&#x27;, streamId, tracksNotSameError]);

    var requireAudio = !!settings.settings.audio;
    var requireVideo = !!settings.settings.video;

    if (settings.settings.audio &amp;&amp; stream.getAudioTracks().length === 0) {
      settings.settings.audio = false;
    }

    if (settings.settings.video &amp;&amp; stream.getVideoTracks().length === 0) {
      settings.settings.video = false;
    }

    self._trigger(&#x27;mediaAccessFallback&#x27;, {
      error: new Error(tracksNotSameError),
      diff: {
        video: { expected: requireVideo ? 1 : 0, received: stream.getVideoTracks().length },
        audio: { expected: requireAudio ? 1 : 0, received: stream.getAudioTracks().length }
      }
    }, self.MEDIA_ACCESS_FALLBACK_STATE.FALLBACKED, !!isScreenSharing, !!isAudioFallback, streamId);
  }

  self._streams[ isScreenSharing ? &#x27;screenshare&#x27; : &#x27;userMedia&#x27; ] = {
    stream: stream,
    settings: settings.settings,
    constraints: settings.getUserMediaSettings
  };
  self._muteStreams();
  self._trigger(&#x27;mediaAccessSuccess&#x27;, stream, !!isScreenSharing, !!isAudioFallback, streamId);
};

/**
 * Function that handles the native &lt;code&gt;navigator.getUserMedia()&lt;/code&gt; API failure callback result.
 * @method _onStreamAccessError
 * @private
 * @for Skylink
 * @since 0.6.15
 */
Skylink.prototype._onStreamAccessError = function(error, settings, isScreenSharing) {
  var self = this;

  if (!isScreenSharing &amp;&amp; settings.settings.audio &amp;&amp; settings.settings.video &amp;&amp; self._audioFallback) {
    log.debug(&#x27;Fallbacking to retrieve audio only Stream&#x27;);

    self._trigger(&#x27;mediaAccessFallback&#x27;, {
      error: error,
      diff: null
    }, self.MEDIA_ACCESS_FALLBACK_STATE.FALLBACKING, false, true);

    navigator.getUserMedia({
      audio: true
    }, function (stream) {
      self._onStreamAccessSuccess(stream, settings, false, true);

    }, function (error) {
      log.error(&#x27;Failed fallbacking to retrieve audio only Stream -&gt;&#x27;, error);

      self._trigger(&#x27;mediaAccessError&#x27;, error, false, true);
      self._trigger(&#x27;mediaAccessFallback&#x27;, {
        error: error,
        diff: null
      }, self.MEDIA_ACCESS_FALLBACK_STATE.ERROR, false, true);
    });
    return;
  }

  log.error(&#x27;Failed retrieving &#x27; + (isScreenSharing ? &#x27;screensharing&#x27; : &#x27;camera&#x27;) + &#x27; Stream -&gt;&#x27;, error);

  self._trigger(&#x27;mediaAccessError&#x27;, error, !!isScreenSharing, false);
};

/**
 * Function that handles the &lt;code&gt;RTCPeerConnection.onaddstream&lt;/code&gt; remote MediaStream received.
 * @method _onRemoteStreamAdded
 * @private
 * @for Skylink
 * @since 0.5.2
 */
Skylink.prototype._onRemoteStreamAdded = function(targetMid, stream, isScreenSharing) {
  var self = this;

  if (!self._peerInformations[targetMid]) {
    log.warn([targetMid, &#x27;MediaStream&#x27;, stream.id,
      &#x27;Received remote stream when peer is not connected. &#x27; +
      &#x27;Ignoring stream -&gt;&#x27;], stream);
    return;
  }

  /*if (!self._peerInformations[targetMid].settings.audio &amp;&amp;
    !self._peerInformations[targetMid].settings.video &amp;&amp; !isScreenSharing) {
    log.log([targetMid, &#x27;MediaStream&#x27;, stream.id,
      &#x27;Receive remote stream but ignoring stream as it is empty -&gt;&#x27;
      ], stream);
    return;
  }*/
  log.log([targetMid, &#x27;MediaStream&#x27;, stream.id, &#x27;Received remote stream -&gt;&#x27;], stream);

  if (isScreenSharing) {
    log.log([targetMid, &#x27;MediaStream&#x27;, stream.id, &#x27;Peer is having a screensharing session with user&#x27;]);
  }

  self._trigger(&#x27;incomingStream&#x27;, targetMid, stream, false, self.getPeerInfo(targetMid), isScreenSharing, stream.id || stream.label);
  self._trigger(&#x27;peerUpdated&#x27;, targetMid, self.getPeerInfo(targetMid), false);
};

/**
 * Function that sets User&#x27;s Stream to send to Peer connection.
 * Priority for &lt;code&gt;shareScreen()&lt;/code&gt; Stream over &lt;code&gt;getUserMedia()&lt;/code&gt; Stream.
 * @method _addLocalMediaStreams
 * @private
 * @for Skylink
 * @since 0.5.2
 */
Skylink.prototype._addLocalMediaStreams = function(peerId) {
  var self = this;

  // NOTE ALEX: here we could do something smarter
  // a mediastream is mainly a container, most of the info
  // are attached to the tracks. We should iterates over track and print
  try {
    log.log([peerId, null, null, &#x27;Adding local stream&#x27;]);

    var pc = self._peerConnections[peerId];

    if (pc) {
      if (pc.signalingState !== self.PEER_CONNECTION_STATE.CLOSED) {
        // Updates the streams accordingly
        var updateStreamFn = function (updatedStream) {
          var hasStream = false;

          // remove streams
          var streams = pc.getLocalStreams();
          for (var i = 0; i &lt; streams.length; i++) {
            if (updatedStream !== null &amp;&amp; streams[i].id === updatedStream.id) {
              hasStream = true;
              continue;
            }
            // try removeStream
            pc.removeStream(streams[i]);
          }

          if (updatedStream !== null &amp;&amp; !hasStream) {
            pc.addStream(updatedStream);
          }
        };

        if (self._streams.screenshare &amp;&amp; self._streams.screenshare.stream) {
          log.debug([peerId, &#x27;MediaStream&#x27;, null, &#x27;Sending screen&#x27;], self._streams.screenshare.stream);

          updateStreamFn(self._streams.screenshare.stream);

        } else if (self._streams.userMedia &amp;&amp; self._streams.userMedia.stream) {
          log.debug([peerId, &#x27;MediaStream&#x27;, null, &#x27;Sending stream&#x27;], self._streams.userMedia.stream);

          updateStreamFn(self._streams.userMedia.stream);

        } else {
          log.warn([peerId, &#x27;MediaStream&#x27;, null, &#x27;No media to send. Will be only receiving&#x27;]);

          updateStreamFn(null);
        }

      } else {
        log.warn([peerId, &#x27;MediaStream&#x27;, null,
          &#x27;Not adding any stream as signalingState is closed&#x27;]);
      }
    } else {
      log.warn([peerId, &#x27;MediaStream&#x27;, self._mediaStream,
        &#x27;Not adding stream as peerconnection object does not exists&#x27;]);
    }
  } catch (error) {
    if ((error.message || &#x27;&#x27;).indexOf(&#x27;already added&#x27;) &gt; -1) {
      log.warn([peerId, null, null, &#x27;Not re-adding stream as LocalMediaStream is already added&#x27;], error);
    } else {
      // Fix errors thrown like NS_ERROR_UNEXPECTED
      log.error([peerId, null, null, &#x27;Failed adding local stream&#x27;], error);
    }
  }
};

/**
 * Function that handles ended streams.
 * @method _handleEndedStreams
 * @private
 * @for Skylink
 * @since 0.6.16
 */
Skylink.prototype._handleEndedStreams = function (peerId, checkStreamId) {
  var self = this;
  self._streamsSession[peerId] = self._streamsSession[peerId] || {};

  var renderEndedFn = function (streamId) {
    var shouldTrigger = !!self._streamsSession[peerId][streamId];

    if (!checkStreamId &amp;&amp; self._peerConnections[peerId] &amp;&amp;
      self._peerConnections[peerId].signalingState !== self.PEER_CONNECTION_STATE.CLOSED) {
      var streams = self._peerConnections[peerId].getRemoteStreams();

      for (var i = 0; i &lt; streams.length; i++) {
        if (streamId === (streams[i].id || streams[i].label)) {
          shouldTrigger = false;
          break;
        }
      }
    }

    if (shouldTrigger) {
      var peerInfo = clone(self.getPeerInfo(peerId));
      peerInfo.settings.audio = clone(self._streamsSession[peerId][streamId].audio);
      peerInfo.settings.video = clone(self._streamsSession[peerId][streamId].video);
      var hasScreenshare = peerInfo.settings.video &amp;&amp; typeof peerInfo.settings.video === &#x27;object&#x27; &amp;&amp;
        !!peerInfo.settings.video.screenshare;
      self._streamsSession[peerId][streamId] = false;
      self._trigger(&#x27;streamEnded&#x27;, peerId, peerInfo, false, hasScreenshare, streamId);
    }
  };

  if (checkStreamId) {
    renderEndedFn(checkStreamId);
  } else {
    for (var prop in self._streamsSession[peerId]) {
      if (self._streamsSession[peerId].hasOwnProperty(prop) &amp;&amp; self._streamsSession[peerId][prop]) {
        renderEndedFn(prop);
      }
    }
  }
};
    </pre>
</div>

                  </div>
              </div>
          </div>
      </div>
  </div>
</div>
<script src="../assets/vendor/prettify/prettify-min.js"></script>
<script>prettyPrint();</script>
<script src="../assets/js/yui-prettify.js"></script>
<script src="../assets/../api.js"></script>
<script src="../assets/js/api-filter.js"></script>
<script src="../assets/js/api-list.js"></script>
<script src="../assets/js/api-search.js"></script>
<script src="../assets/js/apidocs.js"></script>
</body>
</html>
